# RAG Agent Swarm UI Integration Guide

**Created:** 2025-01-08  
**Status:** âœ… Integration Complete  
**Purpose:** Guide for using the RAG Agent Swarm in the RAG Management UI

---

## ğŸ‰ **What's New**

The RAG Management App now supports **dual modes**:
1. **ğŸ”¥ Agent Swarm (Best Quality)** - 5 specialized agents working together
2. **âš¡ Single Agent (Fast)** - Original single-agent approach

You can switch between them and compare results in real-time!

---

## ğŸš€ **How to Use**

### **Starting the RAG UI**

```bash
# Activate environment
C:\App\Anaconda\Scripts\activate.bat base

# Start RAG Management App
streamlit run apps/rag_management_app.py --server.port 8510
```

Navigate to: [http://localhost:8510](http://localhost:8510)

---

## ğŸ’¬ **Agent Chat Page**

### **Selecting Mode**

1. Go to **"ğŸ’¬ Agent Chat"** tab
2. In the **"RAG Mode"** dropdown, choose:
   - **ğŸ”¥ Agent Swarm (Best Quality)** â† Recommended for best results
   - **âš¡ Single Agent (Fast)** â† Faster, simpler

### **What You'll See with Agent Swarm**

When using **Agent Swarm mode**, the UI shows:

#### **Chat Interface:**
- Your query
- Agent's comprehensive response with citations
- Context statistics panel (if Debug Mode enabled)

#### **Context Statistics Panel** (Debug Mode):
```
ğŸ”¥ Agent Swarm Pipeline
âœ… 1. Query Analysis
âœ… 2. Context Retrieval
âœ… 3. Re-ranking
âœ… 4. Quality Assurance
âœ… 5. Response Generation

Quality & Confidence
Quality Score: ğŸŸ¢ 0.85
Confidence: ğŸŸ¢ 0.82

â±ï¸ Pipeline Timing
Query Analysis: 234ms
Retrieval: 412ms
Re Ranking: 156ms
Qa: 189ms
Generation: 1,845ms

ğŸ“š Sources Cited
â€¢ agents/rag/query_analyst_agent.py
â€¢ docs/architecture/RAG_AGENT_SWARM_ARCHITECTURE.md
```

---

## ğŸ§ª **Testing & Evaluation Page**

### **Running Tests**

1. Go to **"ğŸ§ª Testing & Evaluation"** tab
2. Click **"Single Query Test"** tab
3. Enter your test query
4. Click **"ğŸš€ Run Test"**

The test now uses **Agent Swarm by default**!

### **Transparency Report**

The transparency report now shows:

#### **Overview Metrics:**
```
Mode: ğŸ”¥ Agent Swarm

â±ï¸ Total Time  ğŸ“„ Results  Quality  Confidence  Stages
   2,845ms        10      ğŸŸ¢ 0.85   ğŸŸ¢ 0.82    âœ… 5/5
```

#### **Generated Response:**
Full response with proper citations and formatting

#### **Retrieved Context Details:**
- Top 10 results with scores
- Scoring breakdown (Semantic, Keyword, Quality, Diversity)
- Source information

#### **Processing Pipeline:**
```
ğŸ”¥ Agent Swarm Pipeline

âœ… 1ï¸âƒ£ Query Analysis (QueryAnalystAgent)
âœ… 2ï¸âƒ£ Context Retrieval (RetrievalSpecialistAgent)
âœ… 3ï¸âƒ£ Re-ranking (ReRankerAgent)
âœ… 4ï¸âƒ£ Quality Assurance (QualityAssuranceAgent)
âœ… 5ï¸âƒ£ Response Generation (WriterAgent)

â±ï¸ Stage Timing
Query Analysis: 234ms
Retrieval: 412ms
Re Ranking: 156ms
Qa: 189ms
Generation: 1,845ms

ğŸ” Query Analysis Details
{
  "original_query": "What is context engineering?",
  "intent": "conceptual",
  "rewritten_queries": [...],
  "key_concepts": [...],
  "search_strategy": "broad",
  "complexity": 0.55
}

ğŸ“š Sources Cited
â€¢ file1.py
â€¢ file2.md
```

---

## ğŸ” **Debug Mode Features**

### **Enabling Debug Mode**

In the Agent Chat page:
1. Check the **"Debug Mode"** checkbox
2. Adjust **"Context Detail Level"** slider to "Debug"

### **What Debug Mode Shows**

- **Real-time pipeline visualization**
- **Quality scores and confidence**
- **Stage-by-stage timing**
- **Query analysis breakdown**
- **Sources cited**
- **Full context statistics**

---

## ğŸ“Š **Comparing Swarm vs Single Agent**

### **Side-by-Side Comparison**

To compare both modes:

1. Ask the same question in **Agent Swarm** mode
2. Note the response quality and timing
3. Switch to **Single Agent** mode
4. Ask the same question again
5. Compare:
   - **Response quality and completeness**
   - **Source citations**
   - **Processing time**
   - **Confidence scores** (swarm only)

### **Expected Differences**

| Aspect | Single Agent | Agent Swarm |
|--------|-------------|-------------|
| **Quality** | Good | Excellent âœ¨ |
| **Citations** | Basic | Comprehensive |
| **Speed** | Fast (1-2s) | Moderate (3-5s) |
| **Context** | Single search | Multi-stage |
| **QA** | Self-check | Dedicated QA agent |
| **Confidence** | Implicit | Explicit score |
| **Traceability** | Limited | Full pipeline visibility |

---

## ğŸ¯ **Best Practices**

### **When to Use Agent Swarm**
- âœ… Complex queries requiring comprehensive answers
- âœ… Multi-hop questions spanning multiple concepts
- âœ… When accuracy and citations are critical
- âœ… For production-quality responses
- âœ… When you need quality scoring

### **When to Use Single Agent**
- âœ… Simple factual queries
- âœ… Quick testing during development
- âœ… When speed is more important than depth
- âœ… For exploratory queries

---

## ğŸ”§ **Configuration**

### **Swarm Parameters** (in code)

When using the swarm programmatically:

```python
from agents.rag import RAGSwarmCoordinator
from context.context_engine import ContextEngine

# Initialize
context_engine = ContextEngine(context_config)
swarm = RAGSwarmCoordinator(context_engine)

# Execute with custom parameters
result = await swarm.execute({
    'query': 'Your question here',
    'max_results': 10,           # Default: 10
    'quality_threshold': 0.7,     # Default: 0.7 (0.0-1.0)
    'enable_re_retrieval': True   # Default: True
})
```

### **Parameters Explained:**

- **max_results**: Number of top results to return (after ranking)
- **quality_threshold**: Minimum quality score (triggers re-retrieval if below)
- **enable_re_retrieval**: Allow automatic re-retrieval if quality is low

---

## ğŸ› **Troubleshooting**

### **"Agent Swarm mode not available"**
- Check that all RAG agent files are present in `agents/rag/`
- Verify imports are working: `from agents.rag import RAGSwarmCoordinator`

### **"Quality score is always low"**
- Check that your vector store has sufficient documents indexed
- Try uploading more relevant documents
- Verify embeddings are initialized

### **"Pipeline stages incomplete"**
- Check logs for specific agent failures
- Verify API keys are configured (Gemini)
- Check LangSmith configuration if tracing is enabled

### **"Responses are slow"**
- Normal for Agent Swarm (3-5 seconds is expected)
- Check if re-retrieval is happening (adds 2-3s)
- Consider using Single Agent mode for speed

---

## ğŸ“š **LangSmith Tracing**

### **Viewing Swarm Traces**

If LangSmith is configured:

1. Go to [https://smith.langchain.com/](https://smith.langchain.com/)
2. Select project: **"ai-dev-agent-rag"**
3. Find your query trace
4. Click to expand the execution tree

### **What You'll See:**

```
Trace: "RAGSwarmCoordinator.execute"
â”œâ”€ QueryAnalystAgent.execute
â”‚  â”œâ”€ LLM: Gemini 2.0 Flash (intent analysis)
â”‚  â””â”€ Output: query_analysis
â”œâ”€ RetrievalSpecialistAgent.execute
â”‚  â”œâ”€ Search #1: original query
â”‚  â”œâ”€ Search #2: variant 1
â”‚  â”œâ”€ Search #3: variant 2
â”‚  â””â”€ Output: 24 candidates
â”œâ”€ ReRankerAgent.execute
â”‚  â”œâ”€ Deduplication: 24 â†’ 18
â”‚  â”œâ”€ Multi-signal scoring
â”‚  â””â”€ Output: Top 10 ranked
â”œâ”€ QualityAssuranceAgent.execute
â”‚  â””â”€ Output: quality_report (0.85)
â””â”€ WriterAgent.execute
   â”œâ”€ LLM: Gemini 2.0 Flash Thinking (synthesis)
   â””â”€ Output: final_response
```

---

## âœ… **Verification Checklist**

Before testing, ensure:

- [ ] RAG system initialized (documents uploaded or codebase indexed)
- [ ] Vector store has data (check "ğŸ“Š Context Statistics" on home page)
- [ ] Gemini API key configured in `.streamlit/secrets.toml`
- [ ] Debug Mode enabled for full visibility
- [ ] LangSmith configured (optional but recommended)

---

## ğŸ“ **Example Queries**

### **Good Queries for Agent Swarm:**

1. **Conceptual:**
   - "What is context engineering and how is it implemented in this project?"
   - "Explain the difference between RAG and fine-tuning"

2. **Multi-hop:**
   - "How does the QueryAnalystAgent interact with the RetrievalSpecialistAgent?"
   - "What are the main components of the RAG system and how do they work together?"

3. **Procedural:**
   - "How do I add a new agent to the swarm?"
   - "What steps are involved in the RAG pipeline?"

4. **Comparative:**
   - "Compare the agent swarm approach vs single agent for RAG"
   - "What are the pros and cons of different retrieval strategies?"

---

## ğŸ“– **Related Documentation**

- [RAG Agent Swarm Architecture](../architecture/RAG_AGENT_SWARM_ARCHITECTURE.md)
- [RAG Agent Swarm Implementation](../architecture/RAG_AGENT_SWARM_IMPLEMENTATION.md)
- [How to See RAG Calls](./HOW_TO_SEE_RAG_CALLS.md)
- [RAG LangSmith Integration](../architecture/RAG_LANGSMITH_INTEGRATION.md)

---

## ğŸš€ **Next Steps**

1. **Test with your queries** - Try both modes and compare
2. **Build golden dataset** - Add good queries to "Golden Dataset Management"
3. **Monitor quality scores** - Track improvement over time
4. **Optimize parameters** - Adjust thresholds based on results
5. **Check LangSmith traces** - Understand the full pipeline

---

**Status:** âœ… Fully integrated and ready to use!  
**Last Updated:** 2025-01-08

