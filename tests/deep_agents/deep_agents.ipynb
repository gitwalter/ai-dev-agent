{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eecae63",
   "metadata": {},
   "source": [
    "# Gemini Client Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2750003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ad9684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(profile={'max_input_tokens': 1048576, 'max_output_tokens': 65536, 'image_inputs': True, 'audio_inputs': True, 'pdf_inputs': True, 'video_inputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'image_tool_message': True, 'tool_choice': True}, model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001178EE697D0>, default_metadata=(), model_kwargs={})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423174c5",
   "metadata": {},
   "source": [
    "# Utility Text Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4df50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import textwrap\n",
    "\n",
    "def display_wrapped_text(text, width=80, language=\"\"):\n",
    "    \"\"\"Display text with line wrapping in a Jupyter notebook.\"\"\"\n",
    "    wrapped = textwrap.fill(str(text), width=width)\n",
    "    if language:\n",
    "        display(Markdown(f\"{language}\\n{wrapped}\\n\"))\n",
    "    else:        \n",
    "        display(Markdown(f\"\\n{wrapped}\\n\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2134310e",
   "metadata": {},
   "source": [
    "# Internet Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137173fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "{'query': 'What are the core concepts of langchain?', 'follow_up_questions':\n",
       "None, 'answer': None, 'images': [], 'results': [{'url':\n",
       "'https://apxml.com/courses/python-llm-workflows/chapter-4-langchain-\n",
       "fundamentals/langchain-core-concepts', 'title': 'LangChain Core Concepts:\n",
       "Models, Prompts, Parsers', 'content': 'LangChain organizes interactions with\n",
       "Large Language Models (LLMs) around three fundamental components: Models,\n",
       "Prompts, and Output Parsers.', 'score': 0.99989367, 'raw_content': None},\n",
       "{'url': 'https://www.ksolves.com/blog/artificial-intelligence/key-concepts-of-\n",
       "langchain', 'title': 'Understand the Core Components and Key Concepts of\n",
       "LangChain', 'content': 'LangChain is an open-source framework that gives\n",
       "developers the tools they need to create applications using large language\n",
       "models (LLMs). LangChain is a framework designed to build applications that\n",
       "utilize language models. Furthermore, LangChain’s model management tools let\n",
       "developers work with many language model types and versions, making updates and\n",
       "changes simple. In LangChain, agents are interfaces that combine language models\n",
       "with outside tools and services to create dynamic and interactive applications.\n",
       "Because of LangChain’s modular architecture, developers may easily swap out\n",
       "language models, data sources, and processing stages without compromising the\n",
       "functionality of the entire program. Developers may create dynamic applications\n",
       "that interact intelligently with several data sources, automate complex\n",
       "processes, and carry out multi-step activities with ease by utilizing agents.\n",
       "Adopting LangChain in your Artificial Intelligence and Machine Learning projects\n",
       "offers a multitude of advantages, empowering developers and organizations to\n",
       "unlock the full potential of large language models. LangChain empowers\n",
       "developers to create sophisticated conversational AI systems and context-aware\n",
       "applications.', 'score': 0.9998859, 'raw_content': None}, {'url':\n",
       "'https://www.decube.io/post/langchain-intro', 'title': 'Langchain : Concepts and\n",
       "getting started - Decube', 'content': 'By leveraging its core components,\n",
       "including prompt templates, LLMs, agents, and memory, data engineers can build\n",
       "powerful applications that automate processes, provide valuable insights, and\n",
       "enhance productivity. Whether using LLMs from the Hugging Face Hub or OpenAI,\n",
       "Langchain empowers data engineers to tap into the full potential of these\n",
       "language models. Context Engineering is the practice of designing and\n",
       "operationalizing business meaning, data lineage, quality signals, ownership, and\n",
       "policy constraints so that both humans and AI systems can reliably understand\n",
       "and act on enterprise data. The four core components of Context Engineering are:\n",
       "Semantic context (business meaning and definitions) Lineage context (end-to-end\n",
       "data flow and dependencies) Operational context (data quality and reliability\n",
       "signals) Policy context (privacy, compliance, and usage constraints) Together,\n",
       "these form a unified context layer that supports enterprise decision-making and\n",
       "AI automation. Platforms like Decube’s Data Trust Platform unify lineage with\n",
       "data quality and metadata management to help enterprises achieve AI readiness.',\n",
       "'score': 0.9994642, 'raw_content': None}, {'url':\n",
       "'https://docs.langchain.com/oss/python/langchain/overview', 'title': 'LangChain\n",
       "overview - Docs by LangChain', 'content': 'LangChain is an open source framework\n",
       "with a pre-built agent architecture and integrations for any model or tool — so\n",
       "you can build agents that adapt as fast as the ecosystem evolves. LangChain is\n",
       "the easiest way to start building agents and applications powered by LLMs. With\n",
       "under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more.\n",
       "LangChain provides a pre-built agent architecture and model integrations to help\n",
       "you get started quickly and seamlessly incorporate LLMs into your agents and\n",
       "applications. LangChain agents are built on top of LangGraph in order to provide\n",
       "durable execution, streaming, human-in-the-loop, persistence, and more. You do\n",
       "not need to know LangGraph for basic LangChain agent usage. See the Installation\n",
       "instructions and Quickstart guide to get started building your own agents and\n",
       "applications with LangChain. LangChain standardizes how you interact with models\n",
       "so that you can seamlessly swap providers and avoid lock-in.## Easy to use,\n",
       "highly flexible agent. LangChain’s agents are built on top of LangGraph.',\n",
       "'score': 0.9992679, 'raw_content': None}, {'url':\n",
       "'https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-\n",
       "langchain/', 'title': 'Introduction to LangChain - GeeksforGeeks', 'content':\n",
       "\"Chains:**** Chains define sequences of actions, where each step can involve\n",
       "querying an LLM, manipulating data or interacting with external tools. Vector\n",
       "database plays a key role in tasks like document retrieval, knowledge base\n",
       "integration or context-based search providing the model with dynamic, real-time\n",
       "data to enhance responses. LangChain follows a structured pipeline that\n",
       "integrates user queries, data retrieval and response generation into seamless\n",
       "workflow. Based on the similarity search, LangChain retrieves the most relevant\n",
       "data or context from the database. Let's implement a model using LangChain and\n",
       "OpenAI API:. * ****langchain:**** the core LangChain framework (chains, prompts,\n",
       "tools, memory, etc.). The LangChain framework is a great interface to develop\n",
       "interesting AI-powered applications and from personal assistants to prompt\n",
       "management as well as automating tasks. 10 min readTypes of Artificial\n",
       "Intelligence (AI). 6 min readTop 20 Applications of Artificial Intelligence (AI)\n",
       "in 2025. 7 min readAdversarial Search Algorithms in Artificial Intelligence\n",
       "(AI). 12 min readGenerative AI Applications. 15+ min readTop Generative AI and\n",
       "LLM Interview Question with Answer.\", 'score': 0.99906737, 'raw_content':\n",
       "None}], 'response_time': 0.64, 'request_id':\n",
       "'9b02973b-f94a-4d0d-b5fc-8d96062f8c3b'}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "\n",
    "\n",
    "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "\n",
    "def internet_search(query: str, max_results: int = 5):\n",
    "    \"\"\"Run a web search\"\"\"\n",
    "    return tavily_client.search(query, max_results=max_results)\n",
    "\n",
    "\n",
    "result = internet_search(\"What are the core concepts of langchain?\")\n",
    "display_wrapped_text(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7839df2",
   "metadata": {},
   "source": [
    "# Python REPL Tool (Read-Evaluate-Print Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ac4850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.tools import Tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "# 1. Create the Python REPL instance\n",
    "python_repl = PythonREPL()\n",
    "\n",
    "\n",
    "# 3. Create the Tool wrapper\n",
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
    "    func=python_repl.run,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce7d279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl.run(\"print(1+1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e26cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.tools import Tool\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def run_pandas_analysis(input_text: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Load test.csv and calculate comprehensive statistics, returning a DataFrame with calculated data.\n",
    "    \n",
    "    Args:\n",
    "        input_text: Optional input text (ignored, but required by LangChain Tool interface)\n",
    "    \n",
    "    Returns:\n",
    "        str: JSON string containing the statistics DataFrame and summary information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the script directory - use absolute paths to avoid duplication\n",
    "        current_dir = Path.cwd().resolve()\n",
    "        \n",
    "        # Check if we're already in tests/deep_agents directory\n",
    "        if current_dir.name == 'deep_agents' and current_dir.parent.name == 'tests':\n",
    "            csv_path = current_dir / \"test.csv\"\n",
    "        else:\n",
    "            # Find project root (ai-dev-agent directory)\n",
    "            project_root = current_dir\n",
    "            while project_root.name != 'ai-dev-agent' and len(project_root.parts) > 1:\n",
    "                project_root = project_root.parent\n",
    "            \n",
    "            if project_root.name == 'ai-dev-agent':\n",
    "                csv_path = (project_root / \"tests\" / \"deep_agents\" / \"test.csv\").resolve()\n",
    "            else:\n",
    "                # Fallback: assume we're at project root\n",
    "                csv_path = (current_dir / \"tests\" / \"deep_agents\" / \"test.csv\").resolve()\n",
    "        \n",
    "        # Verify file exists\n",
    "        if not csv_path.exists():\n",
    "            return json.dumps({\n",
    "                'error': f'Could not find test.csv',\n",
    "                'current_directory': str(current_dir),\n",
    "                'csv_path_attempted': str(csv_path),\n",
    "                'hint': 'Ensure test.csv exists in tests/deep_agents/ directory'\n",
    "            })\n",
    "        \n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Get numerical columns\n",
    "        numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        # Calculate comprehensive statistics DataFrame (integrated from calculate_statistics)\n",
    "        stats_df = pd.DataFrame({\n",
    "            'Mean': df[numerical_cols].mean(),\n",
    "            'Median': df[numerical_cols].median(),\n",
    "            'Std Dev': df[numerical_cols].std(),\n",
    "            'Variance': df[numerical_cols].var(),\n",
    "            'Min': df[numerical_cols].min(),\n",
    "            'Max': df[numerical_cols].max(),\n",
    "            'Range': df[numerical_cols].max() - df[numerical_cols].min(),\n",
    "            'Q1 (25%)': df[numerical_cols].quantile(0.25),\n",
    "            'Q3 (75%)': df[numerical_cols].quantile(0.75),\n",
    "            'IQR': df[numerical_cols].quantile(0.75) - df[numerical_cols].quantile(0.25),\n",
    "            'Skewness': df[numerical_cols].skew(),\n",
    "            'Kurtosis': df[numerical_cols].kurtosis()\n",
    "        })\n",
    "        \n",
    "        # Round statistics for readability\n",
    "        stats_df = stats_df.round(2)\n",
    "        \n",
    "        # Calculate additional summary metrics\n",
    "        summary = {\n",
    "            'total_rows': len(df),\n",
    "            'total_columns': len(df.columns),\n",
    "            'numerical_columns': numerical_cols,\n",
    "            'categorical_columns': df.select_dtypes(include=['object']).columns.tolist(),\n",
    "            'total_revenue': float(df['revenue'].sum()),\n",
    "            'total_quantity_sold': int(df['quantity_sold'].sum()),\n",
    "            'average_price': float(df['price'].mean()),\n",
    "            'average_rating': float(df['rating'].mean()),\n",
    "            'unique_categories': int(df['category'].nunique()),\n",
    "            'unique_regions': int(df['region'].nunique())\n",
    "        }\n",
    "        \n",
    "        # Find outliers for each numerical column\n",
    "        outliers_info = {}\n",
    "        for col in numerical_cols:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "            if len(outliers) > 0:\n",
    "                outliers_info[col] = {\n",
    "                    'count': len(outliers),\n",
    "                    'lower_bound': float(lower_bound),\n",
    "                    'upper_bound': float(upper_bound),\n",
    "                    'outlier_values': outliers[['product_name', col]].to_dict('records')\n",
    "                }\n",
    "        \n",
    "        # Calculate correlation matrix\n",
    "        correlation_matrix = df[numerical_cols].corr().round(3)\n",
    "        \n",
    "        # Find strong correlations\n",
    "        strong_correlations = []\n",
    "        for i in range(len(correlation_matrix.columns)):\n",
    "            for j in range(i+1, len(correlation_matrix.columns)):\n",
    "                corr_value = correlation_matrix.iloc[i, j]\n",
    "                if abs(corr_value) > 0.7:\n",
    "                    strong_correlations.append({\n",
    "                        'column1': correlation_matrix.columns[i],\n",
    "                        'column2': correlation_matrix.columns[j],\n",
    "                        'correlation': float(corr_value)\n",
    "                    })\n",
    "        \n",
    "        # Prepare result dictionary\n",
    "        result = {\n",
    "            'statistics_dataframe': stats_df.to_dict(),\n",
    "            'summary': summary,\n",
    "            'outliers': outliers_info,\n",
    "            'correlation_matrix': correlation_matrix.to_dict(),\n",
    "            'strong_correlations': strong_correlations,\n",
    "            'dataframe_preview': df.head().to_dict('records')\n",
    "        }\n",
    "        \n",
    "        # Convert to JSON string for the agent\n",
    "        return json.dumps(result, indent=2, default=str)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        return json.dumps({\n",
    "            'error': f'Could not find test.csv in {csv_path}',\n",
    "            'message': 'Please ensure test.csv exists in the same directory.'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return json.dumps({\n",
    "            'error': str(e),\n",
    "            'error_type': type(e).__name__\n",
    "        })\n",
    "\n",
    "pandas_analysis_tool = Tool(\n",
    "    name=\"pandas_data_analysis\",\n",
    "    description=\"\"\"Load test.csv and calculate comprehensive statistical analysis. Returns a JSON object containing:\n",
    "    - statistics_dataframe: DataFrame with Mean, Median, Std Dev, Variance, Min, Max, Range, Q1, Q3, IQR, Skewness, Kurtosis for each numerical column\n",
    "    - summary: Overall statistics including total revenue, quantity sold, averages, and counts\n",
    "    - outliers: Outlier detection results using IQR method for each numerical column\n",
    "    - correlation_matrix: Correlation coefficients between all numerical columns\n",
    "    - strong_correlations: Pairs of columns with correlation > 0.7\n",
    "    - dataframe_preview: First 5 rows of the original data\"\"\",\n",
    "    func=run_pandas_analysis\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4254a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='How to build a model context protocol server as proposed by Anthropic?', additional_kwargs={}, response_metadata={}, id='097d02fb-f048-4e1e-adbd-962baa90b7e2'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'internet_search', 'arguments': '{\"query\": \"Anthropic model context protocol server\"}'}, '__gemini_function_call_thought_signatures__': {'f779818b-43de-4de4-ad04-4d3ed3988ed2': 'CuwBAXLI2ny7xwaog+ns1D/Uy5AU2vmbdXqDOinyZgZ3nUrcZNJ/x5ma/9CXV5dJON46MzuLrHeheVvUic8RHj2TedoF9qvi+g5rMKBJka29feJcJWnVKtUQ/7PF0rLQDAx2wGPCPM8Me3qomBnZt45tDtgyi5dmrwysCPptU+B0Qvy2X1m2hpUk0PAhP8SvpKCHijKlpcMuSwbArhdoq+kmu76WYUcIkjHinfZdnduMiFWO9zNg57wLSF/3akATEzscZzYObBhTw5BaaEWAObYJBdWyFevhQD7vjWXNKBkqwgWNuY06kebH6HP6iN8='}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--e959a5a6-55a6-48f5-9231-67a2f24d65f0-0', tool_calls=[{'name': 'internet_search', 'args': {'query': 'Anthropic model context protocol server'}, 'id': 'f779818b-43de-4de4-ad04-4d3ed3988ed2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4997, 'output_tokens': 60, 'total_tokens': 5057, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 40}}),\n",
       "  ToolMessage(content='{\"query\": \"Anthropic model context protocol server\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://en.wikipedia.org/wiki/Model_Context_Protocol\", \"title\": \"Model Context Protocol - Wikipedia\", \"content\": \"The **Model Context Protocol** (**MCP**) is an open standard and open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP was announced by Anthropic in November 2024 as an open standard for connecting AI assistants to data systems such as content repositories, business management tools, and development environments. MCP defines a standardized framework for integrating AI systems with external data sources and tools. The protocol also supports bidirectional connections between data sources and AI tools.*[non-primary source needed*]. Integrated development environments (IDEs), coding platforms such as Replit, and code intelligence tools like Sourcegraph have adopted MCP to grant AI coding assistants real-time access to project context. \\\\\"Anthropic releases Model Context Protocol to standardize AI-data integration\\\\\". \\\\\"OpenAI adopts rival Anthropic\\'s standard for connecting AI models to data\\\\\". \\\\\"Model Context Protocol (MCP): Integrating Azure OpenAI for Enhanced Tool Integration and Prompting\\\\\".\", \"score\": 0.90810597, \"raw_content\": null}, {\"url\": \"https://www.merge.dev/blog/model-context-protocol\", \"title\": \"What you need to know about the Model Context Protocol (MCP)\", \"content\": \"Anthropic\\'s recently-released Model Context Protocol (MCP) reaffirms that large language models (LLMs) need customer data to provide reliable, personalized, and useful outputs. To help all of the AI chatbot’s underlying LLMs get the context needed to understand tasks and perform them, you can integrate the LLMs with the relevant support applications via the MCP protocol\\xa0and give the LLMs access to read and write capabilities across these connected systems. *Learn about* *project management MCP servers* *you can connect to with Merge Agent Handler:*. To power this, you can integrate your AI agent’s LLM with your customers’ applicant tracking systems (ATSs) through MCP. Unified API solutions, which let you add hundreds of integrations to your product through a single, aggregated API, complement MCP for any integration, whether that’s managing authentication, data normalization, security, or sync speeds. Unified API solutions can offer a full suite of integration observability features to help your customer-facing team manage any of your MCP-based integrations.\", \"score\": 0.8443195, \"raw_content\": null}, {\"url\": \"https://anthropic.skilljar.com/introduction-to-model-context-protocol\", \"title\": \"Introduction to Model Context Protocol - Anthropic Courses\", \"content\": \"## Learn to build Model Context Protocol servers and clients from scratch using Python. This course provides comprehensive coverage of the Model Context Protocol (MCP), focusing on building both MCP servers and clients using the Python SDK. You\\'ll learn about MCP\\'s three core primitives—tools, resources, and prompts—and understand how they integrate with Claude AI to create powerful applications without writing extensive integration code. This course provides comprehensive coverage of the Model Context Protocol (MCP), focusing on building both MCP servers and clients using the Python SDK. You\\'ll learn about MCP\\'s three core primitives—tools, resources, and prompts—and understand how they integrate with Claude AI to create powerful applications without writing extensive integration code. Skilljar only tracks your learning progress within this course platform, while your Anthropic account manages your access to the Anthropic Console and/or Claude AI services. Your learning data is stored on secure servers with appropriate access controls.\", \"score\": 0.8342047, \"raw_content\": null}, {\"url\": \"https://www.atlassian.com/blog/announcements/remote-mcp-server\", \"title\": \"Introducing Atlassian\\'s Remote Model Context Protocol (MCP) Server\", \"content\": \"Bringing Atlassian’s enterprise knowledge to more AI tools — starting with Jira and Confluence wherever you use Anthropic’s Claude. We’re bringing Atlassian’s structured knowledge into more AI tools thanks to MCP, which provides a universal, open standard for connecting AI systems with data sources. With our Remote MCP Server, you can summarize work, create issues or pages, and perform multi-step actions, all while keeping data secure and within permissioned boundaries. We’re building our Remote MCP server with industry leaders who share our commitment to security and innovation. With Atlassian’s Remote MCP Server, teams can access their Jira tickets and Confluence documentation conveniently within Claude. To further ensure your enterprise data stays secure while enabling powerful integrations, our server will soon integrate with additional trusted and thoughtfully curated AI partners that support remote MCP. In addition to teaming up with Anthropic, we’re using Cloudflare’s Agents SDK to build our Remote MCP Server. You can try the Atlassian Remote MCP Server *today* in beta with Claude in Jira and Confluence.\", \"score\": 0.8029425, \"raw_content\": null}, {\"url\": \"https://www.anthropic.com/news/model-context-protocol\", \"title\": \"Introducing the Model Context Protocol - Anthropic\", \"content\": \"[Skip to main content](https://www.anthropic.com/news/model-context-protocol#main-content)[Skip to footer](https://www.anthropic.com/news/model-context-protocol#footer). *   [Research](https://www.anthropic.com/research). *   [News](https://www.anthropic.com/news). Today, we\\'re open-sourcing the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), a new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. *   The Model Context Protocol [specification and SDKs](https://github.com/modelcontextprotocol). [Read more](https://www.anthropic.com/news/compliance-framework-SB53). [Read more](https://www.anthropic.com/news/protecting-well-being-of-users). *   [Claude](https://claude.com/product/overview). *   [Claude Code](https://claude.com/product/claude-code). *   [Claude in Chrome](https://claude.com/chrome). *   [Skills](https://www.claude.com/skills). *   [Max plan](https://claude.com/pricing/max). *   [Team plan](https://claude.com/pricing/team). *   [Enterprise plan](https://claude.com/pricing/enterprise). *   [Pricing](https://claude.com/pricing). *   [Opus](https://www.anthropic.com/claude/opus). *   [Sonnet](https://www.anthropic.com/claude/sonnet). *   [Haiku](https://www.anthropic.com/claude/haiku). *   [AI agents](https://claude.com/solutions/agents). *   [Code modernization](https://claude.com/solutions/code-modernization). *   [Coding](https://claude.com/solutions/coding). *   [Customer support](https://claude.com/solutions/customer-support). *   [Education](https://claude.com/solutions/education). *   [Financial services](https://claude.com/solutions/financial-services). *   [Government](https://claude.com/solutions/government). *   [Life sciences](https://claude.com/solutions/life-sciences). *   [Nonprofits](https://claude.com/solutions/nonprofits). *   [Overview](https://claude.com/platform/api). *   [Developer docs](https://platform.claude.com/docs). *   [Pricing](https://claude.com/pricing#api). *   [Regional Compliance](https://claude.com/regional-compliance). *   [Google Cloud’s Vertex AI](https://claude.com/partners/google-cloud-vertex-ai). *   [Blog](https://claude.com/blog). *   [Claude partner network](https://claude.com/partners). *   [Connectors](https://claude.com/connectors). *   [Courses](https://www.anthropic.com/learn). *   [Customer stories](https://claude.com/customers). *   [Engineering at Anthropic](https://www.anthropic.com/engineering). *   [Events](https://www.anthropic.com/events). *   [Service partners](https://claude.com/partners/services). *   [Tutorials](https://claude.com/resources/tutorials). *   [Anthropic](https://www.anthropic.com/company). *   [Careers](https://www.anthropic.com/careers). *   [Research](https://www.anthropic.com/research). *   [News](https://www.anthropic.com/news). *   [Transparency](https://www.anthropic.com/transparency). *   [Availability](https://www.anthropic.com/supported-countries). *   [Support center](https://support.claude.com/en/). *   [Usage policy](https://www.anthropic.com/legal/aup). *   [](https://www.youtube.com/@anthropic-ai).\", \"score\": 0.77751994, \"raw_content\": null}], \"response_time\": 0.63, \"request_id\": \"f3d65769-63c0-4de6-b8fd-17ec7d61ac63\"}', name='internet_search', id='8fc72d1c-ce81-4e05-8aa7-3f19c9c67af2', tool_call_id='f779818b-43de-4de4-ad04-4d3ed3988ed2'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'The Model Context Protocol (MCP) is an open standard and open-source framework introduced by Anthropic to standardize how AI systems, like large language models (LLMs), integrate and share data with external tools, systems, and data sources. It allows AI assistants to access and interact with content repositories, business management tools, and development environments.\\n\\nTo build a Model Context Protocol server, you would typically use the Python SDK provided by Anthropic. The protocol revolves around three core primitives:\\n\\n*   **Tools:** These are actions or functions that an AI model can invoke in external systems.\\n*   **Resources:** These represent data or information that the AI model can access and utilize from external sources.\\n*   **Prompts:** These are the instructions or queries given to the AI model, which can leverage the available tools and resources.\\n\\nAnthropic offers a course titled \"Introduction to Model Context Protocol\" that focuses on building both MCP servers and clients from scratch using the Python SDK. You can find more information and the open-source SDK on the Model Context Protocol website and GitHub repository, as mentioned in Anthropic\\'s announcement.', 'extras': {'signature': 'CsoGAXLI2nzNjx4r53Hst+RWLTKjNI5EyOT8ThyFzPvuYVEFcCA5usViLwsA9Q0jEXMTl3C0wCqy+aLkW+47GfwiOJILGJKj+8HI/VUbcDzaNlUpTYPgdqEk5OSdJUOiGcIHVRZ8Ywcav5cGmDsTyWqi1gGQ+QsvXPutzk6WFW/um2zafl5ec1cvwqMLr8bz04etrrFIuab/VP/gJR8xLxzHCJXrclsm0kVQrE6qYRyhC1320cnv8B2D5xwD/jbHmU1fVFqha57oSxduU/n4ensDZG5/Ej3abXZrUlcN1HjQ7oPNF5gW90g8ML5jKwYoJcAvugL8VAiJNX/Q7+3mkd74HDywGZUIX1gLVkBYA++XCrTgz4CSDBZB8LGLVssRqFJnDUN6Zt8YmTRA7dPr0t5xtRcWJddxNSxd1FyoUG1ZRitH9MaZ1ceqU/3i8BMoy8Zl+AM4vvotZQv/Rbt+NgDSAYgmOz5uj+eDKZcvzT4d92tFLx1iiwPNYJ7QvFToF3kOWYK8nA38XNCEZO0bxAuVsfoq+0+VOi7aVqwiZuyOAHTRtYuEO+UJx0JGH4j8vqDmWshpNScHhFLn1O2Dq7xjtWI1bchCl4ur9CVrt0Ab9nLpZiNBQ9Gfc3HQgPUwB0A+xpMLr5PC/jJyN3LRWSVDTrE8c/RM8ez0PDbsugXZ+pqPyF2qf5dwcPuy6VmyrIO8Ts/XAcRE1XSkfspnsuw07MgTsi1dEo/FpV9QdEAoR2cVcgU9EyTl+GguJEJ0lux8xxNtAO9xjLBU9v/6fxkUkvZTG9mKdwOurn7sH1KiPF7eQcAITUd4u2gjfJbyHXl1/A3y4nkppTZMLxbQxr6XVIfMRuNIIAZ3qqg3oMfvN3cxbbQ0i8j69kgh00/mWhc6tmBfUednBzRxDf+hsvjzqZCHpMHkMToIYdYtIdcKhFDmc4d1f5pIQaIUfmzGyXptAL2t7GVJoBU092NDa8DbLdja+IbdKpy2wYkhOcQCdWLZiXJ1VwrXyeH5ERWQ0S3YznJC4oGXI0xTmm+P7Thh9n2M64D/ttDL8pWYdOixjTBZVq0grR9FeArrofs3BruqtWDwUAni8u+A004YVPyQHfUeZKsk8/ylqFU='}}], additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--b4fc82c8-30d2-407b-a0ed-5818f5167089-0', usage_metadata={'input_tokens': 7213, 'output_tokens': 385, 'total_tokens': 7598, 'input_token_details': {'cache_read': 4799}, 'output_token_details': {'reasoning': 156}})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepagents import create_deep_agent\n",
    "\n",
    "# System prompt to steer the agent to be an expert researcher\n",
    "research_instructions = \"\"\"You are an expert researcher. Your job is to conduct thorough research and then write a polished report.\n",
    "\n",
    "You have also access to an internet search tool as your primary means of gathering information for this task.\n",
    "\n",
    "## `internet_search`\n",
    "\n",
    "Use this to run an internet search for a given query. You can specify the max number of results to return, the topic, and whether raw content should be included.\n",
    "Think step-by-step and make a plan and todos how to generate searchterms and how you write and finanlize the report.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    tools=[internet_search],\n",
    "    # system_prompt=research_instructions,\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"How to build a model context protocol server as proposed by Anthropic?\"}]})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94533f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df897c73bc4ded92914308e977bc3a62\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "OWM_API_KEY = os.environ.get(\"OPENWEATHERMAP_API_KEY\")\n",
    "print(OWM_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d818d8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=[{'type': 'text', 'text': 'The Model Context Protocol (MCP) is an open standard and open-source framework introduced by Anthropic to standardize how AI systems, like large language models (LLMs), integrate and share data with external tools, systems, and data sources. It allows AI assistants to access and interact with content repositories, business management tools, and development environments.\\n\\nTo build a Model Context Protocol server, you would typically use the Python SDK provided by Anthropic. The protocol revolves around three core primitives:\\n\\n*   **Tools:** These are actions or functions that an AI model can invoke in external systems.\\n*   **Resources:** These represent data or information that the AI model can access and utilize from external sources.\\n*   **Prompts:** These are the instructions or queries given to the AI model, which can leverage the available tools and resources.\\n\\nAnthropic offers a course titled \"Introduction to Model Context Protocol\" that focuses on building both MCP servers and clients from scratch using the Python SDK. You can find more information and the open-source SDK on the Model Context Protocol website and GitHub repository, as mentioned in Anthropic\\'s announcement.', 'extras': {'signature': 'CsoGAXLI2nzNjx4r53Hst+RWLTKjNI5EyOT8ThyFzPvuYVEFcCA5usViLwsA9Q0jEXMTl3C0wCqy+aLkW+47GfwiOJILGJKj+8HI/VUbcDzaNlUpTYPgdqEk5OSdJUOiGcIHVRZ8Ywcav5cGmDsTyWqi1gGQ+QsvXPutzk6WFW/um2zafl5ec1cvwqMLr8bz04etrrFIuab/VP/gJR8xLxzHCJXrclsm0kVQrE6qYRyhC1320cnv8B2D5xwD/jbHmU1fVFqha57oSxduU/n4ensDZG5/Ej3abXZrUlcN1HjQ7oPNF5gW90g8ML5jKwYoJcAvugL8VAiJNX/Q7+3mkd74HDywGZUIX1gLVkBYA++XCrTgz4CSDBZB8LGLVssRqFJnDUN6Zt8YmTRA7dPr0t5xtRcWJddxNSxd1FyoUG1ZRitH9MaZ1ceqU/3i8BMoy8Zl+AM4vvotZQv/Rbt+NgDSAYgmOz5uj+eDKZcvzT4d92tFLx1iiwPNYJ7QvFToF3kOWYK8nA38XNCEZO0bxAuVsfoq+0+VOi7aVqwiZuyOAHTRtYuEO+UJx0JGH4j8vqDmWshpNScHhFLn1O2Dq7xjtWI1bchCl4ur9CVrt0Ab9nLpZiNBQ9Gfc3HQgPUwB0A+xpMLr5PC/jJyN3LRWSVDTrE8c/RM8ez0PDbsugXZ+pqPyF2qf5dwcPuy6VmyrIO8Ts/XAcRE1XSkfspnsuw07MgTsi1dEo/FpV9QdEAoR2cVcgU9EyTl+GguJEJ0lux8xxNtAO9xjLBU9v/6fxkUkvZTG9mKdwOurn7sH1KiPF7eQcAITUd4u2gjfJbyHXl1/A3y4nkppTZMLxbQxr6XVIfMRuNIIAZ3qqg3oMfvN3cxbbQ0i8j69kgh00/mWhc6tmBfUednBzRxDf+hsvjzqZCHpMHkMToIYdYtIdcKhFDmc4d1f5pIQaIUfmzGyXptAL2t7GVJoBU092NDa8DbLdja+IbdKpy2wYkhOcQCdWLZiXJ1VwrXyeH5ERWQ0S3YznJC4oGXI0xTmm+P7Thh9n2M64D/ttDL8pWYdOixjTBZVq0grR9FeArrofs3BruqtWDwUAni8u+A004YVPyQHfUeZKsk8/ylqFU='}}], additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--b4fc82c8-30d2-407b-a0ed-5818f5167089-0', usage_metadata={'input_tokens': 7213, 'output_tokens': 385, 'total_tokens': 7598, 'input_token_details': {'cache_read': 4799}, 'output_token_details': {'reasoning': 156}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last_message_text = result['messages'][-1].content[0]['text']\n",
    "# last_message_text = last_message.content[0]['text']\n",
    "# display_wrapped_text(last_message_text)\n",
    "result['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eb16f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='How to build a model context protocol server as proposed by Anthropic?' additional_kwargs={} response_metadata={} id='097d02fb-f048-4e1e-adbd-962baa90b7e2'\n",
      "content='' additional_kwargs={'function_call': {'name': 'internet_search', 'arguments': '{\"query\": \"Anthropic model context protocol server\"}'}, '__gemini_function_call_thought_signatures__': {'f779818b-43de-4de4-ad04-4d3ed3988ed2': 'CuwBAXLI2ny7xwaog+ns1D/Uy5AU2vmbdXqDOinyZgZ3nUrcZNJ/x5ma/9CXV5dJON46MzuLrHeheVvUic8RHj2TedoF9qvi+g5rMKBJka29feJcJWnVKtUQ/7PF0rLQDAx2wGPCPM8Me3qomBnZt45tDtgyi5dmrwysCPptU+B0Qvy2X1m2hpUk0PAhP8SvpKCHijKlpcMuSwbArhdoq+kmu76WYUcIkjHinfZdnduMiFWO9zNg57wLSF/3akATEzscZzYObBhTw5BaaEWAObYJBdWyFevhQD7vjWXNKBkqwgWNuY06kebH6HP6iN8='}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--e959a5a6-55a6-48f5-9231-67a2f24d65f0-0' tool_calls=[{'name': 'internet_search', 'args': {'query': 'Anthropic model context protocol server'}, 'id': 'f779818b-43de-4de4-ad04-4d3ed3988ed2', 'type': 'tool_call'}] usage_metadata={'input_tokens': 4997, 'output_tokens': 60, 'total_tokens': 5057, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 40}}\n",
      "content='{\"query\": \"Anthropic model context protocol server\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://en.wikipedia.org/wiki/Model_Context_Protocol\", \"title\": \"Model Context Protocol - Wikipedia\", \"content\": \"The **Model Context Protocol** (**MCP**) is an open standard and open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP was announced by Anthropic in November 2024 as an open standard for connecting AI assistants to data systems such as content repositories, business management tools, and development environments. MCP defines a standardized framework for integrating AI systems with external data sources and tools. The protocol also supports bidirectional connections between data sources and AI tools.*[non-primary source needed*]. Integrated development environments (IDEs), coding platforms such as Replit, and code intelligence tools like Sourcegraph have adopted MCP to grant AI coding assistants real-time access to project context. \\\\\"Anthropic releases Model Context Protocol to standardize AI-data integration\\\\\". \\\\\"OpenAI adopts rival Anthropic\\'s standard for connecting AI models to data\\\\\". \\\\\"Model Context Protocol (MCP): Integrating Azure OpenAI for Enhanced Tool Integration and Prompting\\\\\".\", \"score\": 0.90810597, \"raw_content\": null}, {\"url\": \"https://www.merge.dev/blog/model-context-protocol\", \"title\": \"What you need to know about the Model Context Protocol (MCP)\", \"content\": \"Anthropic\\'s recently-released Model Context Protocol (MCP) reaffirms that large language models (LLMs) need customer data to provide reliable, personalized, and useful outputs. To help all of the AI chatbot’s underlying LLMs get the context needed to understand tasks and perform them, you can integrate the LLMs with the relevant support applications via the MCP protocol\\xa0and give the LLMs access to read and write capabilities across these connected systems. *Learn about* *project management MCP servers* *you can connect to with Merge Agent Handler:*. To power this, you can integrate your AI agent’s LLM with your customers’ applicant tracking systems (ATSs) through MCP. Unified API solutions, which let you add hundreds of integrations to your product through a single, aggregated API, complement MCP for any integration, whether that’s managing authentication, data normalization, security, or sync speeds. Unified API solutions can offer a full suite of integration observability features to help your customer-facing team manage any of your MCP-based integrations.\", \"score\": 0.8443195, \"raw_content\": null}, {\"url\": \"https://anthropic.skilljar.com/introduction-to-model-context-protocol\", \"title\": \"Introduction to Model Context Protocol - Anthropic Courses\", \"content\": \"## Learn to build Model Context Protocol servers and clients from scratch using Python. This course provides comprehensive coverage of the Model Context Protocol (MCP), focusing on building both MCP servers and clients using the Python SDK. You\\'ll learn about MCP\\'s three core primitives—tools, resources, and prompts—and understand how they integrate with Claude AI to create powerful applications without writing extensive integration code. This course provides comprehensive coverage of the Model Context Protocol (MCP), focusing on building both MCP servers and clients using the Python SDK. You\\'ll learn about MCP\\'s three core primitives—tools, resources, and prompts—and understand how they integrate with Claude AI to create powerful applications without writing extensive integration code. Skilljar only tracks your learning progress within this course platform, while your Anthropic account manages your access to the Anthropic Console and/or Claude AI services. Your learning data is stored on secure servers with appropriate access controls.\", \"score\": 0.8342047, \"raw_content\": null}, {\"url\": \"https://www.atlassian.com/blog/announcements/remote-mcp-server\", \"title\": \"Introducing Atlassian\\'s Remote Model Context Protocol (MCP) Server\", \"content\": \"Bringing Atlassian’s enterprise knowledge to more AI tools — starting with Jira and Confluence wherever you use Anthropic’s Claude. We’re bringing Atlassian’s structured knowledge into more AI tools thanks to MCP, which provides a universal, open standard for connecting AI systems with data sources. With our Remote MCP Server, you can summarize work, create issues or pages, and perform multi-step actions, all while keeping data secure and within permissioned boundaries. We’re building our Remote MCP server with industry leaders who share our commitment to security and innovation. With Atlassian’s Remote MCP Server, teams can access their Jira tickets and Confluence documentation conveniently within Claude. To further ensure your enterprise data stays secure while enabling powerful integrations, our server will soon integrate with additional trusted and thoughtfully curated AI partners that support remote MCP. In addition to teaming up with Anthropic, we’re using Cloudflare’s Agents SDK to build our Remote MCP Server. You can try the Atlassian Remote MCP Server *today* in beta with Claude in Jira and Confluence.\", \"score\": 0.8029425, \"raw_content\": null}, {\"url\": \"https://www.anthropic.com/news/model-context-protocol\", \"title\": \"Introducing the Model Context Protocol - Anthropic\", \"content\": \"[Skip to main content](https://www.anthropic.com/news/model-context-protocol#main-content)[Skip to footer](https://www.anthropic.com/news/model-context-protocol#footer). *   [Research](https://www.anthropic.com/research). *   [News](https://www.anthropic.com/news). Today, we\\'re open-sourcing the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), a new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. *   The Model Context Protocol [specification and SDKs](https://github.com/modelcontextprotocol). [Read more](https://www.anthropic.com/news/compliance-framework-SB53). [Read more](https://www.anthropic.com/news/protecting-well-being-of-users). *   [Claude](https://claude.com/product/overview). *   [Claude Code](https://claude.com/product/claude-code). *   [Claude in Chrome](https://claude.com/chrome). *   [Skills](https://www.claude.com/skills). *   [Max plan](https://claude.com/pricing/max). *   [Team plan](https://claude.com/pricing/team). *   [Enterprise plan](https://claude.com/pricing/enterprise). *   [Pricing](https://claude.com/pricing). *   [Opus](https://www.anthropic.com/claude/opus). *   [Sonnet](https://www.anthropic.com/claude/sonnet). *   [Haiku](https://www.anthropic.com/claude/haiku). *   [AI agents](https://claude.com/solutions/agents). *   [Code modernization](https://claude.com/solutions/code-modernization). *   [Coding](https://claude.com/solutions/coding). *   [Customer support](https://claude.com/solutions/customer-support). *   [Education](https://claude.com/solutions/education). *   [Financial services](https://claude.com/solutions/financial-services). *   [Government](https://claude.com/solutions/government). *   [Life sciences](https://claude.com/solutions/life-sciences). *   [Nonprofits](https://claude.com/solutions/nonprofits). *   [Overview](https://claude.com/platform/api). *   [Developer docs](https://platform.claude.com/docs). *   [Pricing](https://claude.com/pricing#api). *   [Regional Compliance](https://claude.com/regional-compliance). *   [Google Cloud’s Vertex AI](https://claude.com/partners/google-cloud-vertex-ai). *   [Blog](https://claude.com/blog). *   [Claude partner network](https://claude.com/partners). *   [Connectors](https://claude.com/connectors). *   [Courses](https://www.anthropic.com/learn). *   [Customer stories](https://claude.com/customers). *   [Engineering at Anthropic](https://www.anthropic.com/engineering). *   [Events](https://www.anthropic.com/events). *   [Service partners](https://claude.com/partners/services). *   [Tutorials](https://claude.com/resources/tutorials). *   [Anthropic](https://www.anthropic.com/company). *   [Careers](https://www.anthropic.com/careers). *   [Research](https://www.anthropic.com/research). *   [News](https://www.anthropic.com/news). *   [Transparency](https://www.anthropic.com/transparency). *   [Availability](https://www.anthropic.com/supported-countries). *   [Support center](https://support.claude.com/en/). *   [Usage policy](https://www.anthropic.com/legal/aup). *   [](https://www.youtube.com/@anthropic-ai).\", \"score\": 0.77751994, \"raw_content\": null}], \"response_time\": 0.63, \"request_id\": \"f3d65769-63c0-4de6-b8fd-17ec7d61ac63\"}' name='internet_search' id='8fc72d1c-ce81-4e05-8aa7-3f19c9c67af2' tool_call_id='f779818b-43de-4de4-ad04-4d3ed3988ed2'\n",
      "content=[{'type': 'text', 'text': 'The Model Context Protocol (MCP) is an open standard and open-source framework introduced by Anthropic to standardize how AI systems, like large language models (LLMs), integrate and share data with external tools, systems, and data sources. It allows AI assistants to access and interact with content repositories, business management tools, and development environments.\\n\\nTo build a Model Context Protocol server, you would typically use the Python SDK provided by Anthropic. The protocol revolves around three core primitives:\\n\\n*   **Tools:** These are actions or functions that an AI model can invoke in external systems.\\n*   **Resources:** These represent data or information that the AI model can access and utilize from external sources.\\n*   **Prompts:** These are the instructions or queries given to the AI model, which can leverage the available tools and resources.\\n\\nAnthropic offers a course titled \"Introduction to Model Context Protocol\" that focuses on building both MCP servers and clients from scratch using the Python SDK. You can find more information and the open-source SDK on the Model Context Protocol website and GitHub repository, as mentioned in Anthropic\\'s announcement.', 'extras': {'signature': 'CsoGAXLI2nzNjx4r53Hst+RWLTKjNI5EyOT8ThyFzPvuYVEFcCA5usViLwsA9Q0jEXMTl3C0wCqy+aLkW+47GfwiOJILGJKj+8HI/VUbcDzaNlUpTYPgdqEk5OSdJUOiGcIHVRZ8Ywcav5cGmDsTyWqi1gGQ+QsvXPutzk6WFW/um2zafl5ec1cvwqMLr8bz04etrrFIuab/VP/gJR8xLxzHCJXrclsm0kVQrE6qYRyhC1320cnv8B2D5xwD/jbHmU1fVFqha57oSxduU/n4ensDZG5/Ej3abXZrUlcN1HjQ7oPNF5gW90g8ML5jKwYoJcAvugL8VAiJNX/Q7+3mkd74HDywGZUIX1gLVkBYA++XCrTgz4CSDBZB8LGLVssRqFJnDUN6Zt8YmTRA7dPr0t5xtRcWJddxNSxd1FyoUG1ZRitH9MaZ1ceqU/3i8BMoy8Zl+AM4vvotZQv/Rbt+NgDSAYgmOz5uj+eDKZcvzT4d92tFLx1iiwPNYJ7QvFToF3kOWYK8nA38XNCEZO0bxAuVsfoq+0+VOi7aVqwiZuyOAHTRtYuEO+UJx0JGH4j8vqDmWshpNScHhFLn1O2Dq7xjtWI1bchCl4ur9CVrt0Ab9nLpZiNBQ9Gfc3HQgPUwB0A+xpMLr5PC/jJyN3LRWSVDTrE8c/RM8ez0PDbsugXZ+pqPyF2qf5dwcPuy6VmyrIO8Ts/XAcRE1XSkfspnsuw07MgTsi1dEo/FpV9QdEAoR2cVcgU9EyTl+GguJEJ0lux8xxNtAO9xjLBU9v/6fxkUkvZTG9mKdwOurn7sH1KiPF7eQcAITUd4u2gjfJbyHXl1/A3y4nkppTZMLxbQxr6XVIfMRuNIIAZ3qqg3oMfvN3cxbbQ0i8j69kgh00/mWhc6tmBfUednBzRxDf+hsvjzqZCHpMHkMToIYdYtIdcKhFDmc4d1f5pIQaIUfmzGyXptAL2t7GVJoBU092NDa8DbLdja+IbdKpy2wYkhOcQCdWLZiXJ1VwrXyeH5ERWQ0S3YznJC4oGXI0xTmm+P7Thh9n2M64D/ttDL8pWYdOixjTBZVq0grR9FeArrofs3BruqtWDwUAni8u+A004YVPyQHfUeZKsk8/ylqFU='}}] additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--b4fc82c8-30d2-407b-a0ed-5818f5167089-0' usage_metadata={'input_tokens': 7213, 'output_tokens': 385, 'total_tokens': 7598, 'input_token_details': {'cache_read': 4799}, 'output_token_details': {'reasoning': 156}}\n"
     ]
    }
   ],
   "source": [
    "for message in result['messages']:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1dd4750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--ed3eb533-5a52-47b6-9b3b-3562ecf1876c-0', usage_metadata={'input_tokens': 21, 'output_tokens': 7, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1181cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"I need you to analyze this dataset using Python REPL:\\nData: {'sales': [120, 150, 180, 200, 165, 190, 210, 175, 195, 220], \\n       'months': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct']}\\n\\nTasks:\\n1. Calculate total sales\\n2. Find the month with highest sales\\n3. Calculate average monthly sales\\n4. Find months where sales exceeded the average\\n5. Calculate month-over-month growth percentage for each month\\n6. Display results in a formatted report\\n\\nUse Python REPL economically to perform all calculations in one program and show your work.\", additional_kwargs={}, response_metadata={}, id='0e4f02cd-cb0c-4393-8dbf-afae03f5ed63'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl', 'arguments': '{\"__arg1\": \"\\\\ndata = {\\'sales\\': [120, 150, 180, 200, 165, 190, 210, 175, 195, 220], \\\\n        \\'months\\': [\\'Jan\\', \\'Feb\\', \\'Mar\\', \\'Apr\\', \\'May\\', \\'Jun\\', \\'Jul\\', \\'Aug\\', \\'Sep\\', \\'Oct\\']}\\\\n\\\\nsales = data[\\'sales\\']\\\\nmonths = data[\\'months\\']\\\\n\\\\n# 1. Calculate total sales\\\\ntotal_sales = sum(sales)\\\\n\\\\n# 2. Find the month with highest sales\\\\nmax_sales = max(sales)\\\\nmonth_highest_sales = months[sales.index(max_sales)]\\\\n\\\\n# 3. Calculate average monthly sales\\\\naverage_sales = total_sales / len(sales)\\\\n\\\\n# 4. Find months where sales exceeded the average\\\\nmonths_above_average = [months[i] for i, s in enumerate(sales) if s > average_sales]\\\\n\\\\n# 5. Calculate month-over-month growth percentage for each month\\\\ngrowth_percentages = []\\\\nfor i in range(1, len(sales)):\\\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\\\n    growth_percentages.append(f\\\\\"{growth:.2f}%\\\\\")\\\\n\\\\n# 6. Display results in a formatted report\\\\nprint(\\\\\"--- Sales Analysis Report ---\\\\\")\\\\nprint(f\\\\\"Total Sales: ${total_sales}\\\\\")\\\\nprint(f\\\\\"Month with Highest Sales: {month_highest_sales} (${max_sales})\\\\\")\\\\nprint(f\\\\\"Average Monthly Sales: ${average_sales:.2f}\\\\\")\\\\nprint(\\\\\"Months where sales exceeded the average:\\\\\", \\\\\", \\\\\".join(months_above_average))\\\\nprint(\\\\\"Month-over-month Growth Percentage:\\\\\")\\\\nfor i, growth in enumerate(growth_percentages):\\\\n    print(f\\\\\"  {months[i+1]}: {growth}\\\\\")\\\\n\"}'}, '__gemini_function_call_thought_signatures__': {'14b6ef37-cb31-4b7e-b264-4a9aa075b647': 'CqAFAXLI2nx7E/o/6wxXK/IOi/zDJ7A1ZmDmMS7QM2qYHIc4dXeaOtRzBL5479dqYKanw18C5WNGVvR5SnJUlGJ2qshYqc4L/I3PEzW72CFnHD4UbLTfN6RRW0OlBcBzhI16a1vXu3PkbkrkAPMtDe56R3TYCjmMsLCTcHJb2PuhSHcCrsibZ6RoAjUFRK2Rka+NtvxxwGHDsMK7L6fFgHC8kMTZSQEBsRqTLagBpCsq6fAUPpcLjBbpW4BNi9MrPuZ697QnN7UwrB6TbBWh2pSDRK/WJ2CadDHd0Ix9QHE3/pKDTVqGKb7PiG6TAYqonFCqsgD6W/H1ynYneapJBaFvPJCbzoDBXNkgRlo0K1qeOiIZE9Dm90geHxCiFhjZD2nbdk2fQ9Lrt01roUK/RWHpeivWP99bpsZF0TQVrajkNgZg6yxwrkqDEP4gd6IdidWKPoOTsZJfxh756RofRIhMpaXtbKQuoMhepveB6fK+ZaULgnMcKouRiTMkzNNKZ72Su81fzU41dYwPA2mXdSu71pGAmg+IFKbaHzAL2zKglCtFbRfMFEiMjzceBoSQNbJrpvGRf7i6XaGU4E6lZTYnbo36S9YLrv39M3gUqoGYtPAJrzY/qM0ZSMV3dmePaCN9kmo1ugQyE9QeeXD2JG0m0wXuF/Z0MjzwMLb0IFMi0FrvpXqR6my6bI5tAinkRFXT7SUil3sUzKdnrm97YRGI09//FNOOxwyZUoeWOa5nXsKcx31utaGCrzSAqZxgfBV1a8NTnFSKoc19a8JV+ufU0nnfn9IVcuqocLb1m1lB5v2S1aYAJepFkxMYqdmh1NQ+sOrx12vv6BfHZmFz1NAzD4ZesirHfv/Px8VGWzkB1CrIJoyiQUOLyLBw6mcYprUP'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--47f4d2ac-378e-4beb-b0bf-c37b95e05972-0', tool_calls=[{'name': 'python_repl', 'args': {'__arg1': '\\ndata = {\\'sales\\': [120, 150, 180, 200, 165, 190, 210, 175, 195, 220], \\n        \\'months\\': [\\'Jan\\', \\'Feb\\', \\'Mar\\', \\'Apr\\', \\'May\\', \\'Jun\\', \\'Jul\\', \\'Aug\\', \\'Sep\\', \\'Oct\\']}\\n\\nsales = data[\\'sales\\']\\nmonths = data[\\'months\\']\\n\\n# 1. Calculate total sales\\ntotal_sales = sum(sales)\\n\\n# 2. Find the month with highest sales\\nmax_sales = max(sales)\\nmonth_highest_sales = months[sales.index(max_sales)]\\n\\n# 3. Calculate average monthly sales\\naverage_sales = total_sales / len(sales)\\n\\n# 4. Find months where sales exceeded the average\\nmonths_above_average = [months[i] for i, s in enumerate(sales) if s > average_sales]\\n\\n# 5. Calculate month-over-month growth percentage for each month\\ngrowth_percentages = []\\nfor i in range(1, len(sales)):\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\n    growth_percentages.append(f\"{growth:.2f}%\")\\n\\n# 6. Display results in a formatted report\\nprint(\"--- Sales Analysis Report ---\")\\nprint(f\"Total Sales: ${total_sales}\")\\nprint(f\"Month with Highest Sales: {month_highest_sales} (${max_sales})\")\\nprint(f\"Average Monthly Sales: ${average_sales:.2f}\")\\nprint(\"Months where sales exceeded the average:\", \", \".join(months_above_average))\\nprint(\"Month-over-month Growth Percentage:\")\\nfor i, growth in enumerate(growth_percentages):\\n    print(f\"  {months[i+1]}: {growth}\")\\n'}, 'id': '14b6ef37-cb31-4b7e-b264-4a9aa075b647', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5239, 'output_tokens': 662, 'total_tokens': 5901, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 148}}),\n",
       "  ToolMessage(content='NameError(\"name \\'average_sales\\' is not defined\")', name='python_repl', id='d39b121f-8dc3-4bb2-8d73-00addffc7f1e', tool_call_id='14b6ef37-cb31-4b7e-b264-4a9aa075b647'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl', 'arguments': '{\"__arg1\": \"\\\\ndata = {\\'sales\\': [120, 150, 180, 200, 165, 190, 210, 175, 195, 220], \\\\n        \\'months\\': [\\'Jan\\', \\'Feb\\', \\'Mar\\', \\'Apr\\', \\'May\\', \\'Jun\\', \\'Jul\\', \\'Aug\\', \\'Sep\\', \\'Oct\\']}\\\\n\\\\nsales = data[\\'sales\\']\\\\nmonths = data[\\'months\\']\\\\n\\\\n# 1. Calculate total sales\\\\ntotal_sales = sum(sales)\\\\n\\\\n# 2. Find the month with highest sales\\\\nmax_sales = max(sales)\\\\nmonth_highest_sales = months[sales.index(max_sales)]\\\\n\\\\n# 3. Calculate average monthly sales\\\\naverage_sales = total_sales / len(sales)\\\\n\\\\n# 4. Find months where sales exceeded the average\\\\nmonths_above_average = [months[i] for i, s in enumerate(sales) if s > average_sales]\\\\n\\\\n# 5. Calculate month-over-month growth percentage for each month\\\\ngrowth_percentages = []\\\\nfor i in range(1, len(sales)):\\\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\\\n    growth_percentages.append(f\\\\\"{growth:.2f}%\\\\\")\\\\n\\\\n# 6. Display results in a formatted report\\\\nprint(\\\\\"--- Sales Analysis Report ---\\\\\")\\\\nprint(f\\\\\"Total Sales: ${total_sales}\\\\\")\\\\nprint(f\\\\\"Month with Highest Sales: {month_highest_sales} (${max_sales})\\\\\")\\\\nprint(f\\\\\"Average Monthly Sales: ${average_sales:.2f}\\\\\")\\\\nprint(\\\\\"Months where sales exceeded the average:\\\\\", \\\\\", \\\\\".join(months_above_average))\\\\nprint(\\\\\"Month-over-month Growth Percentage:\\\\\")\\\\nfor i, growth in enumerate(growth_percentages):\\\\n    print(f\\\\\"  {months[i+1]}: {growth}\\\\\")\\\\n\"}'}, '__gemini_function_call_thought_signatures__': {'07499c30-bfeb-415a-8c07-57187f189b78': 'CtsHAXLI2nwuy6M8vxAKBT0WWd6X2DwanpYyON3JEZfsxTqGgS70EQISYG8AemqK55G1tY9oIex81hdq86tv9C3J9NPVpi2JsexG4ja+Jzq7D1YGHAj9uPTJJOEsVpPcq2dd1a0hzoQpBiWuIyI7eAh97xKXrZCFErrQgakeuLBfJPyQW8kXO+5wRtNitfm48gBhQQ1p/C9A+0EraOuHI8iBb5BlcLXXM8Fx3dBuV/rXbUD9RE+UTtqOZLzb6wYYVi0zd2a+q30N5KGSKgxX+/9BCtlNH4SRS/9T9Oh+fK/oXQp2mGLj/dfzrE7u5tR92ZiteB6PATvXn5vj6/S9bulkzlZr7ciuj+mj0u0oF0H5JbNYADYiPMrVLuUShe0IecA7Mr/2t5gXi8kzMoUXu7JGNWdfT4WtFa9Bo18r6Ix6ZkMdCV47O3ODh13S/TE54DUb5xrkoA3I35KWUXIELMwZf8I5BmM1DzatcSKNYg57fCrpzZeDDs7Xi7ujxzkBBsThRj9RiXTgQqvB5QidtpAWpPIOyGWHf/8sNiTn1z1cW4QcJ56o3btl9jouA9qbviJOw5erx51eszoY+a7Ssjrvhgi1pKHhWYZ8D8f2ZhdNmWkAker+5jnctgc0zEODeKHjB2qPaCXtP1rCMgQ5zZNW8bOy4P+mIZAnnTO7OIeo+BGwA6C3sk2ySucU3bkjrqm6Whb4j4pOlL2pqwOD9OVpk6j3K1nzoOhkA7qrZp9e5QrRlh4UAApoG3ZtqaCV0lYAS+RcnETm04tYn/RkRh8Xu2Rgb8jHqnhE497DOc+2L8izmuxvFR3AYu/P+USc2IHB4ZbJCVMLzr/4RGPxoghYcMLiCUf+r/BWEOIqfoI6xUsXUhK3/UZJAExiKozaB04+rM2jBPyeNNNgj7vbjolKVRMxlCz4TpmwdsF9XMdu+ip1CV/jPSao5kdqGQZr76jN7vwe5jp74CuEnrlCI90cBeBWyNC6JiEV5y8oF44898zkBZjoec0VjohhrpP2xfPusN2601LViCRIshHbOW20BGM7zrDGnWTqce0A/5SX45QcoiBm7QGmljU3zCJ17w4N0D7NvaOznmpIMu6bJ5QVn8OGS+IL5lDlZxXgsHWNKedxjWNMGyLIjAv/mcQq2it4CL9NB994oEWolAHdWBNNjTRLtoD9FASMAyGNek6S7E+LV7dluYcjsK6QQobUKCp9Qelo3kXG9PIG9FV6m+mwm435ONHkfFn2jq7mxiZ6/je4oIDXC2hlXCF5eTFwvtV+z6grWu4jmJIeZGR0xJt8GtWEBC98RsAzERI4'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--9f485fa7-04c9-431b-8a9b-77c2c233c9a6-0', tool_calls=[{'name': 'python_repl', 'args': {'__arg1': '\\ndata = {\\'sales\\': [120, 150, 180, 200, 165, 190, 210, 175, 195, 220], \\n        \\'months\\': [\\'Jan\\', \\'Feb\\', \\'Mar\\', \\'Apr\\', \\'May\\', \\'Jun\\', \\'Jul\\', \\'Aug\\', \\'Sep\\', \\'Oct\\']}\\n\\nsales = data[\\'sales\\']\\nmonths = data[\\'months\\']\\n\\n# 1. Calculate total sales\\ntotal_sales = sum(sales)\\n\\n# 2. Find the month with highest sales\\nmax_sales = max(sales)\\nmonth_highest_sales = months[sales.index(max_sales)]\\n\\n# 3. Calculate average monthly sales\\naverage_sales = total_sales / len(sales)\\n\\n# 4. Find months where sales exceeded the average\\nmonths_above_average = [months[i] for i, s in enumerate(sales) if s > average_sales]\\n\\n# 5. Calculate month-over-month growth percentage for each month\\ngrowth_percentages = []\\nfor i in range(1, len(sales)):\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\n    growth_percentages.append(f\"{growth:.2f}%\")\\n\\n# 6. Display results in a formatted report\\nprint(\"--- Sales Analysis Report ---\")\\nprint(f\"Total Sales: ${total_sales}\")\\nprint(f\"Month with Highest Sales: {month_highest_sales} (${max_sales})\")\\nprint(f\"Average Monthly Sales: ${average_sales:.2f}\")\\nprint(\"Months where sales exceeded the average:\", \", \".join(months_above_average))\\nprint(\"Month-over-month Growth Percentage:\")\\nfor i, growth in enumerate(growth_percentages):\\n    print(f\"  {months[i+1]}: {growth}\")\\n'}, 'id': '07499c30-bfeb-415a-8c07-57187f189b78', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5781, 'output_tokens': 755, 'total_tokens': 6536, 'input_token_details': {'cache_read': 4646}, 'output_token_details': {'reasoning': 241}}),\n",
       "  ToolMessage(content='NameError(\"name \\'average_sales\\' is not defined\")', name='python_repl', id='ef022d72-c8a3-4aec-b40e-403bf03ecd57', tool_call_id='07499c30-bfeb-415a-8c07-57187f189b78'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl', 'arguments': '{\"__arg1\": \"\\\\ndata = {\\'sales\\': [120, 150, 180, 200, 165, 190, 210, 175, 195, 220], \\\\n        \\'months\\': [\\'Jan\\', \\'Feb\\', \\'Mar\\', \\'Apr\\', \\'May\\', \\'Jun\\', \\'Jul\\', \\'Aug\\', \\'Sep\\', \\'Oct\\']}\\\\n\\\\nsales = data[\\'sales\\']\\\\nmonths = data[\\'months\\']\\\\n\\\\n# 1. Calculate total sales\\\\ntotal_sales = sum(sales)\\\\n\\\\n# 2. Find the month with highest sales\\\\nmax_sales = max(sales)\\\\nmonth_highest_sales = months[sales.index(max_sales)]\\\\n\\\\n# 3. Calculate average monthly sales\\\\naverage_sales = total_sales / len(sales)\\\\nprint(f\\\\\"DEBUG: average_sales = {average_sales}\\\\\") # Debug print\\\\n\\\\n# 4. Find months where sales exceeded the average\\\\nmonths_above_average = []\\\\nfor i, s in enumerate(sales):\\\\n    if s > average_sales:\\\\n        months_above_average.append(months[i])\\\\n\\\\n# 5. Calculate month-over-month growth percentage for each month\\\\ngrowth_percentages = []\\\\nfor i in range(1, len(sales)):\\\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\\\n    growth_percentages.append(f\\\\\"{growth:.2f}%\\\\\")\\\\n\\\\n# 6. Display results in a formatted report\\\\nprint(\\\\\"--- Sales Analysis Report ---\\\\\")\\\\nprint(f\\\\\"Total Sales: ${total_sales}\\\\\")\\\\nprint(f\\\\\"Month with Highest Sales: {month_highest_sales} (${max_sales})\\\\\")\\\\nprint(f\\\\\"Average Monthly Sales: ${average_sales:.2f}\\\\\")\\\\nprint(\\\\\"Months where sales exceeded the average:\\\\\", \\\\\", \\\\\".join(months_above_average))\\\\nprint(\\\\\"Month-over-month Growth Percentage:\\\\\")\\\\nfor i, growth in enumerate(growth_percentages):\\\\n    print(f\\\\\"  {months[i+1]}: {growth}\\\\\")\\\\n\"}'}, '__gemini_function_call_thought_signatures__': {'a75e8154-3f86-4d6d-8f5a-8b92ab3cd7b2': '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'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--7bb4509a-6d33-4337-a8ea-470dee2bfb3e-0', tool_calls=[{'name': 'python_repl', 'args': {'__arg1': '\\ndata = {\\'sales\\': [120, 150, 180, 200, 165, 190, 210, 175, 195, 220], \\n        \\'months\\': [\\'Jan\\', \\'Feb\\', \\'Mar\\', \\'Apr\\', \\'May\\', \\'Jun\\', \\'Jul\\', \\'Aug\\', \\'Sep\\', \\'Oct\\']}\\n\\nsales = data[\\'sales\\']\\nmonths = data[\\'months\\']\\n\\n# 1. Calculate total sales\\ntotal_sales = sum(sales)\\n\\n# 2. Find the month with highest sales\\nmax_sales = max(sales)\\nmonth_highest_sales = months[sales.index(max_sales)]\\n\\n# 3. Calculate average monthly sales\\naverage_sales = total_sales / len(sales)\\nprint(f\"DEBUG: average_sales = {average_sales}\") # Debug print\\n\\n# 4. Find months where sales exceeded the average\\nmonths_above_average = []\\nfor i, s in enumerate(sales):\\n    if s > average_sales:\\n        months_above_average.append(months[i])\\n\\n# 5. Calculate month-over-month growth percentage for each month\\ngrowth_percentages = []\\nfor i in range(1, len(sales)):\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\n    growth_percentages.append(f\"{growth:.2f}%\")\\n\\n# 6. Display results in a formatted report\\nprint(\"--- Sales Analysis Report ---\")\\nprint(f\"Total Sales: ${total_sales}\")\\nprint(f\"Month with Highest Sales: {month_highest_sales} (${max_sales})\")\\nprint(f\"Average Monthly Sales: ${average_sales:.2f}\")\\nprint(\"Months where sales exceeded the average:\", \", \".join(months_above_average))\\nprint(\"Month-over-month Growth Percentage:\")\\nfor i, growth in enumerate(growth_percentages):\\n    print(f\"  {months[i+1]}: {growth}\")\\n'}, 'id': 'a75e8154-3f86-4d6d-8f5a-8b92ab3cd7b2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 6323, 'output_tokens': 2296, 'total_tokens': 8619, 'input_token_details': {'cache_read': 5418}, 'output_token_details': {'reasoning': 1746}}),\n",
       "  ToolMessage(content='DEBUG: average_sales = 180.5\\n--- Sales Analysis Report ---\\nTotal Sales: $1805\\nMonth with Highest Sales: Oct ($220)\\nAverage Monthly Sales: $180.50\\nMonths where sales exceeded the average: Apr, Jun, Jul, Sep, Oct\\nMonth-over-month Growth Percentage:\\n  Feb: 25.00%\\n  Mar: 20.00%\\n  Apr: 11.11%\\n  May: -17.50%\\n  Jun: 15.15%\\n  Jul: 10.53%\\n  Aug: -16.67%\\n  Sep: 11.43%\\n  Oct: 12.82%\\n', name='python_repl', id='2760f56c-4212-4adf-a94a-e789112d085b', tool_call_id='a75e8154-3f86-4d6d-8f5a-8b92ab3cd7b2'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Here is the sales analysis report based on the provided dataset:\\n\\n--- Sales Analysis Report ---\\nTotal Sales: $1805\\nMonth with Highest Sales: Oct ($220)\\nAverage Monthly Sales: $180.50\\nMonths where sales exceeded the average: Apr, Jun, Jul, Sep, Oct\\nMonth-over-month Growth Percentage:\\n  Feb: 25.00%\\n  Mar: 20.00%\\n  Apr: 11.11%\\n  May: -17.50%\\n  Jun: 15.15%\\n  Jul: 10.53%\\n  Aug: -16.67%\\n  Sep: 11.43%\\n  Oct: 12.82%', 'extras': {'signature': 'CooEAXLI2nyELZA03HBpHilcvgm3OaCJsUO0uElPTNM7HvgN8+YIMvU8fujPWj67bTPYsjhmuwqD8nJlUxRuXMuBEN3DV+Nj5EH/KdR7kIjLPQvNTQd17ecV2J1TwtyORQB5HusRpyC+Z75LA5ajP7kxkbHGHtBjLFCtUYqK6n97An27J4xiIe8y+Jp8Of8RLVJtCo+vSIDCk5aObkYK+mEAYnJ3m7c+g45uyHOFz7zhyo9aw/YTMsc2I+IOG/Ek3d68fwAHfiBpp1bK1ZEx9xY7H+bg/jlHjphaKCeNZtjVdSID4IbgIvw+I5UU2xSH1ZmcB6ry6CVW/QGNrtKOuUknuhVBmPhRC9Qzh1pFVYBQMVVQxr+Zkw1J5hfscX3Yz+9nIqpfK/7NQR7jp2BMrEj+bEOge5g6TW9O7UoJ/tc1KqgU3mvZw/YmSx9FLODdpUGd8mW6ulZznSFqgIXrtEnfgKSxamvWOVVv8m1GqrAxTx21OxHSlJQN9Kgr9PMzTL/DMZju5W+lO7rwN4LieOCWaJJ6Rp95YSrkOkSZMZ0YlNC/9O+vdSN3D7nZ9vebGcHXHm3Pmpx+ZP5q0yADz6gv6PCBy/KHMrjPTWTy45OV4jbhVMA8SnT/KJKerrGqarWUpup5R4Sp7eW9LvcEIeVMHFwW1p+RkMzmUbVp7fzHQA0uBuD4EIQzbS94'}}], additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--147bfc00-6546-4df1-93db-978b1ccd0841-0', usage_metadata={'input_tokens': 7069, 'output_tokens': 277, 'total_tokens': 7346, 'input_token_details': {'cache_read': 5647}, 'output_token_details': {'reasoning': 101}})]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepagents.backends import FilesystemBackend\n",
    "\n",
    "tools = [repl_tool, internet_search]\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    tools=tools,\n",
    "    model=llm,\n",
    "    backend=FilesystemBackend()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "analyze_sales_data_prompt = \"\"\"I need you to analyze this dataset using Python REPL:\n",
    "Data: {'sales': [120, 150, 180, 200, 165, 190, 210, 175, 195, 220], \n",
    "       'months': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct']}\n",
    "\n",
    "Tasks:\n",
    "1. Calculate total sales\n",
    "2. Find the month with highest sales\n",
    "3. Calculate average monthly sales\n",
    "4. Find months where sales exceeded the average\n",
    "5. Calculate month-over-month growth percentage for each month\n",
    "6. Display results in a formatted report\n",
    "\n",
    "Use Python REPL economically to perform all calculations in one program and show your work.\"\"\"\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": analyze_sales_data_prompt}]})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2e52cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Sales Analysis Report:  1. Total Sales: $1805 2. Month with Highest Sales: Oct\n",
       "($220) 3. Average Monthly Sales: $180.50 4. Months where Sales Exceeded Average:\n",
       "Apr, Jun, Jul, Sep, Oct 5. Month-over-Month Growth Percentage:    Feb: 25.00%\n",
       "Mar: 20.00%    Apr: 11.11%    May: -17.50%    Jun: 15.15%    Jul: 10.53%    Aug:\n",
       "-16.67%    Sep: 11.43%    Oct: 12.82%\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_message_text = result['messages'][-1].content[0]['text']\n",
    "# long_string = last_message.content[0]['text']\n",
    "display_wrapped_text(last_message_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3a424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_program_prompt = \"\"\"use this code as template to analyze the sales data:\n",
    "\"__arg1\": \"\\ndata = {'sales': [120, 150, 180, 200, 165, 190, 210, 175, 195, 220], \\n        'months': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct']}\\n\\nsales = data['sales']\\nmonths = data['months']\\n\\n# 1. Calculate total sales\\ntotal_sales = sum(sales)\\n\\n# 2. Find the month with highest sales\\nmax_sales = max(sales)\\nmax_sales_month_index = sales.index(max_sales)\\nmonth_highest_sales = months[max_sales_month_index]\\n\\n# 3. Calculate average monthly sales\\naverage_sales = total_sales / len(sales)\\n\\n# 4. Find months where sales exceeded the average\\nmonths_above_average = []\\nfor i, s in enumerate(sales):\\n    if s > average_sales:\\n        months_above_average.append(months[i])\\n\\n# 5. Calculate month-over-month growth percentage for each month\\ngrowth_percentages = []\\nfor i in range(1, len(sales)):\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\n    growth_percentages.append(f\\\"{growth:.2f}%\\\")\\n\\n# 6. Display results in a formatted report\\nreport_lines = [\\n    \\\"Sales Analysis Report:\\\",\\n    \\\"\\\",\\n    f\\\"1. Total Sales: ${total_sales}\\\",\\n    f\\\"2. Month with Highest Sales: {month_highest_sales} (${max_sales})\\\",\\n    f\\\"3. Average Monthly Sales: ${average_sales:.2f}\\\",\\n    f\\\"4. Months where Sales Exceeded Average: {', '.join(months_above_average)}\\\",\\n    \\\"5. Month-over-Month Growth Percentage:\\\"\\n]\\n\\nfor i in range(len(growth_percentages)):\\n    report_lines.append(f\\\"   {months[i+1]}: {growth_percentages[i]}\\\")\\n\\nprint(\\\"\\\\n\\\".join(report_lines))\\n\"\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d58d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_sales_data_prompt = \"\"\"I need you to analyze this dataset using Python REPL:\n",
    "Data: {'sales': [2120, 150, 5180, 2400, 3165, 4190, 5210, 175, 7195, 220], \n",
    "       'months': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct']}\n",
    "\n",
    "Tasks:\n",
    "1. Calculate total sales\n",
    "2. Find the month with highest sales and the month with lowest sales\n",
    "3. Calculate average monthly sales\n",
    "4. Find months where sales exceeded the average\n",
    "5. Calculate month-over-month growth percentage for each month\n",
    "6. Display results in a formatted report\n",
    "\n",
    "Use Python REPL economically to perform all calculations in one program and show your work.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad4de9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"I need you to analyze this dataset using Python REPL:\\nData: {'sales': [2120, 150, 5180, 2400, 3165, 4190, 5210, 175, 7195, 220], \\n       'months': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct']}\\n\\nTasks:\\n1. Calculate total sales\\n2. Find the month with highest sales and the month with lowest sales\\n3. Calculate average monthly sales\\n4. Find months where sales exceeded the average\\n5. Calculate month-over-month growth percentage for each month\\n6. Display results in a formatted report\\n\\nUse Python REPL economically to perform all calculations in one program and show your work.\", additional_kwargs={}, response_metadata={}, id='dbf149bf-8439-47e1-9cf7-54f0e8597379'),\n",
       "  HumanMessage(content='use this code as template to analyze the sales data:\\n\"__arg1\": \"\\ndata = {\\'sales\\': [120, 150, 180, 200, 165, 190, 210, 175, 195, 220], \\n        \\'months\\': [\\'Jan\\', \\'Feb\\', \\'Mar\\', \\'Apr\\', \\'May\\', \\'Jun\\', \\'Jul\\', \\'Aug\\', \\'Sep\\', \\'Oct\\']}\\n\\nsales = data[\\'sales\\']\\nmonths = data[\\'months\\']\\n\\n# 1. Calculate total sales\\ntotal_sales = sum(sales)\\n\\n# 2. Find the month with highest sales\\nmax_sales = max(sales)\\nmax_sales_month_index = sales.index(max_sales)\\nmonth_highest_sales = months[max_sales_month_index]\\n\\n# 3. Calculate average monthly sales\\naverage_sales = total_sales / len(sales)\\n\\n# 4. Find months where sales exceeded the average\\nmonths_above_average = []\\nfor i, s in enumerate(sales):\\n    if s > average_sales:\\n        months_above_average.append(months[i])\\n\\n# 5. Calculate month-over-month growth percentage for each month\\ngrowth_percentages = []\\nfor i in range(1, len(sales)):\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\n    growth_percentages.append(f\"{growth:.2f}%\")\\n\\n# 6. Display results in a formatted report\\nreport_lines = [\\n    \"Sales Analysis Report:\",\\n    \"\",\\n    f\"1. Total Sales: ${total_sales}\",\\n    f\"2. Month with Highest Sales: {month_highest_sales} (${max_sales})\",\\n    f\"3. Average Monthly Sales: ${average_sales:.2f}\",\\n    f\"4. Months where Sales Exceeded Average: {\\', \\'.join(months_above_average)}\",\\n    \"5. Month-over-Month Growth Percentage:\"\\n]\\n\\nfor i in range(len(growth_percentages)):\\n    report_lines.append(f\"   {months[i+1]}: {growth_percentages[i]}\")\\n\\nprint(\"\\\\n\".join(report_lines))\\n\"\\n}', additional_kwargs={}, response_metadata={}, id='853a4e1e-f807-4773-baea-318c1debb773'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl', 'arguments': '{\"__arg1\": \"\\\\ndata = {\\'sales\\': [2120, 150, 5180, 2400, 3165, 4190, 5210, 175, 7195, 220], \\\\n        \\'months\\': [\\'Jan\\', \\'Feb\\', \\'Mar\\', \\'Apr\\', \\'May\\', \\'Jun\\', \\'Jul\\', \\'Aug\\', \\'Sep\\', \\'Oct\\']}\\\\n\\\\nsales = data[\\'sales\\']\\\\nmonths = data[\\'months\\']\\\\n\\\\n# 1. Calculate total sales\\\\ntotal_sales = sum(sales)\\\\n\\\\n# 2. Find the month with highest sales and the month with lowest sales\\\\nmax_sales = max(sales)\\\\nmax_sales_month_index = sales.index(max_sales)\\\\nmonth_highest_sales = months[max_sales_month_index]\\\\n\\\\nmin_sales = min(sales)\\\\nmin_sales_month_index = sales.index(min_sales)\\\\nmonth_lowest_sales = months[min_sales_month_index]\\\\n\\\\n# 3. Calculate average monthly sales\\\\naverage_sales = total_sales / len(sales)\\\\n\\\\n# 4. Find months where sales exceeded the average\\\\nmonths_above_average = []\\\\nfor i, s in enumerate(sales):\\\\n    if s > average_sales:\\\\n        months_above_average.append(months[i])\\\\n\\\\n# 5. Calculate month-over-month growth percentage for each month\\\\ngrowth_percentages = []\\\\nfor i in range(1, len(sales)):\\\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\\\n    growth_percentages.append(f\\\\\"{growth:.2f}%\\\\\")\\\\n\\\\n# 6. Display results in a formatted report\\\\nreport_lines = [\\\\n    \\\\\"Sales Analysis Report:\\\\\",\\\\n    \\\\\"\\\\\",\\\\n    f\\\\\"1. Total Sales: ${total_sales}\\\\\",\\\\n    f\\\\\"2. Month with Highest Sales: {month_highest_sales} (${max_sales})\\\\\",\\\\n    f\\\\\"   Month with Lowest Sales: {month_lowest_sales} (${min_sales})\\\\\",\\\\n    f\\\\\"3. Average Monthly Sales: ${average_sales:.2f}\\\\\",\\\\n    f\\\\\"4. Months where Sales Exceeded Average: {\\', \\'.join(months_above_average)}\\\\\",\\\\n    \\\\\"5. Month-over-Month Growth Percentage:\\\\\"\\\\n]\\\\n\\\\nfor i in range(len(growth_percentages)):\\\\n    report_lines.append(f\\\\\"   {months[i+1]}: {growth_percentages[i]}\\\\\")\\\\n\\\\nprint(\\\\\"\\\\n\\\\\".join(report_lines))\\\\n\"}'}, '__gemini_function_call_thought_signatures__': {'c2704421-383e-4265-b3d3-a6c4a6ed5a40': 'CuwEAXLI2nyJM3d1MhvEXefzsB5WURyRsN2sYZg3yZ57JVv10YCSnCwEKwYq8tt0iu7jP/PRLpt/NHlZgLT7IN4+6T6aaGXf2zEGEiH11ikGGAU1J6sXPWsUa3ymFMhdLHPhqUjLxLQbFV68eyoc6AMEIUFmv3v8f5Q1nZRHtk03cmgKT2Ygaua4bivsfVmzm+AY8hcAcIRubRNA9aXg6df0emhDkLXgUWDNNRvw0t8OQksfy81fAVg7Zhig0PDqSUskKdD4Q2dCgAT5eBtZruezIFqd1bWduw54JmNle62DoI3LC80q01GcaWg9/l6HobSAPnwppeMlxTxtc2E/4PiL8DN0kkNf4r6QVGOMzgFu5ZZ1rYLYl8AP9qVXBfRNkeIq7C1Ok7mvPzaMgEdCvRCSKI4hZsPIAI6DGOQtAbg8tFzkK0MtOymgtOA1b6nYSGSjrqF/kxMBIFyBfhWMNXAqWYjPnKtgjU1HiYfA7VFmFLfLeJN00n1ahczy8OyoGS5ksRAZYUslnYWrwtJ57/Y35kBswe0NpfQqjobm/pGJsCnXmxTx51pW9yiwjihtYNTy0SJxb1X2nFkl9g8F8s0xcw0MocbmWacnOAQC5XaxHdn4FSYJyBmwDBjjUBdkbCGlPvuskrensOLDiO+6NK+1WNGIVqYof90Xon+xnJ1WnrgpQC2GTWN6YVKKLSp1ndMECFH4oyYL3Bvg/FJnUjeHMD0d+rpQqtM/nps4X3hftIi6sA9VFSw50MMIQBO1xV0SzVHUCDQwRQidzuknOisYVKsgdk0ofQ+jiAS14UmLDx/0XP2+4AwBXe/Hp/Q='}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--c67eacac-e7e5-4b83-af90-e5b15f0fc574-0', tool_calls=[{'name': 'python_repl', 'args': {'__arg1': '\\ndata = {\\'sales\\': [2120, 150, 5180, 2400, 3165, 4190, 5210, 175, 7195, 220], \\n        \\'months\\': [\\'Jan\\', \\'Feb\\', \\'Mar\\', \\'Apr\\', \\'May\\', \\'Jun\\', \\'Jul\\', \\'Aug\\', \\'Sep\\', \\'Oct\\']}\\n\\nsales = data[\\'sales\\']\\nmonths = data[\\'months\\']\\n\\n# 1. Calculate total sales\\ntotal_sales = sum(sales)\\n\\n# 2. Find the month with highest sales and the month with lowest sales\\nmax_sales = max(sales)\\nmax_sales_month_index = sales.index(max_sales)\\nmonth_highest_sales = months[max_sales_month_index]\\n\\nmin_sales = min(sales)\\nmin_sales_month_index = sales.index(min_sales)\\nmonth_lowest_sales = months[min_sales_month_index]\\n\\n# 3. Calculate average monthly sales\\naverage_sales = total_sales / len(sales)\\n\\n# 4. Find months where sales exceeded the average\\nmonths_above_average = []\\nfor i, s in enumerate(sales):\\n    if s > average_sales:\\n        months_above_average.append(months[i])\\n\\n# 5. Calculate month-over-month growth percentage for each month\\ngrowth_percentages = []\\nfor i in range(1, len(sales)):\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\n    growth_percentages.append(f\"{growth:.2f}%\")\\n\\n# 6. Display results in a formatted report\\nreport_lines = [\\n    \"Sales Analysis Report:\",\\n    \"\",\\n    f\"1. Total Sales: ${total_sales}\",\\n    f\"2. Month with Highest Sales: {month_highest_sales} (${max_sales})\",\\n    f\"   Month with Lowest Sales: {month_lowest_sales} (${min_sales})\",\\n    f\"3. Average Monthly Sales: ${average_sales:.2f}\",\\n    f\"4. Months where Sales Exceeded Average: {\\', \\'.join(months_above_average)}\",\\n    \"5. Month-over-Month Growth Percentage:\"\\n]\\n\\nfor i in range(len(growth_percentages)):\\n    report_lines.append(f\"   {months[i+1]}: {growth_percentages[i]}\")\\n\\nprint(\"\\n\".join(report_lines))\\n'}, 'id': 'c2704421-383e-4265-b3d3-a6c4a6ed5a40', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5778, 'output_tokens': 808, 'total_tokens': 6586, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 140}}),\n",
       "  ToolMessage(content='SyntaxError(\\'unterminated string literal (detected at line 49)\\', (\\'<string>\\', 49, 7, \\'print(\"\\', 49, 7))', name='python_repl', id='20c3da01-8718-4e74-a928-a566f90b2ecb', tool_call_id='c2704421-383e-4265-b3d3-a6c4a6ed5a40'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl', 'arguments': '{\"__arg1\": \"data = {\\'sales\\': [2120, 150, 5180, 2400, 3165, 4190, 5210, 175, 7195, 220], \\\\n        \\'months\\': [\\'Jan\\', \\'Feb\\', \\'Mar\\', \\'Apr\\', \\'May\\', \\'Jun\\', \\'Jul\\', \\'Aug\\', \\'Sep\\', \\'Oct\\']}\\\\n\\\\nsales = data[\\'sales\\']\\\\nmonths = data[\\'months\\']\\\\n\\\\n# 1. Calculate total sales\\\\ntotal_sales = sum(sales)\\\\n\\\\n# 2. Find the month with highest sales and the month with lowest sales\\\\nmax_sales = max(sales)\\\\nmax_sales_month_index = sales.index(max_sales)\\\\nmonth_highest_sales = months[max_sales_month_index]\\\\n\\\\nmin_sales = min(sales)\\\\nmin_sales_month_index = sales.index(min_sales)\\\\nmonth_lowest_sales = months[min_sales_month_index]\\\\n\\\\n# 3. Calculate average monthly sales\\\\naverage_sales = total_sales / len(sales)\\\\n\\\\n# 4. Find months where sales exceeded the average\\\\nmonths_above_average = []\\\\nfor i, s in enumerate(sales):\\\\n    if s > average_sales:\\\\n        months_above_average.append(months[i])\\\\n\\\\n# 5. Calculate month-over-month growth percentage for each month\\\\ngrowth_percentages = []\\\\nfor i in range(1, len(sales)):\\\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\\\n    growth_percentages.append(f\\\\\"{growth:.2f}%\\\\\")\\\\n\\\\n# 6. Display results in a formatted report\\\\nreport_lines = [\\\\n    \\\\\"Sales Analysis Report:\\\\\",\\\\n    \\\\\"\\\\\",\\\\n    f\\\\\"1. Total Sales: ${total_sales}\\\\\",\\\\n    f\\\\\"2. Month with Highest Sales: {month_highest_sales} (${max_sales})\\\\\",\\\\n    f\\\\\"   Month with Lowest Sales: {month_lowest_sales} (${min_sales})\\\\\",\\\\n    f\\\\\"3. Average Monthly Sales: ${average_sales:.2f}\\\\\",\\\\n    f\\\\\"4. Months where Sales Exceeded Average: {\\', \\'.join(months_above_average)}\\\\\",\\\\n    \\\\\"5. Month-over-Month Growth Percentage:\\\\\"\\\\n]\\\\n\\\\nfor i in range(len(growth_percentages)):\\\\n    report_lines.append(f\\\\\"   {months[i+1]}: {growth_percentages[i]}\\\\\")\\\\n\\\\nprint(\\\\\"\\\\\\\\n\\\\\".join(report_lines))\"}'}, '__gemini_function_call_thought_signatures__': {'d5122c2f-0845-4a24-9c4e-f70f128b6caf': 'CvYGAXLI2nxSMF63b4gI4UmbYN0Vyg7LwxkAdqKBfN6k/oKHH5MTi5elwMvj9cSZLcvJ5PGUdR+P/XWGxyf6Ih/HFpiIchDy31PrzdFjm+5m+tiNugmRHpauTYtX7CBrbhkCuvT7E7B0QeZ3661hbjq0Jg9bSz9tExsSvm4NgwAwtsTd9ndiazlmlG1pffM7GqBSL/pXDQjnQMQ1INV2GL7t+/fYor0POFe/k64lQSdc/+BhQZNxp9o/wKLmdlDvpLbDJFOhUofMEJH340KHxc1pjGxpSBX8D09APtIVrh1Q/akVBWdCNflzmDs3A8MCA0VLpis5WFvCdFpd20mYgUOiMS0f9/pMRzCY8Y4I4fHAmWVW8Ad3UaQVPytlmE+fVmmUfoR0PFbVdkyDtjjRfiL+VXlp876imFC0+49Cv7SuufkcsEayMb342pZyfp93R/OQWKKfEeZru8zjHK3862K9zUhUnZSu9aeDOhvTKbE5CAT2tzd3RjBXRJqlBxqrpBZewc1wg43xjxAxV9KBTk1MI81r9YJ/C40183D6P9hFX2TKwCOOqYOU8z5eZaUGmiN2HralzSToWtxNmn97Z9ijxBZBneS7tBZHoln8nzh0PfiHxdwsDGF0EdVjZc3XUMMBCLY3yQrUYkLcVKllW7yOM2JRDw9OjaxnX0L6bc6pEOQ+Omo+DARzZ6F1eqp6EZU6qtoftULlB56DYC6wWB9a4XA0zs58VsviF6uedDkKw7KayWsIqfezgrY+uOLyNUv7e2bcVIuH/n6BiCA3GgL1AK+hKiO12cEIjLqFtN7C/+lPqv+1DSMcwIviRfVSyKfOMDdrtszS3I6VrpDMdI0/rKbaN76A/tObykszhN3GsMXzWQiu0ILAe3oKq9m3XBIhCQR84UhMDJDRFJnfWy8nSkN8wOkqRIbzzB/PP61ivCzV/3dMniGBq2UuPhdjAdOQgRNVA1BVsx8hA8vLgzr1IaN5NOgGnlVocUTXUGrwJBS29DjzM7VBaGzcFqgPgBaBVOVebjNDX5RMPwwiuthGCzMRQaXxNANxAe2++7GwKzeMtsoG5bvXybotMPq8vott3gmwCwBxIa+eVirmRqAnk4qnbpg0I8MASz3G7yb9BLnjWigARpOD48zI3xzaWcs3KJCk3Bg0SzcASSpYKk8kGdr5sZ+mGg=='}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--bb965ed0-6719-4fa6-b82f-f441ed3cefee-0', tool_calls=[{'name': 'python_repl', 'args': {'__arg1': 'data = {\\'sales\\': [2120, 150, 5180, 2400, 3165, 4190, 5210, 175, 7195, 220], \\n        \\'months\\': [\\'Jan\\', \\'Feb\\', \\'Mar\\', \\'Apr\\', \\'May\\', \\'Jun\\', \\'Jul\\', \\'Aug\\', \\'Sep\\', \\'Oct\\']}\\n\\nsales = data[\\'sales\\']\\nmonths = data[\\'months\\']\\n\\n# 1. Calculate total sales\\ntotal_sales = sum(sales)\\n\\n# 2. Find the month with highest sales and the month with lowest sales\\nmax_sales = max(sales)\\nmax_sales_month_index = sales.index(max_sales)\\nmonth_highest_sales = months[max_sales_month_index]\\n\\nmin_sales = min(sales)\\nmin_sales_month_index = sales.index(min_sales)\\nmonth_lowest_sales = months[min_sales_month_index]\\n\\n# 3. Calculate average monthly sales\\naverage_sales = total_sales / len(sales)\\n\\n# 4. Find months where sales exceeded the average\\nmonths_above_average = []\\nfor i, s in enumerate(sales):\\n    if s > average_sales:\\n        months_above_average.append(months[i])\\n\\n# 5. Calculate month-over-month growth percentage for each month\\ngrowth_percentages = []\\nfor i in range(1, len(sales)):\\n    growth = ((sales[i] - sales[i-1]) / sales[i-1]) * 100\\n    growth_percentages.append(f\"{growth:.2f}%\")\\n\\n# 6. Display results in a formatted report\\nreport_lines = [\\n    \"Sales Analysis Report:\",\\n    \"\",\\n    f\"1. Total Sales: ${total_sales}\",\\n    f\"2. Month with Highest Sales: {month_highest_sales} (${max_sales})\",\\n    f\"   Month with Lowest Sales: {month_lowest_sales} (${min_sales})\",\\n    f\"3. Average Monthly Sales: ${average_sales:.2f}\",\\n    f\"4. Months where Sales Exceeded Average: {\\', \\'.join(months_above_average)}\",\\n    \"5. Month-over-Month Growth Percentage:\"\\n]\\n\\nfor i in range(len(growth_percentages)):\\n    report_lines.append(f\"   {months[i+1]}: {growth_percentages[i]}\")\\n\\nprint(\"\\\\n\".join(report_lines))'}, 'id': 'd5122c2f-0845-4a24-9c4e-f70f128b6caf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 6502, 'output_tokens': 875, 'total_tokens': 7377, 'input_token_details': {'cache_read': 5642}, 'output_token_details': {'reasoning': 208}}),\n",
       "  ToolMessage(content='Sales Analysis Report:\\n\\n1. Total Sales: $30005\\n2. Month with Highest Sales: Sep ($7195)\\n   Month with Lowest Sales: Feb ($150)\\n3. Average Monthly Sales: $3000.50\\n4. Months where Sales Exceeded Average: Mar, May, Jun, Jul, Sep\\n5. Month-over-Month Growth Percentage:\\n   Feb: -92.92%\\n   Mar: 3353.33%\\n   Apr: -53.67%\\n   May: 31.87%\\n   Jun: 32.39%\\n   Jul: 24.34%\\n   Aug: -96.64%\\n   Sep: 4011.43%\\n   Oct: -96.94%\\n', name='python_repl', id='c518ca38-7762-443a-af89-8b72fd0a947c', tool_call_id='d5122c2f-0845-4a24-9c4e-f70f128b6caf'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Sales Analysis Report:\\n\\n1. Total Sales: $30005\\n2. Month with Highest Sales: Sep ($7195)\\n   Month with Lowest Sales: Feb ($150)\\n3. Average Monthly Sales: $3000.50\\n4. Months where Sales Exceeded Average: Mar, May, Jun, Jul, Sep\\n5. Month-over-Month Growth Percentage:\\n   Feb: -92.92%\\n   Mar: 3353.33%\\n   Apr: -53.67%\\n   May: 31.87%\\n   Jun: 32.39%\\n   Jul: 24.34%\\n   Aug: -96.64%\\n   Sep: 4011.43%\\n   Oct: -96.94%', 'extras': {'signature': 'Cv0DAXLI2ny2U36LoRyq6qapAhHwsqCv2tQtFGTJGZHMwN2bEgPoVCQa1hWVFvJbVu0BghX5CzM35IqhpcSkjrGvgf9ad7oQ722NRe7Ws88mtSXs/6Q5+AF9DQ2XKkpOOkfHlnSq0bjhcANrPtEmjvqo3hX/ZYw6hX7bT3goc0lM0VIj7wxoza10bV3nKQlVItQs/Ppk00C/XEbvPkc4W6q3FO7WG4VrymBn33YxF0ouoERq5uTsQ4p7sKl5q/NzT/x46qUUkdpE6o5l6ZcqX0gQz2up6yghkunbCTpUeNv/rggyAv4PWXYrZsETZlzF+boMWoLA+KN1v9eOvjImYwgFnQpv5DKMvWXd5wNSsmRM0JFZkofyUQkqxVb9uVJcj0Tm9f743kxB2KaM2NDpy6v2idSkqVY636wFbj71o226oWgyZdSu9cb4w2rpkTJEaCNlNaBxmpJErsxyr1+bZabSgDakcQx3atPgav9MxNj667W6IyUYYuIa/c2LWz03NavnIkajLZeWKggmbEqjiIMeM0SNJ1wZCOvSHykuGMM08ecQBEf/Du53riw1K7Vp1OBTfkUx+/ZvLXIZoTzvLeW0KET1GvobVZ/A/UMYuFfBaw9bao1grayw5Hm+/1Q5VY843vV9zJ2X72n33TcXe7jtq7dTuLUXLLPWVHV3Joc='}}], additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--72354d1f-b66d-4a10-8254-5dcb6c6ab039-0', usage_metadata={'input_tokens': 7381, 'output_tokens': 308, 'total_tokens': 7689, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 116}})]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": analyze_sales_data_prompt},\n",
    "                                    {\"role\": \"user\", \"content\": default_program_prompt}]})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "690031ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Sales Analysis Report:  1. Total Sales: $30005 2. Month with Highest Sales: Sep\n",
       "($7195)    Month with Lowest Sales: Feb ($150) 3. Average Monthly Sales:\n",
       "$3000.50 4. Months where Sales Exceeded Average: Mar, May, Jun, Jul, Sep 5.\n",
       "Month-over-Month Growth Percentage:    Feb: -92.92%    Mar: 3353.33%    Apr:\n",
       "-53.67%    May: 31.87%    Jun: 32.39%    Jul: 24.34%    Aug: -96.64%    Sep:\n",
       "4011.43%    Oct: -96.94%\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_message_text = result['messages'][-1].content[0]['text']\n",
    "# long_string = last_message.content[0]['text']\n",
    "display_wrapped_text(last_message_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fd14a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I want you to only to call the pandas_data_analysis tool with X as parameter and report me the results.', additional_kwargs={}, response_metadata={}, id='3bab81a6-4246-4c60-b5f2-2b9f47fe6037'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'pandas_data_analysis', 'arguments': '{\"__arg1\": \"X\"}'}, '__gemini_function_call_thought_signatures__': {'4cc00925-9374-457c-9e40-49536a2e229f': 'CqEBAXLI2nyWHgSWODFnOGXUdGsbpbO5AVKtrEC/VK7XtBjYwKVu82z5d7whD3Bc+oiLiVWDR05ee71iJDSfZGvziqE5/JVIWeQFSjN3XOv5XJDHSHXPZsRLxffXJWfCVHYWpas/Xz1kLWnIcthZHFW9uxNLiHBMyArcBWu6x2KLVqy70OJi43lNXLut3TSbMUZxQ7Wt5hAwvyePqrdy8R2tkzk='}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--5aec9aea-54fe-4dd4-9ed8-fe2d11435ac8-0', tool_calls=[{'name': 'pandas_data_analysis', 'args': {'__arg1': 'X'}, 'id': '4cc00925-9374-457c-9e40-49536a2e229f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5128, 'output_tokens': 53, 'total_tokens': 5181, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 35}}),\n",
       "  ToolMessage(content='{\\n  \"statistics_dataframe\": {\\n    \"Mean\": {\\n      \"price\": 96.95,\\n      \"quantity_sold\": 122.2,\\n      \"revenue\": 4640.62,\\n      \"rating\": 4.32,\\n      \"customer_age\": 38.9\\n    },\\n    \"Median\": {\\n      \"price\": 47.74,\\n      \"quantity_sold\": 100.5,\\n      \"revenue\": 4459.08,\\n      \"rating\": 4.35,\\n      \"customer_age\": 37.0\\n    },\\n    \"Std Dev\": {\\n      \"price\": 99.03,\\n      \"quantity_sold\": 95.78,\\n      \"revenue\": 1466.15,\\n      \"rating\": 0.43,\\n      \"customer_age\": 11.38\\n    },\\n    \"Variance\": {\\n      \"price\": 9806.34,\\n      \"quantity_sold\": 9173.85,\\n      \"revenue\": 2149585.89,\\n      \"rating\": 0.18,\\n      \"customer_age\": 129.46\\n    },\\n    \"Min\": {\\n      \"price\": 9.99,\\n      \"quantity_sold\": 8.0,\\n      \"revenue\": 2799.92,\\n      \"rating\": 3.5,\\n      \"customer_age\": 22.0\\n    },\\n    \"Max\": {\\n      \"price\": 349.99,\\n      \"quantity_sold\": 312.0,\\n      \"revenue\": 7798.44,\\n      \"rating\": 5.0,\\n      \"customer_age\": 62.0\\n    },\\n    \"Range\": {\\n      \"price\": 340.0,\\n      \"quantity_sold\": 304.0,\\n      \"revenue\": 4998.52,\\n      \"rating\": 1.5,\\n      \"customer_age\": 40.0\\n    },\\n    \"Q1 (25%)\": {\\n      \"price\": 23.74,\\n      \"quantity_sold\": 32.5,\\n      \"revenue\": 3495.55,\\n      \"rating\": 3.98,\\n      \"customer_age\": 30.5\\n    },\\n    \"Q3 (75%)\": {\\n      \"price\": 152.12,\\n      \"quantity_sold\": 191.25,\\n      \"revenue\": 5287.12,\\n      \"rating\": 4.62,\\n      \"customer_age\": 45.5\\n    },\\n    \"IQR\": {\\n      \"price\": 128.38,\\n      \"quantity_sold\": 158.75,\\n      \"revenue\": 1791.58,\\n      \"rating\": 0.65,\\n      \"customer_age\": 15.0\\n    },\\n    \"Skewness\": {\\n      \"price\": 1.36,\\n      \"quantity_sold\": 0.46,\\n      \"revenue\": 0.72,\\n      \"rating\": -0.21,\\n      \"customer_age\": 0.55\\n    },\\n    \"Kurtosis\": {\\n      \"price\": 1.19,\\n      \"quantity_sold\": -1.05,\\n      \"revenue\": -0.34,\\n      \"rating\": -0.94,\\n      \"customer_age\": -0.56\\n    }\\n  },\\n  \"summary\": {\\n    \"total_rows\": 20,\\n    \"total_columns\": 9,\\n    \"numerical_columns\": [\\n      \"price\",\\n      \"quantity_sold\",\\n      \"revenue\",\\n      \"rating\",\\n      \"customer_age\"\\n    ],\\n    \"categorical_columns\": [\\n      \"product_name\",\\n      \"category\",\\n      \"region\",\\n      \"sale_date\"\\n    ],\\n    \"total_revenue\": 92812.41,\\n    \"total_quantity_sold\": 2444,\\n    \"average_price\": 96.95450000000001,\\n    \"average_rating\": 4.319999999999999,\\n    \"unique_categories\": 3,\\n    \"unique_regions\": 4\\n  },\\n  \"outliers\": {\\n    \"price\": {\\n      \"count\": 1,\\n      \"lower_bound\": -168.83374999999998,\\n      \"upper_bound\": 344.69624999999996,\\n      \"outlier_values\": [\\n        {\\n          \"product_name\": \"Premium Product\",\\n          \"price\": 349.99\\n        }\\n      ]\\n    }\\n  },\\n  \"correlation_matrix\": {\\n    \"price\": {\\n      \"price\": 1.0,\\n      \"quantity_sold\": -0.8,\\n      \"revenue\": -0.171,\\n      \"rating\": 0.697,\\n      \"customer_age\": 0.817\\n    },\\n    \"quantity_sold\": {\\n      \"price\": -0.8,\\n      \"quantity_sold\": 1.0,\\n      \"revenue\": -0.08,\\n      \"rating\": -0.717,\\n      \"customer_age\": -0.751\\n    },\\n    \"revenue\": {\\n      \"price\": -0.171,\\n      \"quantity_sold\": -0.08,\\n      \"revenue\": 1.0,\\n      \"rating\": -0.084,\\n      \"customer_age\": -0.099\\n    },\\n    \"rating\": {\\n      \"price\": 0.697,\\n      \"quantity_sold\": -0.717,\\n      \"revenue\": -0.084,\\n      \"rating\": 1.0,\\n      \"customer_age\": 0.816\\n    },\\n    \"customer_age\": {\\n      \"price\": 0.817,\\n      \"quantity_sold\": -0.751,\\n      \"revenue\": -0.099,\\n      \"rating\": 0.816,\\n      \"customer_age\": 1.0\\n    }\\n  },\\n  \"strong_correlations\": [\\n    {\\n      \"column1\": \"price\",\\n      \"column2\": \"quantity_sold\",\\n      \"correlation\": -0.8\\n    },\\n    {\\n      \"column1\": \"price\",\\n      \"column2\": \"customer_age\",\\n      \"correlation\": 0.817\\n    },\\n    {\\n      \"column1\": \"quantity_sold\",\\n      \"column2\": \"rating\",\\n      \"correlation\": -0.717\\n    },\\n    {\\n      \"column1\": \"quantity_sold\",\\n      \"column2\": \"customer_age\",\\n      \"correlation\": -0.751\\n    },\\n    {\\n      \"column1\": \"rating\",\\n      \"column2\": \"customer_age\",\\n      \"correlation\": 0.816\\n    }\\n  ],\\n  \"dataframe_preview\": [\\n    {\\n      \"product_name\": \"Widget A\",\\n      \"category\": \"Electronics\",\\n      \"price\": 29.99,\\n      \"quantity_sold\": 150,\\n      \"revenue\": 4498.5,\\n      \"rating\": 4.5,\\n      \"customer_age\": 32,\\n      \"region\": \"North\",\\n      \"sale_date\": \"2024-01-15\"\\n    },\\n    {\\n      \"product_name\": \"Widget B\",\\n      \"category\": \"Electronics\",\\n      \"price\": 45.5,\\n      \"quantity_sold\": 89,\\n      \"revenue\": 4049.5,\\n      \"rating\": 4.2,\\n      \"customer_age\": 28,\\n      \"region\": \"South\",\\n      \"sale_date\": \"2024-01-18\"\\n    },\\n    {\\n      \"product_name\": \"Gadget X\",\\n      \"category\": \"Home\",\\n      \"price\": 19.99,\\n      \"quantity_sold\": 234,\\n      \"revenue\": 4677.66,\\n      \"rating\": 4.8,\\n      \"customer_age\": 45,\\n      \"region\": \"East\",\\n      \"sale_date\": \"2024-01-20\"\\n    },\\n    {\\n      \"product_name\": \"Gadget Y\",\\n      \"category\": \"Home\",\\n      \"price\": 35.75,\\n      \"quantity_sold\": 112,\\n      \"revenue\": 4004.0,\\n      \"rating\": 3.9,\\n      \"customer_age\": 38,\\n      \"region\": \"West\",\\n      \"sale_date\": \"2024-01-22\"\\n    },\\n    {\\n      \"product_name\": \"Tool Pro\",\\n      \"category\": \"Hardware\",\\n      \"price\": 89.99,\\n      \"quantity_sold\": 67,\\n      \"revenue\": 6029.33,\\n      \"rating\": 4.6,\\n      \"customer_age\": 52,\\n      \"region\": \"North\",\\n      \"sale_date\": \"2024-01-25\"\\n    }\\n  ]\\n}', name='pandas_data_analysis', id='c7d25a68-6bcc-4d41-94e7-d75448152a17', tool_call_id='4cc00925-9374-457c-9e40-49536a2e229f'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Here are the results from the pandas_data_analysis tool:\\n\\n**Summary:**\\n*   **Total Rows:** 20\\n*   **Total Columns:** 9\\n*   **Numerical Columns:** price, quantity_sold, revenue, rating, customer_age\\n*   **Categorical Columns:** product_name, category, region, sale_date\\n*   **Total Revenue:** 92812.41\\n*   **Total Quantity Sold:** 2444\\n*   **Average Price:** 96.95\\n*   **Average Rating:** 4.32\\n*   **Unique Categories:** 3\\n*   **Unique Regions:** 4\\n\\n**Statistics Dataframe (Mean, Median, Std Dev, Variance, Min, Max, Range, Q1, Q3, IQR, Skewness, Kurtosis):**\\n\\n| Statistic   | customer_age | price    | quantity_sold | rating | revenue    |\\n| :---------- | :----------- | :------- | :------------ | :----- | :--------- |\\n| Mean        | 38.9         | 96.95    | 122.2         | 4.32   | 4640.62    |\\n| Median      | 37           | 47.74    | 100.5         | 4.35   | 4459.08    |\\n| Std Dev     | 11.38        | 99.03    | 95.78         | 0.43   | 1466.15    |\\n| Variance    | 129.46       | 9806.34  | 9173.85       | 0.18   | 2149585.89 |\\n| Min         | 22           | 9.99     | 8             | 3.5    | 2799.92    |\\n| Max         | 62           | 349.99   | 312           | 5      | 7798.44    |\\n| Range       | 40           | 340      | 304           | 1.5    | 4998.52    |\\n| Q1 (25%)    | 30.5         | 23.74    | 32.5          | 3.98   | 3495.55    |\\n| Q3 (75%)    | 45.5         | 152.12   | 191.25        | 4.62   | 5287.12    |\\n| IQR         | 15           | 128.38   | 158.75        | 0.65   | 1791.58    |\\n| Skewness    | 0.55         | 1.36     | 0.46          | -0.21  | 0.72       |\\n| Kurtosis    | -0.56        | 1.19     | -1.05         | -0.94  | -0.34      |\\n\\n**Outliers:**\\n*   **Price:** 1 outlier found. The value is 349.99 for \"Premium Product\". The lower bound for outliers is -168.83 and the upper bound is 344.70.\\n\\n**Correlation Matrix:**\\n\\n|             | customer_age | price  | quantity_sold | rating | revenue |\\n| :---------- | :----------- | :----- | :------------ | :----- | :------ |\\n| customer_age | 1            | 0.817  | -0.751        | 0.816  | -0.099  |\\n| price       | 0.817        | 1      | -0.8          | 0.697  | -0.171  |\\n| quantity_sold | -0.751       | -0.8   | 1             | -0.717 | -0.08   |\\n| rating      | 0.816        | 0.697  | -0.717        | 1      | -0.084  |\\n| revenue     | -0.099       | -0.171 | -0.08         | -0.084 | 1       |\\n\\n**Strong Correlations (correlation > 0.7):**\\n*   price and quantity_sold: -0.8\\n*   price and customer_age: 0.817\\n*   quantity_sold and rating: -0.717\\n*   quantity_sold and customer_age: -0.751\\n*   rating and customer_age: 0.816\\n\\n**Dataframe Preview (First 5 rows):**\\n\\n| category    | customer_age | price  | product_name | quantity_sold | rating | region | revenue | sale_date  |\\n| :---------- | :----------- | :----- | :----------- | :------------ | :----- | :----- | :------ | :--------- |\\n| Electronics | 32           | 29.99  | Widget A     | 150           | 4.5    | North  | 4498.5  | 2024-01-15 |\\n| Electronics | 28           | 45.5   | Widget B     | 89            | 4.2    | South  | 4049.5  | 2024-01-18 |\\n| Home        | 45           | 19.99  | Gadget X     | 234           | 4.8    | East   | 4677.66 | 2024-01-20 |\\n| Home        | 38           | 35.75  | Gadget Y     | 112           | 3.9    | West   | 4004    | 2024-01-22 |\\n| Hardware    | 52           | 89.99  | Tool Pro     | 67            | 4.6    | North  | 6029.33 | 2024-01-25 |', 'extras': {'signature': 'CsAGAXLI2nzQ26jGkkigBi1g6wofFfrq3wVWj3dGWuKFB4X37W7fpb/ASicE20l9vNhBBucN2TleYnoFhOpVPPpZTt8DyqV7dW1IA9usN8YOz66lJpBLxaBLd8kDMNIL3b32j/g6iVSqOu+xIIwOIMh/ZsxQNG0CpYfIyoxjOKmdfBn0qoQbZTnAv8S+iuq1e+vi9AN5rNTzCFe8EjrTip7V6Rb16x8PCk9c0TtAPp3fFKF9JnvQCpmsGgps+HcfUiaiq/jlO+OPeb21jnpdYE9HnZydjqTKPD8YxMdBrMuhwHo4tp2syXwQQwJiEwbGDDYAYzXLrfz+99Bx5pqfNV1EBfZ6wHl7zAcupZIFTA1ebCqMACwk58Xv+F0YtyOet7pktz/VL5ULTcR/4OKsPEFWakj0/MoP+HflstMqoB7NAlRKQQycAMaCxr90KY1VDZ27yCLHih3lvwz6QxQbJk+8/6PcAHEDf1ovHSHDeT+ubu92qAH5BkFGpuR2zyWz8FnNHKtEGSQ4hOvpduqmhhXXJ/FUIycOtfs7nd13GDOYB8xwQHW6h4ysx3R47xZ5BvOnYNrnLN9yuvlMQzULHlK1eqVm5Hm/fTZbUDT4nDf0LF23Y+0jlntP/CmX18UrPt1BglpT4qXgakHaKYWjsOYBlS+mQZcc7GE0OYhpS1a4s1YUEyP6DykPvTaPd1ev7gsrhqDVkVzXpUiLi9L8FfOiFjSGJRySLsQ0J5wSycHKYdFW0TC3a7k0mWGD4rCc0hn1P84YhNXNQuIB733B3HlxnG7N2n/yPQLCQpThIa7nuGVBKd0fpR/v92LwbQrR/VUiLksMOeQ5oOJA8fPeLF6CgH3knnVL/zu0pTS/5Q9TAMjtfDQTFK3ip6jpvq4bfwnBRy9ejc53UPeL9N5lzY5mG0Y6nYzXL9V7I0uFEy3U+LqIsWu8mv0RpZpy07HLEX/DDt4fcsIIv0Zd9ScNwiDQG7R+zshwEoIAGMNfnUEtg3DJPPdMkzPyFlz4pTcrRGNJOPI12ybn1mQHFMiyjCSTrmW9Hs/gRLwAiNs5zRm6hL9nprGJYp0UL/ycqam0Isgl4Lw0/Z77HarPypFFjvUIZw=='}}], additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--d0fe8b0b-b9dc-4ce8-8a75-5375dc2fa1c2-0', usage_metadata={'input_tokens': 6924, 'output_tokens': 1691, 'total_tokens': 8615, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 191}})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [pandas_analysis_tool]\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    tools=tools,\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "pandas_analysis_prompt = \"\"\"I want you to only to call the pandas_data_analysis tool with X as parameter and report me the results.\"\"\"\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": pandas_analysis_prompt}]})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9205391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Here are the results from the pandas_data_analysis tool:  **Summary:** *\n",
       "**Total Rows:** 20 *   **Total Columns:** 9 *   **Numerical Columns:** price,\n",
       "quantity_sold, revenue, rating, customer_age *   **Categorical Columns:**\n",
       "product_name, category, region, sale_date *   **Total Revenue:** 92812.41 *\n",
       "**Total Quantity Sold:** 2444 *   **Average Price:** 96.95 *   **Average\n",
       "Rating:** 4.32 *   **Unique Categories:** 3 *   **Unique Regions:** 4\n",
       "**Statistics Dataframe (Mean, Median, Std Dev, Variance, Min, Max, Range, Q1,\n",
       "Q3, IQR, Skewness, Kurtosis):**  | Statistic   | customer_age | price    |\n",
       "quantity_sold | rating | revenue    | | :---------- | :----------- | :------- |\n",
       ":------------ | :----- | :--------- | | Mean        | 38.9         | 96.95    |\n",
       "122.2         | 4.32   | 4640.62    | | Median      | 37           | 47.74    |\n",
       "100.5         | 4.35   | 4459.08    | | Std Dev     | 11.38        | 99.03    |\n",
       "95.78         | 0.43   | 1466.15    | | Variance    | 129.46       | 9806.34  |\n",
       "9173.85       | 0.18   | 2149585.89 | | Min         | 22           | 9.99     |\n",
       "8             | 3.5    | 2799.92    | | Max         | 62           | 349.99   |\n",
       "312           | 5      | 7798.44    | | Range       | 40           | 340      |\n",
       "304           | 1.5    | 4998.52    | | Q1 (25%)    | 30.5         | 23.74    |\n",
       "32.5          | 3.98   | 3495.55    | | Q3 (75%)    | 45.5         | 152.12   |\n",
       "191.25        | 4.62   | 5287.12    | | IQR         | 15           | 128.38   |\n",
       "158.75        | 0.65   | 1791.58    | | Skewness    | 0.55         | 1.36     |\n",
       "0.46          | -0.21  | 0.72       | | Kurtosis    | -0.56        | 1.19     |\n",
       "-1.05         | -0.94  | -0.34      |  **Outliers:** *   **Price:** 1 outlier\n",
       "found. The value is 349.99 for \"Premium Product\". The lower bound for outliers\n",
       "is -168.83 and the upper bound is 344.70.  **Correlation Matrix:**  |\n",
       "| customer_age | price  | quantity_sold | rating | revenue | | :---------- |\n",
       ":----------- | :----- | :------------ | :----- | :------ | | customer_age | 1\n",
       "| 0.817  | -0.751        | 0.816  | -0.099  | | price       | 0.817        | 1\n",
       "| -0.8          | 0.697  | -0.171  | | quantity_sold | -0.751       | -0.8   | 1\n",
       "| -0.717 | -0.08   | | rating      | 0.816        | 0.697  | -0.717        | 1\n",
       "| -0.084  | | revenue     | -0.099       | -0.171 | -0.08         | -0.084 | 1\n",
       "|  **Strong Correlations (correlation > 0.7):** *   price and quantity_sold:\n",
       "-0.8 *   price and customer_age: 0.817 *   quantity_sold and rating: -0.717 *\n",
       "quantity_sold and customer_age: -0.751 *   rating and customer_age: 0.816\n",
       "**Dataframe Preview (First 5 rows):**  | category    | customer_age | price  |\n",
       "product_name | quantity_sold | rating | region | revenue | sale_date  | |\n",
       ":---------- | :----------- | :----- | :----------- | :------------ | :----- |\n",
       ":----- | :------ | :--------- | | Electronics | 32           | 29.99  | Widget A\n",
       "| 150           | 4.5    | North  | 4498.5  | 2024-01-15 | | Electronics | 28\n",
       "| 45.5   | Widget B     | 89            | 4.2    | South  | 4049.5  | 2024-01-18\n",
       "| | Home        | 45           | 19.99  | Gadget X     | 234           | 4.8\n",
       "| East   | 4677.66 | 2024-01-20 | | Home        | 38           | 35.75  | Gadget\n",
       "Y     | 112           | 3.9    | West   | 4004    | 2024-01-22 | | Hardware    |\n",
       "52           | 89.99  | Tool Pro     | 67            | 4.6    | North  | 6029.33\n",
       "| 2024-01-25 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_message_text = result['messages'][-1].content[0]['text']\n",
    "display_wrapped_text(last_message_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be92564c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['\\n    \"files\"', '\"files\"', '\"plan\"', 'architecture', 'files_to_generate', 'project_type', 'requirements', 'user_story', 'workspace_dir'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'code_generator_v1', 'lc_hub_commit_hash': '4cf9dbdbe08ae746bca005fd4ddbad2a4ec59c3724bb0d6919a22be0e9765dbd'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['\\n    \"files\"', '\"files\"', '\"plan\"', 'architecture', 'files_to_generate', 'project_type', 'requirements', 'user_story', 'workspace_dir'], input_types={}, partial_variables={}, template='SYSTEM ROLE\\nYou are the Code Generator Agent in the Agile Factory multi-agent workflow. Your mission is to generate production-ready code files by outputting structured JSON with all file content.\\n\\nCRITICAL: YOU MUST OUTPUT STRUCTURED JSON, NOT USE TOOL CALLS\\n\\n=== ABSOLUTE REQUIREMENT: STRUCTURED JSON OUTPUT ===\\n\\nDO NOT:\\n- Use tool calls (write_file, etc.)\\n- Output a \"plan\" JSON structure describing files\\n- Describe what files you would create\\n- List steps you would take\\n- Say \"I will create...\" or \"Let me create...\"\\n\\nDO:\\n- IMMEDIATELY output structured JSON with all file content\\n- Output format: {\"files\": {\"filename\": \"complete file content\"}}\\n- Include ALL files listed below\\n- Each file path should be relative (e.g., \"index.html\", not \"/path/to/index.html\")\\n- File content must be complete, working code (no placeholders)\\n\\nOPERATING PRINCIPLES\\n1. **JSON-First Approach** – Your output must be valid JSON with all files\\n2. **Completeness** – Generate all necessary files with full, executable code\\n3. **Production-Ready** – No placeholders, TODOs, or incomplete implementations\\n4. **Architecture Compliance** – Follow the provided architecture design exactly\\n5. **Requirement Coverage** – Implement all functional requirements\\n6. **Security** – No hardcoded secrets, validate inputs, sanitize outputs\\n7. **Quality** – Idiomatic code, SOLID principles, clear naming, proper error handling\\n\\nWORKFLOW CONTEXT\\nYou are part of an Agile Factory workflow:\\n1. Requirements Analyst → provides requirements\\n2. Architecture Designer → provides architecture design\\n3. YOU (Code Generator) → MUST output JSON with all code file content\\n4. Code Reviewer → will review your generated files\\n5. Testing Agent → will test your code\\n\\nYour output (JSON with file content) will be parsed and files written to disk automatically.\\n\\nOUTPUT FORMAT (REQUIRED):\\n{\\n    \"files\": {\\n        \"index.html\": \"<!DOCTYPE html><html>...</html>\",\\n        \"styles.css\": \"body { margin: 0; }\",\\n        \"app.py\": \"# Python code here\"\\n    }\\n}\\n\\nDYNAMIC CONTEXT (injected at runtime):\\n- User Story: {user_story}\\n- Project Type: {project_type}\\n- Requirements: {requirements}\\n- Architecture: {architecture}\\n- Workspace Directory: {workspace_dir}\\n- Files to Generate: {files_to_generate}\\n\\nINPUTS PROVIDED\\n- User Story: The original user story describing what to build\\n- Requirements: Structured requirements from Requirements Analyst\\n- Architecture: Complete architecture design from Architecture Designer\\n- Project Type: \"website\" or \"streamlit_app\"\\n- Files to Generate: List of files specified by architecture designer\\n\\nOUTPUT REQUIREMENTS\\nYou MUST output JSON with all files. The files you create should include:\\n\\nFor \"website\" projects:\\n- index.html (main HTML file with complete structure)\\n- styles.css (CSS styling)\\n- app.js (JavaScript if needed)\\n- Any other necessary files\\n\\nFor \"streamlit_app\" projects:\\n- app.py or streamlit_app.py (main Streamlit application)\\n- requirements.txt (with pinned dependency versions)\\n- Any supporting Python modules\\n\\nQUALITY STANDARDS\\n- Complete, executable code (no placeholders)\\n- Proper error handling\\n- Input validation\\n- Security best practices\\n- Clean, maintainable structure\\n- Follow architecture design exactly\\n- Implement all functional requirements\\n\\nEXAMPLE CORRECT BEHAVIOR (JSON OUTPUT)\\nIf files_to_generate lists 3 files, your response must be valid JSON:\\n{\\n    \"files\": {\\n        \"index.html\": \"<!DOCTYPE html><html><head>...</head><body>...</body></html>\",\\n        \"styles.css\": \"body { margin: 0; padding: 0; }\",\\n        \"app.js\": \"// JavaScript code...\"\\n    }\\n}\\n\\nCRITICAL: Generate ALL files listed in files_to_generate. Do not skip any files!\\n\\nEXAMPLE INCORRECT BEHAVIOR (DO NOT DO THIS):\\n{\"plan\": [\"Create index.html\", \"Create styles.css\"]}\\n\"I will create the following files...\"\\n\"Here\\'s my plan for the project...\"\\nUsing tool calls like write_file()\\n\\nTASK INSTRUCTIONS\\nWhen you receive a task, IMMEDIATELY output JSON with all code files for the {project_type} project.\\n\\nDO NOT RESPOND WITH TEXT. DO NOT USE TOOL CALLS. OUTPUT JSON NOW.\\n\\nCRITICAL: YOU MUST GENERATE ALL FILES LISTED BELOW\\nThe architecture designer has specified these files. You MUST include ALL of them in your JSON output:\\n\\n{files_to_generate}\\n\\nREQUIREMENT: Include EACH file listed above in your JSON output. Do not skip any files.\\n- If the list shows 3 files, your JSON must contain all 3 files\\n- If the list shows 5 files, your JSON must contain all 5 files\\n- Generate ALL files, not just one!\\n\\nYour response must be valid JSON with files object containing EVERY file listed.\\nDo not describe what you will do - OUTPUT THE JSON NOW.\\n\\nExample of correct response (if 3 files are listed):\\n{\\n    \"files\": {\\n        \"index.html\": \"<complete HTML code>\",\\n        \"styles.css\": \"<complete CSS code>\",\\n        \"app.js\": \"<complete JavaScript code>\"\\n    }\\n}\\n\\nOUTPUT JSON NOW with all files listed above.\\n\\nREMEMBER\\n- START by outputting JSON NOW\\n- Do not plan. Do not describe. OUTPUT JSON.\\n- Every file must be included in the JSON \"files\" object\\n- Create complete, working code immediately\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "import os\n",
    "client = Client(api_key=os.environ[\"LANGSMITH_API_KEY\"])\n",
    "prompt = client.pull_prompt(\"code_generator_v1\", include_model=True)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7aa077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>input_variables=['\\n    \"files\"', '\"files\"', '\"plan\"', 'architecture', 'files_to_generate', 'project_type', 'requirements', 'user_story', 'workspace_dir'] input_types={} partial_variables={} metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'code_generator_v1', 'lc_hub_commit_hash': '4cf9dbdbe08ae746bca005fd4ddbad2a4ec59c3724bb0d6919a22be0e9765dbd'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['\\n    \"files\"', '\"files\"', '\"plan\"', 'architecture', 'files_to_generate', 'project_type', 'requirements', 'user_story', 'workspace_dir'], input_types={}, partial_variables={}, template='SYSTEM ROLE\\nYou are the Code Generator Agent in the Agile Factory multi-agent workflow. Your mission is to generate production-ready code files by outputting structured JSON with all file content.\\n\\nCRITICAL: YOU MUST OUTPUT STRUCTURED JSON, NOT USE TOOL CALLS\\n\\n=== ABSOLUTE REQUIREMENT: STRUCTURED JSON OUTPUT ===\\n\\nDO NOT:\\n- Use tool calls (write_file, etc.)\\n- Output a \"plan\" JSON structure describing files\\n- Describe what files you would create\\n- List steps you would take\\n- Say \"I will create...\" or \"Let me create...\"\\n\\nDO:\\n- IMMEDIATELY output structured JSON with all file content\\n- Output format: {\"files\": {\"filename\": \"complete file content\"}}\\n- Include ALL files listed below\\n- Each file path should be relative (e.g., \"index.html\", not \"/path/to/index.html\")\\n- File content must be complete, working code (no placeholders)\\n\\nOPERATING PRINCIPLES\\n1. **JSON-First Approach** – Your output must be valid JSON with all files\\n2. **Completeness** – Generate all necessary files with full, executable code\\n3. **Production-Ready** – No placeholders, TODOs, or incomplete implementations\\n4. **Architecture Compliance** – Follow the provided architecture design exactly\\n5. **Requirement Coverage** – Implement all functional requirements\\n6. **Security** – No hardcoded secrets, validate inputs, sanitize outputs\\n7. **Quality** – Idiomatic code, SOLID principles, clear naming, proper error handling\\n\\nWORKFLOW CONTEXT\\nYou are part of an Agile Factory workflow:\\n1. Requirements Analyst → provides requirements\\n2. Architecture Designer → provides architecture design\\n3. YOU (Code Generator) → MUST output JSON with all code file content\\n4. Code Reviewer → will review your generated files\\n5. Testing Agent → will test your code\\n\\nYour output (JSON with file content) will be parsed and files written to disk automatically.\\n\\nOUTPUT FORMAT (REQUIRED):\\n{\\n    \"files\": {\\n        \"index.html\": \"<!DOCTYPE html><html>...</html>\",\\n        \"styles.css\": \"body { margin: 0; }\",\\n        \"app.py\": \"# Python code here\"\\n    }\\n}\\n\\nDYNAMIC CONTEXT (injected at runtime):\\n- User Story: {user_story}\\n- Project Type: {project_type}\\n- Requirements: {requirements}\\n- Architecture: {architecture}\\n- Workspace Directory: {workspace_dir}\\n- Files to Generate: {files_to_generate}\\n\\nINPUTS PROVIDED\\n- User Story: The original user story describing what to build\\n- Requirements: Structured requirements from Requirements Analyst\\n- Architecture: Complete architecture design from Architecture Designer\\n- Project Type: \"website\" or \"streamlit_app\"\\n- Files to Generate: List of files specified by architecture designer\\n\\nOUTPUT REQUIREMENTS\\nYou MUST output JSON with all files. The files you create should include:\\n\\nFor \"website\" projects:\\n- index.html (main HTML file with complete structure)\\n- styles.css (CSS styling)\\n- app.js (JavaScript if needed)\\n- Any other necessary files\\n\\nFor \"streamlit_app\" projects:\\n- app.py or streamlit_app.py (main Streamlit application)\\n- requirements.txt (with pinned dependency versions)\\n- Any supporting Python modules\\n\\nQUALITY STANDARDS\\n- Complete, executable code (no placeholders)\\n- Proper error handling\\n- Input validation\\n- Security best practices\\n- Clean, maintainable structure\\n- Follow architecture design exactly\\n- Implement all functional requirements\\n\\nEXAMPLE CORRECT BEHAVIOR (JSON OUTPUT)\\nIf files_to_generate lists 3 files, your response must be valid JSON:\\n{\\n    \"files\": {\\n        \"index.html\": \"<!DOCTYPE html><html><head>...</head><body>...</body></html>\",\\n        \"styles.css\": \"body { margin: 0; padding: 0; }\",\\n        \"app.js\": \"// JavaScript code...\"\\n    }\\n}\\n\\nCRITICAL: Generate ALL files listed in files_to_generate. Do not skip any files!\\n\\nEXAMPLE INCORRECT BEHAVIOR (DO NOT DO THIS):\\n{\"plan\": [\"Create index.html\", \"Create styles.css\"]}\\n\"I will create the following files...\"\\n\"Here\\'s my plan for the project...\"\\nUsing tool calls like write_file()\\n\\nTASK INSTRUCTIONS\\nWhen you receive a task, IMMEDIATELY output JSON with all code files for the {project_type} project.\\n\\nDO NOT RESPOND WITH TEXT. DO NOT USE TOOL CALLS. OUTPUT JSON NOW.\\n\\nCRITICAL: YOU MUST GENERATE ALL FILES LISTED BELOW\\nThe architecture designer has specified these files. You MUST include ALL of them in your JSON output:\\n\\n{files_to_generate}\\n\\nREQUIREMENT: Include EACH file listed above in your JSON output. Do not skip any files.\\n- If the list shows 3 files, your JSON must contain all 3 files\\n- If the list shows 5 files, your JSON must contain all 5 files\\n- Generate ALL files, not just one!\\n\\nYour response must be valid JSON with files object containing EVERY file listed.\\nDo not describe what you will do - OUTPUT THE JSON NOW.\\n\\nExample of correct response (if 3 files are listed):\\n{\\n    \"files\": {\\n        \"index.html\": \"<complete HTML code>\",\\n        \"styles.css\": \"<complete CSS code>\",\\n        \"app.js\": \"<complete JavaScript code>\"\\n    }\\n}\\n\\nOUTPUT JSON NOW with all files listed above.\\n\\nREMEMBER\\n- START by outputting JSON NOW\\n- Do not plan. Do not describe. OUTPUT JSON.\\n- Every file must be included in the JSON \"files\" object\\n- Create complete, working code immediately\\n'), additional_kwargs={})]</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "input_variables=['\\n    \"files\"', '\"files\"', '\"plan\"', 'architecture', 'files_to_generate', 'project_type', 'requirements', 'user_story', 'workspace_dir'] input_types={} partial_variables={} metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'code_generator_v1', 'lc_hub_commit_hash': '4cf9dbdbe08ae746bca005fd4ddbad2a4ec59c3724bb0d6919a22be0e9765dbd'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['\\n    \"files\"', '\"files\"', '\"plan\"', 'architecture', 'files_to_generate', 'project_type', 'requirements', 'user_story', 'workspace_dir'], input_types={}, partial_variables={}, template='SYSTEM ROLE\\nYou are the Code Generator Agent in the Agile Factory multi-agent workflow. Your mission is to generate production-ready code files by outputting structured JSON with all file content.\\n\\nCRITICAL: YOU MUST OUTPUT STRUCTURED JSON, NOT USE TOOL CALLS\\n\\n=== ABSOLUTE REQUIREMENT: STRUCTURED JSON OUTPUT ===\\n\\nDO NOT:\\n- Use tool calls (write_file, etc.)\\n- Output a \"plan\" JSON structure describing files\\n- Describe what files you would create\\n- List steps you would take\\n- Say \"I will create...\" or \"Let me create...\"\\n\\nDO:\\n- IMMEDIATELY output structured JSON with all file content\\n- Output format: {\"files\": {\"filename\": \"complete file content\"}}\\n- Include ALL files listed below\\n- Each file path should be relative (e.g., \"index.html\", not \"/path/to/index.html\")\\n- File content must be complete, working code (no placeholders)\\n\\nOPERATING PRINCIPLES\\n1. **JSON-First Approach** – Your output must be valid JSON with all files\\n2. **Completeness** – Generate all necessary files with full, executable code\\n3. **Production-Ready** – No placeholders, TODOs, or incomplete implementations\\n4. **Architecture Compliance** – Follow the provided architecture design exactly\\n5. **Requirement Coverage** – Implement all functional requirements\\n6. **Security** – No hardcoded secrets, validate inputs, sanitize outputs\\n7. **Quality** – Idiomatic code, SOLID principles, clear naming, proper error handling\\n\\nWORKFLOW CONTEXT\\nYou are part of an Agile Factory workflow:\\n1. Requirements Analyst → provides requirements\\n2. Architecture Designer → provides architecture design\\n3. YOU (Code Generator) → MUST output JSON with all code file content\\n4. Code Reviewer → will review your generated files\\n5. Testing Agent → will test your code\\n\\nYour output (JSON with file content) will be parsed and files written to disk automatically.\\n\\nOUTPUT FORMAT (REQUIRED):\\n{\\n    \"files\": {\\n        \"index.html\": \"<!DOCTYPE html><html>...</html>\",\\n        \"styles.css\": \"body { margin: 0; }\",\\n        \"app.py\": \"# Python code here\"\\n    }\\n}\\n\\nDYNAMIC CONTEXT (injected at runtime):\\n- User Story: {user_story}\\n- Project Type: {project_type}\\n- Requirements: {requirements}\\n- Architecture: {architecture}\\n- Workspace Directory: {workspace_dir}\\n- Files to Generate: {files_to_generate}\\n\\nINPUTS PROVIDED\\n- User Story: The original user story describing what to build\\n- Requirements: Structured requirements from Requirements Analyst\\n- Architecture: Complete architecture design from Architecture Designer\\n- Project Type: \"website\" or \"streamlit_app\"\\n- Files to Generate: List of files specified by architecture designer\\n\\nOUTPUT REQUIREMENTS\\nYou MUST output JSON with all files. The files you create should include:\\n\\nFor \"website\" projects:\\n- index.html (main HTML file with complete structure)\\n- styles.css (CSS styling)\\n- app.js (JavaScript if needed)\\n- Any other necessary files\\n\\nFor \"streamlit_app\" projects:\\n- app.py or streamlit_app.py (main Streamlit application)\\n- requirements.txt (with pinned dependency versions)\\n- Any supporting Python modules\\n\\nQUALITY STANDARDS\\n- Complete, executable code (no placeholders)\\n- Proper error handling\\n- Input validation\\n- Security best practices\\n- Clean, maintainable structure\\n- Follow architecture design exactly\\n- Implement all functional requirements\\n\\nEXAMPLE CORRECT BEHAVIOR (JSON OUTPUT)\\nIf files_to_generate lists 3 files, your response must be valid JSON:\\n{\\n    \"files\": {\\n        \"index.html\": \"<!DOCTYPE html><html><head>...</head><body>...</body></html>\",\\n        \"styles.css\": \"body { margin: 0; padding: 0; }\",\\n        \"app.js\": \"// JavaScript code...\"\\n    }\\n}\\n\\nCRITICAL: Generate ALL files listed in files_to_generate. Do not skip any files!\\n\\nEXAMPLE INCORRECT BEHAVIOR (DO NOT DO THIS):\\n{\"plan\": [\"Create index.html\", \"Create styles.css\"]}\\n\"I will create the following files...\"\\n\"Here\\'s my plan for the project...\"\\nUsing tool calls like write_file()\\n\\nTASK INSTRUCTIONS\\nWhen you receive a task, IMMEDIATELY output JSON with all code files for the {project_type} project.\\n\\nDO NOT RESPOND WITH TEXT. DO NOT USE TOOL CALLS. OUTPUT JSON NOW.\\n\\nCRITICAL: YOU MUST GENERATE ALL FILES LISTED BELOW\\nThe architecture designer has specified these files. You MUST include ALL of them in your JSON output:\\n\\n{files_to_generate}\\n\\nREQUIREMENT: Include EACH file listed above in your JSON output. Do not skip any files.\\n- If the list shows 3 files, your JSON must contain all 3 files\\n- If the list shows 5 files, your JSON must contain all 5 files\\n- Generate ALL files, not just one!\\n\\nYour response must be valid JSON with files object containing EVERY file listed.\\nDo not describe what you will do - OUTPUT THE JSON NOW.\\n\\nExample of correct response (if 3 files are listed):\\n{\\n    \"files\": {\\n        \"index.html\": \"<complete HTML code>\",\\n        \"styles.css\": \"<complete CSS code>\",\\n        \"app.js\": \"<complete JavaScript code>\"\\n    }\\n}\\n\\nOUTPUT JSON NOW with all files listed above.\\n\\nREMEMBER\\n- START by outputting JSON NOW\\n- Do not plan. Do not describe. OUTPUT JSON.\\n- Every file must be included in the JSON \"files\" object\\n- Create complete, working code immediately\\n'), additional_kwargs={})]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long_string = prompt\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# For HTML formatting\n",
    "display(HTML(f\"<pre>{long_string}</pre>\"))\n",
    "\n",
    "# For markdown\n",
    "display(Markdown(f\"```\\n{long_string}\\n```\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
