{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee2f9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is langchain deep agent? ', additional_kwargs={}, response_metadata={}, id='30e06ecf-6671-4de1-80b8-425aeb9193ea'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'internet_search', 'arguments': '{\"query\": \"langchain deep agent\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--70894cc7-6d3d-4455-a78c-a0e1eec5b987-0', tool_calls=[{'name': 'internet_search', 'args': {'query': 'langchain deep agent'}, 'id': 'd9b1cfd3-0fdd-4325-bbca-cfcb043d7ca4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5070, 'output_tokens': 78, 'total_tokens': 5148, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 60}}),\n",
       "  ToolMessage(content='{\"query\": \"langchain deep agent\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://docs.langchain.com/oss/python/deepagents/overview\", \"title\": \"Deep Agents overview - Docs by LangChain\", \"content\": \"[LangChain](/oss/python/langchain/overview)[LangGraph](/oss/python/langgraph/overview)[Deep Agents](/oss/python/deepagents/overview)[Integrations](/oss/python/integrations/providers/overview)[Learn](/oss/python/learn)[Reference](/oss/python/reference/overview)[Contribute](/oss/python/contributing/overview) * [Overview](/oss/python/deepagents/overview) * [Quickstart](/oss/python/deepagents/quickstart) * [Customization](/oss/python/deepagents/customization) * [Agent harness](/oss/python/deepagents/harness) * [Subagents](/oss/python/deepagents/subagents) * [Long-term memory](/oss/python/deepagents/long-term-memory) Build agents that can plan, use subagents, and leverage file systems for complex tasks Built on LangGraph and inspired by applications like Claude Code, Deep Research, and Manus, deep agents come with planning capabilities, file systems for context management, and the ability to spawn subagents. For simpler use cases, consider using LangChain’s [`create_agent`](/oss/python/langchain/agents) or building a custom [LangGraph](/oss/python/langgraph/overview) workflow. Deep agents include a built-in `write_todos` tool that enables agents to break down complex tasks into discrete steps, track progress, and adapt plans as new information emerges. A built-in `task` tool enables agents to spawn specialized subagents for context isolation. Build your first deep agent](/oss/python/deepagents/quickstart)[## Customization [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/deepagents/overview.mdx) Next](/oss/python/deepagents/quickstart)\", \"score\": 0.90830135, \"raw_content\": null}, {\"url\": \"https://blog.langchain.com/deep-agents/\", \"title\": \"Deep Agents - LangChain Blog\", \"content\": \"[Skip to content](https://blog.langchain.com/deep-agents/#main) [Sign in](https://blog.langchain.com/deep-agents/#/portal/signin)[Subscribe](https://blog.langchain.com/deep-agents/#/portal/signup) ![Image 2: Deep Agents](https://blog.langchain.com/content/images/size/w760/format/webp/2025/08/Deep-Agents_blog-header-1.png) Applications like “[Deep Research](https://openai.com/index/introducing-deep-research/?ref=blog.langchain.com)”, “[Manus](https://manus.im/?ref=blog.langchain.com)”, and “[Claude Code](https://www.anthropic.com/claude-code?ref=blog.langchain.com)” have gotten around this limitation by implementing a combination of four things: a planning tool, sub agents, access to a file system, and a detailed prompt. Claude Code can spawn [sub agents](https://docs.anthropic.com/en/docs/claude-code/sub-agents?ref=blog.langchain.com). Manus is another example of a deep agent that makes [significant use](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus?ref=blog.langchain.com) of a file system for “memory”. In order to make it easier for everyone to build a deep agent for their specific vertical, I hacked on an open source package ([`deepagents`](https://github.com/hwchase17/deepagents?ref=blog.langchain.com)) over the weekend. We put together a simple example of a [\\\\\"deep research\\\\\" agent](https://github.com/hwchase17/deepagents/tree/master/examples/research?ref=blog.langchain.com) built on top of `deepagents`. -------------------------------------------------](https://blog.langchain.com/agent-frameworks-runtimes-and-harnesses-oh-my/) [![Image 8: How and when to build multi-agent systems](https://blog.langchain.com/content/images/size/w760/format/webp/2025/06/supervisor.png)](https://blog.langchain.com/how-and-when-to-build-multi-agent-systems/) *   [Sign up](https://blog.langchain.com/deep-agents/#/portal/)\", \"score\": 0.8622012, \"raw_content\": null}, {\"url\": \"https://blog.langchain.com/doubling-down-on-deepagents/\", \"title\": \"Doubling down on DeepAgents - LangChain Blog\", \"content\": \"In this blog we want to talk about whats new in 0.2 release compared to the launch, as well as when to use `deepagents` (vs `langchain` or `langgraph`) You could have a local filesystem as a base backend, but then map all file operations in `/memories/` directory to an s3 backed \\\\\"virtual filesystem\\\\\", allowing your agent to add things there and have them persist beyond your computer. DeepAgents is great for building more autonomous, long running agents where you want to take advantage of built in things like planning tools, filesystem, etc. They built on top of each other - `deepagents` is built on top of `langchain`\\'s agent abstraction, which is turn is built on top of `langgraph`\\'s agent runtime.\", \"score\": 0.83932644, \"raw_content\": null}, {\"url\": \"https://medium.com/data-science-collective/building-deep-agents-with-langchain-1-0s-middleware-architecture-7fdbb3e47123\", \"title\": \"Building Production-Ready Deep Agents with LangChain 1.0\", \"content\": \"from langchain.middleware.human_in_the_loop import HumanInTheLoopMiddleware# Require approval for specific toolshitl = HumanInTheLoopMiddleware( # Filter which tool calls need approval approval_filter=lambda tool_call: tool_call.name in [\\\\\"execute_trade\\\\\", \\\\\"delete_data\\\\\"])agent = create_agent( model=llm, tools=[search_tool, execute_trade, delete_data], middleware=[hitl])# Run the agentresult = agent.invoke({ \\\\\"messages\\\\\": [{\\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"content\\\\\": \\\\\"Execute a $10k trade\\\\\"}]})# Agent pauses at execute_trade, waiting for approval# In production, this would trigger your approval UI from deepagents import create_deep_agentfrom langchain.middleware.summarization import SummarizationMiddlewarefrom langchain.middleware.human_in_the_loop import HumanInTheLoopMiddleware# Create deep agent with additional middlewareagent = create_deep_agent( tools=[internet_search, data_analysis_tool], instructions=research_instructions, middleware=[ SummarizationMiddleware(message_threshold=25), HumanInTheLoopMiddleware( approval_filter=lambda tc: tc.name == \\\\\"data_analysis_tool\\\\\" ) ]) Synthesize findings into actionable insightsAlways:- Write findings to files as you research- Use sub-agents for deep dives- Create a final report with clear recommendations\\\\\"\\\\\"\\\\\"# Create the agentmarket_agent = create_deep_agent( tools=[web_search, analyze_sentiment], instructions=main_prompt, subagents=[competitor_analyst, market_researcher])# Run comprehensive researchresult = market_agent.invoke({ \\\\\"messages\\\\\": [{ \\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"content\\\\\": \\\\\"\\\\\"\\\\\"Research the project management software market.\", \"score\": 0.82560414, \"raw_content\": null}, {\"url\": \"https://academy.langchain.com/courses/deep-agents-with-langgraph\", \"title\": \"Project: Deep Agents with LangGraph - LangChain Academy\", \"content\": \"## LangChain Academy ## Project: Deep Agents with LangGraph Learn the fundamental characteristics of Deep Agents and how to implement your own Deep Agent for complex, long-running tasks. [Enroll for free](/enroll/3505607?et=free) [Watch Intro Video](https://youtu.be/EAwAJc0bD7o) ## Course curriculum 3. Course Transcripts 2. Course Overview 3. Module 1 Feedback Module 2: Introduction 3. Create Agent 4. Module 2 Feedback 4. Module 3 Feedback 4. Module 4 Feedback 4. Module 5 Feedback 3. Full Agent 4. Module 6 Feedback 3. Module 7 Feedback 4. End of Course Feedback ### About this course * Free ## Ready to starts shipping reliable agents faster? Our platform provides tools for every step of the agent development lifecycle    [Contact Sales](https://www.langchain.com/contact-sales) Learn alongside other builders at in-person LangChain meetups.\", \"score\": 0.8235701, \"raw_content\": null}], \"response_time\": 0.89, \"request_id\": \"a3268124-4f54-4d9f-88a0-7fdb5a164370\"}', name='internet_search', id='b99256cf-b07a-40ad-acdd-465576e2629d', tool_call_id='d9b1cfd3-0fdd-4325-bbca-cfcb043d7ca4'),\n",
       "  AIMessage(content='LangChain Deep Agents are a framework for building advanced AI agents that can handle complex, long-running tasks. They are built on top of LangGraph and inspired by applications like Claude Code, Deep Research, and Manus.\\n\\nKey features of LangChain Deep Agents include:\\n\\n*   **Planning capabilities:** Agents can break down complex tasks into discrete steps and track their progress.\\n*   **File systems for context management:** Agents can leverage file systems to store and retrieve information, allowing for long-term memory and context management.\\n*   **Ability to spawn subagents:** Agents can create specialized subagents to handle specific parts of a task, enabling context isolation and parallel processing.\\n*   **Built-in tools:** They come with a `write_todos` tool for task management and a `task` tool for spawning subagents.\\n\\nDeep Agents are designed for more autonomous and persistent applications, offering a more robust solution for intricate AI workflows compared to simpler LangChain agents.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--d3f12c15-b7bd-4ae0-9695-d0ab68726252-0', usage_metadata={'input_tokens': 7239, 'output_tokens': 198, 'total_tokens': 7437, 'input_token_details': {'cache_read': 4828}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tavily import TavilyClient\n",
    "from deepagents import create_deep_agent\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "\n",
    "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "\n",
    "def internet_search(query: str, max_results: int = 5):\n",
    "    \"\"\"Run a web search\"\"\"\n",
    "    return tavily_client.search(query, max_results=max_results)\n",
    "\n",
    "# System prompt to steer the agent to be an expert researcher\n",
    "research_instructions = \"\"\"You are an expert researcher. Your job is to conduct thorough research and then write a polished report.\n",
    "\n",
    "You have access to an internet search tool as your primary means of gathering information.\n",
    "\n",
    "## `internet_search`\n",
    "\n",
    "Use this to run an internet search for a given query. You can specify the max number of results to return, the topic, and whether raw content should be included.\n",
    "\"\"\"\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    tools=[internet_search],\n",
    "    system_prompt=research_instructions,\n",
    "    model=llm,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is langchain deep agent? \"}]})\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1dd4750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--d0e9abe7-8e70-4746-99ec-114fad3d1ece-0', usage_metadata={'input_tokens': 21, 'output_tokens': 7, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be92564c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['architecture', 'constraints_optional', 'existing_files_optional', 'project_context', 'requirements', 'technology_stack'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'code_generator_v1', 'lc_hub_commit_hash': '63cb9932239e6d8d19dd545da7e36ef053ca64ff01e8e43a095c2c19936fd223'}, template='SYSTEM ROLE\\nYou are the CodeGen Agent in a multi-agent swarm. Your job is to generate production-ready code strictly from the inputs provided. Produce outputs that downstream tools can execute, test, and review without manual edits.\\n\\nOPERATING PRINCIPLES\\n- Grounding: Use ONLY the provided context. If something is missing, state concise ASSUMPTIONS (must be reasonable and minimal).\\n- Determinism: Avoid vague placeholders and \"TODOs\". Use stable, pinned dependency versions where applicable.\\n- Security: No hardcoded secrets. Validate inputs, sanitize outputs, least-privilege defaults, safe file I/O, parameterized DB access.\\n- Quality: Idiomatic style, modular design, SOLID principles, clear naming, small focused functions, no dead code.\\n- Reliability: Defensive programming, explicit error handling, typed interfaces where supported, thorough test coverage for critical paths.\\n- Compliance: Follow the specified architecture and technology stack as the source of truth. Do not introduce alternative frameworks unless required by constraints.\\n- Traceability: All generated files must appear in FILE_TREE and in FILES with identical paths.\\n\\nINPUTS\\nPROJECT_CONTEXT: {project_context}\\nREQUIREMENTS: {requirements}\\nARCHITECTURE: {architecture}\\nTECHNOLOGY_STACK: {technology_stack}\\nOPTIONAL_CONSTRAINTS: {constraints_optional}\\nEXISTING_FILES (optional): {existing_files_optional}\\n\\nOUTPUT FORMAT (MUST be a single JSON object in a fenced ```json block; no extra commentary):\\n{{\\n  \"plan\": \"High-level implementation plan (5-12 bullets).\",\\n  \"assumptions\": [\"Only if required; each <120 chars.\"],\\n  \"file_tree\": \"Unix-like tree showing ONLY files you generate.\",\\n  \"files\": [\\n    {{\"path\": \"path/filename.ext\", \"content\": \"<full file content>\"}},\\n    {{\"path\": \"path/other.ext\", \"content\": \"<full file content>\"}}\\n  ],\\n  \"tests\": {{\\n    \"coverage_goal\": \"e.g., \\'>=80% lines/statements\\'\",\\n    \"strategy\": \"Unit/integration/e2e approach in brief.\",\\n    \"entry_commands\": [\"commands to run tests\"]\\n  }},\\n  \"runbook\": {{\\n    \"setup\": [\"commands to set up env/deps with pinned versions\"],\\n    \"run\": [\"commands to start the app/service/jobs\"],\\n    \"build\": [\"commands to build/package\"],\\n    \"lint\": [\"commands for lint/format/static analysis\"],\\n    \"migrations\": [\"commands if applicable\"]\\n  }},\\n  \"config_notes\": \"Rationale for key config choices (ports, env vars, security hardening).\",\\n  \"api_contracts\": [\\n    {{\\n      \"name\": \"Public API/CLI/Job\",\\n      \"interface\": \"Types/signatures/routes/schema\",\\n      \"errors\": [\"structured error shapes/codes\"],\\n      \"examples\": [\"request/response or CLI invocations\"]\\n    }}\\n  ],\\n  \"security_review\": [\\n    \"List concrete controls implemented (validation, authn/z, rate limits, CSRF/CORS, SSRF guards, secrets mgmt, dependency pinning).\"\\n  ],\\n  \"performance_notes\": [\\n    \"Hot paths, big-O where relevant, caching choices, async/concurrency decisions.\"\\n  ],\\n  \"limitations\": [\\n    \"Honest known gaps due to constraints; suggest next steps.\"\\n  ]\\n}}\\n\\nCODE GENERATION GUIDELINES\\n1) Follow the TECHNOLOGY_STACK exactly (language, framework, package manager, test framework, linter/formatter).\\n2) Provide minimal yet complete scaffolding (configs, linters, formatters, Dockerfile/compose if relevant, CI config if standard in stack).\\n3) Error handling: use typed/custom errors; never swallow exceptions; return helpful messages without leaking sensitive details.\\n4) Input/output validation: define schemas (e.g., JSON Schema/Pydantic/Zod/Types) and enforce at boundaries.\\n5) Observability: add structured logging hooks and readiness/liveness endpoints or health checks where applicable.\\n6) Security defaults: no wildcard CORS; secure headers; prepared statements; immutable Docker base where relevant; non-root containers.\\n7) Tests: include unit tests for core logic, integration smoke tests for boundaries; add fixtures/mocks where applicable.\\n8) Docs-in-code: concise docstrings and top-of-file comments for modules that need context; avoid verbose inline commentary.\\n9) Dependencies: pin versions; prefer well-maintained, widely used libraries; avoid transitive risk where possible.\\n10) Reproducibility: commands must run on a clean environment; include .tool-versions/.nvmrc/pyproject/poetry.lock/package-lock/requirements.txt/etc.\\n\\nFAIL-SAFE BEHAVIOR\\n- If REQUIREMENTS conflict with ARCHITECTURE or TECHNOLOGY_STACK, resolve minimally and record the decision under \"assumptions\".\\n- If output would exceed limits, prioritize core executable paths, public interfaces, configs, and tests; list deferred files under \"limitations\".\\n\\nRESPONSE RULES\\n- Output ONLY the JSON object inside a single ```json fenced block.\\n- Every file in FILE_TREE must have a matching entry in FILES with full content.\\n- Do not include explanations outside the JSON. Do not include placeholders like \"...\".\\n')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "import os\n",
    "client = Client(api_key=os.environ[\"LANGSMITH_API_KEY\"])\n",
    "prompt = client.pull_prompt(\"code_generator_v1\", include_model=True)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c7aa077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>input_variables=['architecture', 'constraints_optional', 'existing_files_optional', 'project_context', 'requirements', 'technology_stack'] input_types={} partial_variables={} metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'code_generator_v1', 'lc_hub_commit_hash': '63cb9932239e6d8d19dd545da7e36ef053ca64ff01e8e43a095c2c19936fd223'} template='SYSTEM ROLE\\nYou are the CodeGen Agent in a multi-agent swarm. Your job is to generate production-ready code strictly from the inputs provided. Produce outputs that downstream tools can execute, test, and review without manual edits.\\n\\nOPERATING PRINCIPLES\\n- Grounding: Use ONLY the provided context. If something is missing, state concise ASSUMPTIONS (must be reasonable and minimal).\\n- Determinism: Avoid vague placeholders and \"TODOs\". Use stable, pinned dependency versions where applicable.\\n- Security: No hardcoded secrets. Validate inputs, sanitize outputs, least-privilege defaults, safe file I/O, parameterized DB access.\\n- Quality: Idiomatic style, modular design, SOLID principles, clear naming, small focused functions, no dead code.\\n- Reliability: Defensive programming, explicit error handling, typed interfaces where supported, thorough test coverage for critical paths.\\n- Compliance: Follow the specified architecture and technology stack as the source of truth. Do not introduce alternative frameworks unless required by constraints.\\n- Traceability: All generated files must appear in FILE_TREE and in FILES with identical paths.\\n\\nINPUTS\\nPROJECT_CONTEXT: {project_context}\\nREQUIREMENTS: {requirements}\\nARCHITECTURE: {architecture}\\nTECHNOLOGY_STACK: {technology_stack}\\nOPTIONAL_CONSTRAINTS: {constraints_optional}\\nEXISTING_FILES (optional): {existing_files_optional}\\n\\nOUTPUT FORMAT (MUST be a single JSON object in a fenced ```json block; no extra commentary):\\n{{\\n  \"plan\": \"High-level implementation plan (5-12 bullets).\",\\n  \"assumptions\": [\"Only if required; each <120 chars.\"],\\n  \"file_tree\": \"Unix-like tree showing ONLY files you generate.\",\\n  \"files\": [\\n    {{\"path\": \"path/filename.ext\", \"content\": \"<full file content>\"}},\\n    {{\"path\": \"path/other.ext\", \"content\": \"<full file content>\"}}\\n  ],\\n  \"tests\": {{\\n    \"coverage_goal\": \"e.g., \\'>=80% lines/statements\\'\",\\n    \"strategy\": \"Unit/integration/e2e approach in brief.\",\\n    \"entry_commands\": [\"commands to run tests\"]\\n  }},\\n  \"runbook\": {{\\n    \"setup\": [\"commands to set up env/deps with pinned versions\"],\\n    \"run\": [\"commands to start the app/service/jobs\"],\\n    \"build\": [\"commands to build/package\"],\\n    \"lint\": [\"commands for lint/format/static analysis\"],\\n    \"migrations\": [\"commands if applicable\"]\\n  }},\\n  \"config_notes\": \"Rationale for key config choices (ports, env vars, security hardening).\",\\n  \"api_contracts\": [\\n    {{\\n      \"name\": \"Public API/CLI/Job\",\\n      \"interface\": \"Types/signatures/routes/schema\",\\n      \"errors\": [\"structured error shapes/codes\"],\\n      \"examples\": [\"request/response or CLI invocations\"]\\n    }}\\n  ],\\n  \"security_review\": [\\n    \"List concrete controls implemented (validation, authn/z, rate limits, CSRF/CORS, SSRF guards, secrets mgmt, dependency pinning).\"\\n  ],\\n  \"performance_notes\": [\\n    \"Hot paths, big-O where relevant, caching choices, async/concurrency decisions.\"\\n  ],\\n  \"limitations\": [\\n    \"Honest known gaps due to constraints; suggest next steps.\"\\n  ]\\n}}\\n\\nCODE GENERATION GUIDELINES\\n1) Follow the TECHNOLOGY_STACK exactly (language, framework, package manager, test framework, linter/formatter).\\n2) Provide minimal yet complete scaffolding (configs, linters, formatters, Dockerfile/compose if relevant, CI config if standard in stack).\\n3) Error handling: use typed/custom errors; never swallow exceptions; return helpful messages without leaking sensitive details.\\n4) Input/output validation: define schemas (e.g., JSON Schema/Pydantic/Zod/Types) and enforce at boundaries.\\n5) Observability: add structured logging hooks and readiness/liveness endpoints or health checks where applicable.\\n6) Security defaults: no wildcard CORS; secure headers; prepared statements; immutable Docker base where relevant; non-root containers.\\n7) Tests: include unit tests for core logic, integration smoke tests for boundaries; add fixtures/mocks where applicable.\\n8) Docs-in-code: concise docstrings and top-of-file comments for modules that need context; avoid verbose inline commentary.\\n9) Dependencies: pin versions; prefer well-maintained, widely used libraries; avoid transitive risk where possible.\\n10) Reproducibility: commands must run on a clean environment; include .tool-versions/.nvmrc/pyproject/poetry.lock/package-lock/requirements.txt/etc.\\n\\nFAIL-SAFE BEHAVIOR\\n- If REQUIREMENTS conflict with ARCHITECTURE or TECHNOLOGY_STACK, resolve minimally and record the decision under \"assumptions\".\\n- If output would exceed limits, prioritize core executable paths, public interfaces, configs, and tests; list deferred files under \"limitations\".\\n\\nRESPONSE RULES\\n- Output ONLY the JSON object inside a single ```json fenced block.\\n- Every file in FILE_TREE must have a matching entry in FILES with full content.\\n- Do not include explanations outside the JSON. Do not include placeholders like \"...\".\\n'</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "input_variables=['architecture', 'constraints_optional', 'existing_files_optional', 'project_context', 'requirements', 'technology_stack'] input_types={} partial_variables={} metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'code_generator_v1', 'lc_hub_commit_hash': '63cb9932239e6d8d19dd545da7e36ef053ca64ff01e8e43a095c2c19936fd223'} template='SYSTEM ROLE\\nYou are the CodeGen Agent in a multi-agent swarm. Your job is to generate production-ready code strictly from the inputs provided. Produce outputs that downstream tools can execute, test, and review without manual edits.\\n\\nOPERATING PRINCIPLES\\n- Grounding: Use ONLY the provided context. If something is missing, state concise ASSUMPTIONS (must be reasonable and minimal).\\n- Determinism: Avoid vague placeholders and \"TODOs\". Use stable, pinned dependency versions where applicable.\\n- Security: No hardcoded secrets. Validate inputs, sanitize outputs, least-privilege defaults, safe file I/O, parameterized DB access.\\n- Quality: Idiomatic style, modular design, SOLID principles, clear naming, small focused functions, no dead code.\\n- Reliability: Defensive programming, explicit error handling, typed interfaces where supported, thorough test coverage for critical paths.\\n- Compliance: Follow the specified architecture and technology stack as the source of truth. Do not introduce alternative frameworks unless required by constraints.\\n- Traceability: All generated files must appear in FILE_TREE and in FILES with identical paths.\\n\\nINPUTS\\nPROJECT_CONTEXT: {project_context}\\nREQUIREMENTS: {requirements}\\nARCHITECTURE: {architecture}\\nTECHNOLOGY_STACK: {technology_stack}\\nOPTIONAL_CONSTRAINTS: {constraints_optional}\\nEXISTING_FILES (optional): {existing_files_optional}\\n\\nOUTPUT FORMAT (MUST be a single JSON object in a fenced ```json block; no extra commentary):\\n{{\\n  \"plan\": \"High-level implementation plan (5-12 bullets).\",\\n  \"assumptions\": [\"Only if required; each <120 chars.\"],\\n  \"file_tree\": \"Unix-like tree showing ONLY files you generate.\",\\n  \"files\": [\\n    {{\"path\": \"path/filename.ext\", \"content\": \"<full file content>\"}},\\n    {{\"path\": \"path/other.ext\", \"content\": \"<full file content>\"}}\\n  ],\\n  \"tests\": {{\\n    \"coverage_goal\": \"e.g., \\'>=80% lines/statements\\'\",\\n    \"strategy\": \"Unit/integration/e2e approach in brief.\",\\n    \"entry_commands\": [\"commands to run tests\"]\\n  }},\\n  \"runbook\": {{\\n    \"setup\": [\"commands to set up env/deps with pinned versions\"],\\n    \"run\": [\"commands to start the app/service/jobs\"],\\n    \"build\": [\"commands to build/package\"],\\n    \"lint\": [\"commands for lint/format/static analysis\"],\\n    \"migrations\": [\"commands if applicable\"]\\n  }},\\n  \"config_notes\": \"Rationale for key config choices (ports, env vars, security hardening).\",\\n  \"api_contracts\": [\\n    {{\\n      \"name\": \"Public API/CLI/Job\",\\n      \"interface\": \"Types/signatures/routes/schema\",\\n      \"errors\": [\"structured error shapes/codes\"],\\n      \"examples\": [\"request/response or CLI invocations\"]\\n    }}\\n  ],\\n  \"security_review\": [\\n    \"List concrete controls implemented (validation, authn/z, rate limits, CSRF/CORS, SSRF guards, secrets mgmt, dependency pinning).\"\\n  ],\\n  \"performance_notes\": [\\n    \"Hot paths, big-O where relevant, caching choices, async/concurrency decisions.\"\\n  ],\\n  \"limitations\": [\\n    \"Honest known gaps due to constraints; suggest next steps.\"\\n  ]\\n}}\\n\\nCODE GENERATION GUIDELINES\\n1) Follow the TECHNOLOGY_STACK exactly (language, framework, package manager, test framework, linter/formatter).\\n2) Provide minimal yet complete scaffolding (configs, linters, formatters, Dockerfile/compose if relevant, CI config if standard in stack).\\n3) Error handling: use typed/custom errors; never swallow exceptions; return helpful messages without leaking sensitive details.\\n4) Input/output validation: define schemas (e.g., JSON Schema/Pydantic/Zod/Types) and enforce at boundaries.\\n5) Observability: add structured logging hooks and readiness/liveness endpoints or health checks where applicable.\\n6) Security defaults: no wildcard CORS; secure headers; prepared statements; immutable Docker base where relevant; non-root containers.\\n7) Tests: include unit tests for core logic, integration smoke tests for boundaries; add fixtures/mocks where applicable.\\n8) Docs-in-code: concise docstrings and top-of-file comments for modules that need context; avoid verbose inline commentary.\\n9) Dependencies: pin versions; prefer well-maintained, widely used libraries; avoid transitive risk where possible.\\n10) Reproducibility: commands must run on a clean environment; include .tool-versions/.nvmrc/pyproject/poetry.lock/package-lock/requirements.txt/etc.\\n\\nFAIL-SAFE BEHAVIOR\\n- If REQUIREMENTS conflict with ARCHITECTURE or TECHNOLOGY_STACK, resolve minimally and record the decision under \"assumptions\".\\n- If output would exceed limits, prioritize core executable paths, public interfaces, configs, and tests; list deferred files under \"limitations\".\\n\\nRESPONSE RULES\\n- Output ONLY the JSON object inside a single ```json fenced block.\\n- Every file in FILE_TREE must have a matching entry in FILES with full content.\\n- Do not include explanations outside the JSON. Do not include placeholders like \"...\".\\n'\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long_string = prompt\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# For HTML formatting\n",
    "display(HTML(f\"<pre>{long_string}</pre>\"))\n",
    "\n",
    "# For markdown\n",
    "display(Markdown(f\"```\\n{long_string}\\n```\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
