# Automated Git Protection Rule

**CRITICAL**: Automatically commit and push valuable achievements to Git when meaningful progress is made that should be protected from loss. This ensures maximum quality preservation and maximum efficiency through automated protection of valuable work.

## Description
This rule enforces automatic Git protection of valuable achievements through intelligent detection of meaningful progress and automated commit/push operations. It applies holistic-detailed thinking to balance quality preservation with efficiency optimization, ensuring no valuable work is ever lost while maintaining clean Git history.

## Core Requirements

### 1. **Value Achievement Detection Framework**
**MANDATORY**: Systematically detect when valuable achievements occur
```python
# REQUIRED: Value achievement detection system
class ValueAchievementDetector:
    """Holistic-detailed system for detecting valuable achievements."""
    
    def __init__(self):
        self.value_indicators = {
            "code_quality": self._assess_code_quality_improvements,
            "feature_completion": self._assess_feature_completion,
            "test_coverage": self._assess_test_coverage_improvements,
            "bug_fixes": self._assess_bug_fix_achievements,
            "documentation": self._assess_documentation_achievements,
            "performance": self._assess_performance_improvements,
            "security": self._assess_security_improvements,
            "refactoring": self._assess_refactoring_achievements,
            "rule_improvements": self._assess_rule_system_improvements,
            "system_stability": self._assess_system_stability_improvements
        }
        
        self.protection_thresholds = {
            "CRITICAL": 0.9,    # Must protect immediately
            "HIGH": 0.8,        # Should protect within 5 minutes
            "MEDIUM": 0.6,      # Should protect within 15 minutes
            "LOW": 0.4,         # Consider protection within 30 minutes
            "MINIMAL": 0.2      # Track but don't auto-protect
        }
    
    def detect_valuable_achievement(self, session_context: dict) -> ValueAssessment:
        """Detect if current state represents valuable achievement."""
        
        print("üîç HOLISTIC VALUE ACHIEVEMENT DETECTION")
        print("=" * 50)
        
        value_scores = {}
        overall_value = 0
        
        # Assess each value dimension
        for dimension, assessor in self.value_indicators.items():
            print(f"\nüìã Assessing: {dimension}")
            score = assessor(session_context)
            value_scores[dimension] = score
            overall_value += score
            
            if score >= 0.8:
                print(f"   ‚úÖ HIGH VALUE: {score:.1%} - {dimension}")
            elif score >= 0.6:
                print(f"   üü° MEDIUM VALUE: {score:.1%} - {dimension}")
            elif score >= 0.4:
                print(f"   üü¢ LOW VALUE: {score:.1%} - {dimension}")
            else:
                print(f"   ‚ö™ MINIMAL VALUE: {score:.1%} - {dimension}")
        
        # Calculate weighted overall value
        weighted_value = self._calculate_weighted_value(value_scores, session_context)
        
        # Determine protection priority
        protection_priority = self._determine_protection_priority(weighted_value)
        
        print(f"\nüìä VALUE ASSESSMENT RESULTS:")
        print(f"   Overall Value Score: {weighted_value:.1%}")
        print(f"   Protection Priority: {protection_priority}")
        
        return ValueAssessment(
            overall_value=weighted_value,
            dimension_scores=value_scores,
            protection_priority=protection_priority,
            should_protect=weighted_value >= self.protection_thresholds["MEDIUM"],
            urgency_level=self._calculate_urgency_level(weighted_value, session_context)
        )
    
    def _assess_code_quality_improvements(self, context: dict) -> float:
        """Assess code quality improvements."""
        
        quality_factors = {
            "new_functions_added": 0.3,
            "code_coverage_improved": 0.4,
            "linting_errors_fixed": 0.2,
            "documentation_improved": 0.3,
            "performance_optimized": 0.4,
            "security_enhanced": 0.5,
            "tests_added": 0.4,
            "refactoring_completed": 0.3
        }
        
        total_score = 0
        applicable_factors = 0
        
        for factor, weight in quality_factors.items():
            if factor in context and context[factor]:
                if isinstance(context[factor], bool):
                    total_score += weight
                elif isinstance(context[factor], (int, float)):
                    # Normalize numeric values to 0-1 range
                    normalized_value = min(context[factor] / 100, 1.0)
                    total_score += weight * normalized_value
                applicable_factors += 1
        
        return total_score / applicable_factors if applicable_factors > 0 else 0
    
    def _assess_feature_completion(self, context: dict) -> float:
        """Assess feature completion achievements."""
        
        completion_indicators = {
            "user_story_completed": 1.0,
            "feature_fully_implemented": 0.9,
            "feature_partially_implemented": 0.6,
            "milestone_reached": 0.8,
            "epic_completed": 1.0,
            "integration_completed": 0.7,
            "api_endpoint_completed": 0.6,
            "workflow_completed": 0.8
        }
        
        max_score = 0
        for indicator, score in completion_indicators.items():
            if indicator in context and context[indicator]:
                max_score = max(max_score, score)
        
        return max_score
    
    def _assess_test_coverage_improvements(self, context: dict) -> float:
        """Assess test coverage improvements."""
        
        test_factors = {
            "new_tests_added": 0.4,
            "test_coverage_increased": 0.5,
            "failing_tests_fixed": 0.6,
            "integration_tests_added": 0.5,
            "performance_tests_added": 0.4,
            "security_tests_added": 0.5,
            "test_quality_improved": 0.3
        }
        
        total_score = 0
        applicable_factors = 0
        
        for factor, weight in test_factors.items():
            if factor in context and context[factor]:
                total_score += weight
                applicable_factors += 1
        
        return total_score / applicable_factors if applicable_factors > 0 else 0
    
    def _assess_bug_fix_achievements(self, context: dict) -> float:
        """Assess bug fix achievements."""
        
        bug_fix_factors = {
            "critical_bug_fixed": 1.0,
            "high_priority_bug_fixed": 0.8,
            "medium_priority_bug_fixed": 0.6,
            "low_priority_bug_fixed": 0.4,
            "regression_fixed": 0.9,
            "security_vulnerability_fixed": 1.0,
            "performance_issue_fixed": 0.7,
            "data_corruption_fixed": 1.0
        }
        
        max_score = 0
        for factor, score in bug_fix_factors.items():
            if factor in context and context[factor]:
                max_score = max(max_score, score)
        
        return max_score
    
    def _assess_documentation_achievements(self, context: dict) -> float:
        """Assess documentation achievements."""
        
        doc_factors = {
            "api_documentation_completed": 0.7,
            "user_guide_completed": 0.8,
            "architecture_documentation_updated": 0.6,
            "code_documentation_improved": 0.5,
            "troubleshooting_guide_updated": 0.6,
            "readme_updated": 0.4,
            "changelog_updated": 0.3,
            "rules_documented": 0.5
        }
        
        total_score = 0
        applicable_factors = 0
        
        for factor, weight in doc_factors.items():
            if factor in context and context[factor]:
                total_score += weight
                applicable_factors += 1
        
        return total_score / applicable_factors if applicable_factors > 0 else 0
```

### 2. **Intelligent Commit Message Generation**
**MANDATORY**: Generate intelligent, descriptive commit messages
```python
# REQUIRED: Intelligent commit message generation
class IntelligentCommitMessageGenerator:
    """Generate intelligent commit messages based on value achievements."""
    
    def generate_commit_message(self, value_assessment: ValueAssessment, 
                                session_context: dict) -> CommitMessage:
        """Generate intelligent commit message for the achievement."""
        
        print("üìù GENERATING INTELLIGENT COMMIT MESSAGE")
        print("=" * 50)
        
        # Analyze changes for message components
        change_analysis = self._analyze_changes(session_context)
        
        # Generate message components
        message_type = self._determine_message_type(value_assessment, change_analysis)
        scope = self._determine_scope(change_analysis)
        description = self._generate_description(value_assessment, change_analysis)
        body = self._generate_body(value_assessment, change_analysis)
        footer = self._generate_footer(value_assessment, change_analysis)
        
        # Construct commit message
        commit_message = self._construct_commit_message(
            message_type, scope, description, body, footer
        )
        
        print(f"üìù GENERATED COMMIT MESSAGE:")
        print(f"   Type: {message_type}")
        print(f"   Scope: {scope}")
        print(f"   Description: {description}")
        print(f"   Full Message:\n{commit_message}")
        
        return CommitMessage(
            type=message_type,
            scope=scope,
            description=description,
            body=body,
            footer=footer,
            full_message=commit_message
        )
    
    def _determine_message_type(self, assessment: ValueAssessment, 
                                changes: ChangeAnalysis) -> str:
        """Determine the type of commit message."""
        
        # Priority-based type determination
        if assessment.dimension_scores.get("security", 0) >= 0.8:
            return "security"
        elif assessment.dimension_scores.get("bug_fixes", 0) >= 0.8:
            return "fix"
        elif assessment.dimension_scores.get("feature_completion", 0) >= 0.8:
            return "feat"
        elif assessment.dimension_scores.get("test_coverage", 0) >= 0.8:
            return "test"
        elif assessment.dimension_scores.get("documentation", 0) >= 0.8:
            return "docs"
        elif assessment.dimension_scores.get("performance", 0) >= 0.8:
            return "perf"
        elif assessment.dimension_scores.get("refactoring", 0) >= 0.8:
            return "refactor"
        elif assessment.dimension_scores.get("rule_improvements", 0) >= 0.8:
            return "rules"
        elif assessment.dimension_scores.get("system_stability", 0) >= 0.8:
            return "stability"
        else:
            return "improve"
    
    def _generate_description(self, assessment: ValueAssessment, 
                             changes: ChangeAnalysis) -> str:
        """Generate concise description of the achievement."""
        
        # Get top scoring dimensions
        top_dimensions = sorted(
            assessment.dimension_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )[:3]
        
        # Generate description based on top dimensions
        descriptions = []
        for dimension, score in top_dimensions:
            if score >= 0.6:
                description = self._get_dimension_description(dimension, changes)
                if description:
                    descriptions.append(description)
        
        if descriptions:
            return descriptions[0]  # Use the highest scoring dimension
        else:
            return "improve system quality and functionality"
    
    def _get_dimension_description(self, dimension: str, changes: ChangeAnalysis) -> str:
        """Get description for a specific dimension."""
        
        dimension_descriptions = {
            "code_quality": "enhance code quality and maintainability",
            "feature_completion": "complete feature implementation",
            "test_coverage": "improve test coverage and quality",
            "bug_fixes": "fix critical bugs and issues",
            "documentation": "update and improve documentation",
            "performance": "optimize performance and efficiency",
            "security": "enhance security and vulnerability protection",
            "refactoring": "refactor code for better structure",
            "rule_improvements": "improve rule system and compliance",
            "system_stability": "enhance system stability and reliability"
        }
        
        return dimension_descriptions.get(dimension, "improve system")
```

### 3. **Automated Git Operations**
**MANDATORY**: Execute automated Git operations safely
```python
# REQUIRED: Automated Git operations
class AutomatedGitOperations:
    """Execute automated Git operations for value protection."""
    
    def __init__(self):
        self.git_safety_checks = [
            self._check_working_directory_clean,
            self._check_no_merge_conflicts,
            self._check_tests_passing,
            self._check_linting_clean,
            self._check_no_sensitive_data
        ]
    
    def protect_valuable_achievement(self, value_assessment: ValueAssessment,
                                     commit_message: CommitMessage) -> ProtectionResult:
        """Protect valuable achievement through automated Git operations."""
        
        print("üõ°Ô∏è PROTECTING VALUABLE ACHIEVEMENT")
        print("=" * 50)
        
        # Step 1: Pre-commit safety checks
        safety_result = self._execute_safety_checks()
        if not safety_result.safe:
            print(f"‚ùå SAFETY CHECKS FAILED: {safety_result.issues}")
            return ProtectionResult(
                success=False,
                reason=f"Safety checks failed: {safety_result.issues}"
            )
        
        # Step 2: Stage changes intelligently
        staging_result = self._stage_changes_intelligently(value_assessment)
        if not staging_result.success:
            print(f"‚ùå STAGING FAILED: {staging_result.reason}")
            return ProtectionResult(
                success=False,
                reason=f"Staging failed: {staging_result.reason}"
            )
        
        # Step 3: Create commit
        commit_result = self._create_commit(commit_message)
        if not commit_result.success:
            print(f"‚ùå COMMIT FAILED: {commit_result.reason}")
            return ProtectionResult(
                success=False,
                reason=f"Commit failed: {commit_result.reason}"
            )
        
        # Step 4: Push to remote (with safety checks)
        push_result = self._push_to_remote(value_assessment)
        if not push_result.success:
            print(f"‚ùå PUSH FAILED: {push_result.reason}")
            # Commit succeeded but push failed - still partially successful
            return ProtectionResult(
                success=True,
                partial=True,
                reason=f"Committed locally but push failed: {push_result.reason}"
            )
        
        print("‚úÖ VALUABLE ACHIEVEMENT SUCCESSFULLY PROTECTED")
        return ProtectionResult(
            success=True,
            commit_hash=commit_result.commit_hash,
            push_reference=push_result.reference
        )
    
    def _execute_safety_checks(self) -> SafetyResult:
        """Execute comprehensive safety checks before Git operations."""
        
        print("üîç EXECUTING SAFETY CHECKS")
        issues = []
        
        for check in self.git_safety_checks:
            try:
                check_result = check()
                if not check_result.passed:
                    issues.append(check_result.issue)
                    print(f"   ‚ùå {check.__name__}: {check_result.issue}")
                else:
                    print(f"   ‚úÖ {check.__name__}: PASSED")
            except Exception as e:
                issues.append(f"{check.__name__}: {e}")
                print(f"   ‚ùå {check.__name__}: ERROR - {e}")
        
        return SafetyResult(
            safe=len(issues) == 0,
            issues=issues
        )
    
    def _stage_changes_intelligently(self, value_assessment: ValueAssessment) -> StagingResult:
        """Stage changes intelligently based on value assessment."""
        
        print("üì¶ STAGING CHANGES INTELLIGENTLY")
        
        # Get list of modified files
        modified_files = self._get_modified_files()
        
        # Categorize files by importance
        file_categories = self._categorize_files(modified_files, value_assessment)
        
        # Stage files by priority
        staged_files = []
        
        # Always stage critical files
        for file in file_categories["critical"]:
            stage_result = self._stage_file(file)
            if stage_result:
                staged_files.append(file)
                print(f"   ‚úÖ STAGED CRITICAL: {file}")
            else:
                print(f"   ‚ùå FAILED TO STAGE: {file}")
        
        # Stage high-priority files
        for file in file_categories["high"]:
            stage_result = self._stage_file(file)
            if stage_result:
                staged_files.append(file)
                print(f"   ‚úÖ STAGED HIGH: {file}")
        
        # Conditionally stage medium-priority files
        if value_assessment.protection_priority in ["CRITICAL", "HIGH"]:
            for file in file_categories["medium"]:
                stage_result = self._stage_file(file)
                if stage_result:
                    staged_files.append(file)
                    print(f"   ‚úÖ STAGED MEDIUM: {file}")
        
        return StagingResult(
            success=len(staged_files) > 0,
            staged_files=staged_files,
            reason="No files staged" if len(staged_files) == 0 else None
        )
    
    def _categorize_files(self, files: List[str], 
                         assessment: ValueAssessment) -> Dict[str, List[str]]:
        """Categorize files by importance for staging."""
        
        categories = {
            "critical": [],
            "high": [],
            "medium": [],
            "low": []
        }
        
        for file in files:
            category = self._determine_file_importance(file, assessment)
            categories[category].append(file)
        
        return categories
    
    def _determine_file_importance(self, file: str, 
                                  assessment: ValueAssessment) -> str:
        """Determine the importance of a file for staging."""
        
        # Critical files (always stage)
        if any(pattern in file for pattern in [
            ".cursor/rules/", "docs/agile/", "tests/", 
            "requirements.txt", "README.md"
        ]):
            return "critical"
        
        # High importance files
        if any(pattern in file for pattern in [
            "agents/", "workflow/", "utils/", "models/",
            "apps/", "prompts/"
        ]):
            return "high"
        
        # Medium importance files
        if any(pattern in file for pattern in [
            "docs/", "scripts/", "monitoring/"
        ]):
            return "medium"
        
        # Low importance files
        return "low"
```

### 4. **Protection Triggers and Scheduling**
**MANDATORY**: Smart triggers for automated protection
```python
# REQUIRED: Protection triggers and scheduling
class ProtectionTriggerSystem:
    """Smart system for triggering automated protection."""
    
    def __init__(self):
        self.trigger_conditions = {
            "immediate": self._check_immediate_triggers,
            "time_based": self._check_time_based_triggers,
            "value_based": self._check_value_based_triggers,
            "safety_based": self._check_safety_based_triggers
        }
        
        self.last_protection_time = None
        self.protection_history = []
    
    def should_trigger_protection(self, session_context: dict) -> TriggerDecision:
        """Determine if protection should be triggered."""
        
        print("üéØ EVALUATING PROTECTION TRIGGERS")
        print("=" * 50)
        
        trigger_results = {}
        should_trigger = False
        trigger_reason = None
        urgency_level = "LOW"
        
        # Check all trigger conditions
        for trigger_type, trigger_check in self.trigger_conditions.items():
            result = trigger_check(session_context)
            trigger_results[trigger_type] = result
            
            if result.should_trigger:
                should_trigger = True
                if not trigger_reason or result.priority > urgency_level:
                    trigger_reason = result.reason
                    urgency_level = result.priority
        
        # Display trigger evaluation results
        print(f"üìã TRIGGER EVALUATION RESULTS:")
        for trigger_type, result in trigger_results.items():
            status = "üî¥ TRIGGERED" if result.should_trigger else "üü¢ NOT TRIGGERED"
            print(f"   {trigger_type}: {status} - {result.reason}")
        
        print(f"\nüéØ FINAL DECISION:")
        print(f"   Should Trigger: {'YES' if should_trigger else 'NO'}")
        print(f"   Reason: {trigger_reason or 'No trigger conditions met'}")
        print(f"   Urgency: {urgency_level}")
        
        return TriggerDecision(
            should_trigger=should_trigger,
            reason=trigger_reason,
            urgency_level=urgency_level,
            trigger_details=trigger_results
        )
    
    def _check_immediate_triggers(self, context: dict) -> TriggerResult:
        """Check for immediate trigger conditions."""
        
        immediate_conditions = [
            ("critical_bug_fixed", "Critical bug fix completed"),
            ("security_vulnerability_fixed", "Security vulnerability fixed"),
            ("data_corruption_fixed", "Data corruption issue fixed"),
            ("system_crash_fixed", "System crash issue fixed"),
            ("user_story_completed", "User story completed"),
            ("epic_completed", "Epic completed"),
            ("milestone_reached", "Major milestone reached")
        ]
        
        for condition, reason in immediate_conditions:
            if context.get(condition, False):
                return TriggerResult(
                    should_trigger=True,
                    reason=reason,
                    priority="CRITICAL"
                )
        
        return TriggerResult(
            should_trigger=False,
            reason="No immediate trigger conditions met",
            priority="NONE"
        )
    
    def _check_time_based_triggers(self, context: dict) -> TriggerResult:
        """Check for time-based trigger conditions."""
        
        current_time = datetime.now()
        
        # Check if enough time has passed since last protection
        if self.last_protection_time:
            time_since_last = current_time - self.last_protection_time
            
            # Protection intervals based on activity level
            if context.get("high_activity", False) and time_since_last.total_seconds() >= 300:  # 5 minutes
                return TriggerResult(
                    should_trigger=True,
                    reason="High activity time interval reached (5 minutes)",
                    priority="MEDIUM"
                )
            elif time_since_last.total_seconds() >= 900:  # 15 minutes
                return TriggerResult(
                    should_trigger=True,
                    reason="Standard time interval reached (15 minutes)",
                    priority="LOW"
                )
        
        return TriggerResult(
            should_trigger=False,
            reason="Time interval not reached",
            priority="NONE"
        )
    
    def _check_value_based_triggers(self, context: dict) -> TriggerResult:
        """Check for value-based trigger conditions."""
        
        # Calculate accumulated value since last protection
        accumulated_value = self._calculate_accumulated_value(context)
        
        if accumulated_value >= 0.8:
            return TriggerResult(
                should_trigger=True,
                reason=f"High accumulated value reached ({accumulated_value:.1%})",
                priority="HIGH"
            )
        elif accumulated_value >= 0.6:
            return TriggerResult(
                should_trigger=True,
                reason=f"Medium accumulated value reached ({accumulated_value:.1%})",
                priority="MEDIUM"
            )
        
        return TriggerResult(
            should_trigger=False,
            reason=f"Accumulated value below threshold ({accumulated_value:.1%})",
            priority="NONE"
        )
    
    def _check_safety_based_triggers(self, context: dict) -> TriggerResult:
        """Check for safety-based trigger conditions."""
        
        safety_conditions = [
            ("system_unstable", "System instability detected"),
            ("data_at_risk", "Data at risk of loss"),
            ("critical_changes_made", "Critical changes made"),
            ("dependency_updates", "Dependency updates completed"),
            ("configuration_changes", "Configuration changes made")
        ]
        
        for condition, reason in safety_conditions:
            if context.get(condition, False):
                return TriggerResult(
                    should_trigger=True,
                    reason=reason,
                    priority="HIGH"
                )
        
        return TriggerResult(
            should_trigger=False,
            reason="No safety trigger conditions met",
            priority="NONE"
        )
```

### 5. **Integration with Existing Systems**
**MANDATORY**: Integrate with existing automation and rules
```python
# REQUIRED: Integration with existing systems
class GitProtectionIntegration:
    """Integration with existing automation and rule systems."""
    
    def __init__(self):
        self.value_detector = ValueAchievementDetector()
        self.message_generator = IntelligentCommitMessageGenerator()
        self.git_operations = AutomatedGitOperations()
        self.trigger_system = ProtectionTriggerSystem()
        
        # Integration with existing systems
        self.rule_system = self._initialize_rule_system_integration()
        self.test_system = self._initialize_test_system_integration()
        self.quality_system = self._initialize_quality_system_integration()
    
    def execute_automated_protection_workflow(self, session_context: dict) -> WorkflowResult:
        """Execute the complete automated protection workflow."""
        
        print("üöÄ EXECUTING AUTOMATED GIT PROTECTION WORKFLOW")
        print("=" * 60)
        
        # Step 1: Check if protection should be triggered
        trigger_decision = self.trigger_system.should_trigger_protection(session_context)
        
        if not trigger_decision.should_trigger:
            print(f"‚è∏Ô∏è PROTECTION NOT TRIGGERED: {trigger_decision.reason}")
            return WorkflowResult(
                executed=False,
                reason=trigger_decision.reason
            )
        
        # Step 2: Detect valuable achievements
        value_assessment = self.value_detector.detect_valuable_achievement(session_context)
        
        if not value_assessment.should_protect:
            print(f"‚è∏Ô∏è NO VALUABLE ACHIEVEMENT DETECTED")
            return WorkflowResult(
                executed=False,
                reason="No valuable achievement detected"
            )
        
        # Step 3: Generate intelligent commit message
        commit_message = self.message_generator.generate_commit_message(
            value_assessment, session_context
        )
        
        # Step 4: Execute Git protection operations
        protection_result = self.git_operations.protect_valuable_achievement(
            value_assessment, commit_message
        )
        
        # Step 5: Update tracking and history
        self._update_protection_history(value_assessment, protection_result)
        
        # Step 6: Integrate with other systems
        self._notify_integrated_systems(value_assessment, protection_result)
        
        return WorkflowResult(
            executed=True,
            success=protection_result.success,
            value_assessment=value_assessment,
            commit_message=commit_message,
            protection_result=protection_result
        )
```

## Implementation Strategy

### 1. **Holistic Integration**
**MANDATORY**: Integrate with all existing systems holistically
- Integrate with existing Git hooks and automation
- Integrate with test execution and quality validation
- Integrate with rule compliance monitoring
- Integrate with agile artifact maintenance
- Integrate with documentation live updates

### 2. **Quality and Efficiency Balance**
**MANDATORY**: Optimize for both maximum quality and maximum efficiency
- Quality: Comprehensive safety checks, intelligent staging, proper commit messages
- Efficiency: Automated triggers, intelligent detection, minimal manual intervention
- Balance: Smart thresholds, configurable triggers, adaptive behavior

### 3. **Detailed Implementation**
**MANDATORY**: Apply detailed thinking to all aspects
- Comprehensive value detection across all dimensions
- Intelligent commit message generation with proper categorization
- Safe Git operations with multiple safety checks
- Smart trigger system with multiple condition types
- Full integration with existing automation systems

## Benefits

- **Zero Work Loss**: Valuable achievements are automatically protected
- **Maximum Quality**: Comprehensive safety checks ensure clean commits
- **Maximum Efficiency**: Automated operations eliminate manual Git work
- **Intelligent Behavior**: Smart detection and triggers adapt to context
- **Full Integration**: Works seamlessly with existing systems
- **Holistic Approach**: Considers all aspects of value and protection

## Enforcement

This rule is **ALWAYS APPLIED** and must be followed for all:
- Development sessions with valuable achievements
- Feature completion and milestone reaching
- Bug fixes and security improvements
- Test coverage and quality improvements
- Documentation and rule system updates
- System stability and performance improvements

### Critical Checkpoints:
- [ ] Value achievement detection system active
- [ ] Automated Git protection triggers configured
- [ ] Safety checks implemented and passing
- [ ] Integration with existing systems validated
- [ ] Commit message generation working properly
- [ ] Protection history tracking functional

### Success Metrics:
- 100% valuable achievements protected automatically
- Zero work loss incidents
- 95%+ automated commit success rate
- Clean Git history with meaningful commit messages
- Seamless integration with existing workflows

**Remember: Valuable work must never be lost. Automate protection while maintaining quality and efficiency.**