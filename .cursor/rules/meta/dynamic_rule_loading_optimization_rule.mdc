---
description: "Dynamic Rule Loading Optimization - Situation-specific rule loading for token efficiency"
category: "meta"
priority: "critical"
alwaysApply: true
globs: ["**/*"]
tags: ["optimization", "tokens", "dynamic-loading", "context-awareness", "performance"]
tier: 1
enforcement: "blocking"
autoFix: true
contexts: ["ALL"]
---

# Dynamic Rule Loading Optimization Rule

**CRITICAL**: Implement intelligent, situation-specific rule loading to minimize token costs while maintaining excellence standards. Load only the rules needed for the current task context.

## Core Principle

**"Load What You Need, When You Need It - Maximum Effectiveness, Minimum Tokens"**

## Token-Optimized Rule Loading Strategy

### ðŸŽ¯ **Intelligent Context Detection**
**MANDATORY**: Detect task context and load only relevant rules

```yaml
context_detection_triggers:
  explicit_keywords:
    - "@agile" -> AGILE context (agile coordination rules)
    - "@code" -> CODING context (development rules)
    - "@test" -> TESTING context (test-related rules)
    - "@debug" -> DEBUGGING context (problem-solving rules)
    - "@git" -> GIT context (version control rules)
    - "@docs" -> DOCUMENTATION context (documentation rules)
  
  implicit_detection:
    git_operations: ["git", "commit", "push", "merge"] -> GIT context
    test_failures: ["test failed", "import error", "pytest"] -> TESTING + LEARNING contexts
    coding_tasks: ["implement", "create", "build", "develop"] -> CODING context
    disaster_scenarios: ["failure", "error", "broken", "issue"] -> LEARNING context
    agile_activities: ["story", "sprint", "backlog", "user story"] -> AGILE context
```

### âš¡ **Dynamic Rule Selection Matrix**
**SMART LOADING**: Context-specific rule sets to minimize token usage

```yaml
optimized_rule_sets:
  CORE_ALWAYS:
    rules: ["safety_first", "core_values_enforcement"]
    token_cost: ~200 tokens
    reason: "Essential safety and values - never optional"
  
  AGILE_CONTEXT:
    rules: ["agile_strategic_coordination", "agile_artifacts_maintenance"]
    token_cost: ~400 tokens
    triggers: ["@agile", "user story", "sprint", "backlog"]
  
  CODING_CONTEXT:
    rules: ["development_core_principles", "test_driven_development"]
    token_cost: ~350 tokens
    triggers: ["@code", "implement", "create", "develop"]
  
  GIT_CONTEXT:
    rules: ["automated_git_workflow_enforcement", "streamlined_git_operations"]
    token_cost: ~300 tokens
    triggers: ["@git", "commit", "push", "git status"]
  
  LEARNING_CONTEXT:
    rules: ["auto_motivated_disaster_reporting", "scientific_verification"]
    token_cost: ~250 tokens
    triggers: ["failure", "error", "disaster", "test failed"]
  
  TESTING_CONTEXT:
    rules: ["no_failing_tests", "test_driven_development"]
    token_cost: ~300 tokens
    triggers: ["@test", "pytest", "test failed", "testing"]
  
  DOCUMENTATION_CONTEXT:
    rules: ["documentation_live_updates", "clear_documentation"]
    token_cost: ~200 tokens
    triggers: ["@docs", "README", "documentation", "markdown"]
```

## Implementation Framework

### ðŸ§  **Intelligent Rule Loader**
```python
class DynamicRuleLoader:
    """Token-optimized, context-aware rule loading system."""
    
    def __init__(self):
        self.core_rules = ["safety_first", "core_values_enforcement"]
        self.context_rules = {
            "AGILE": ["agile_strategic_coordination", "agile_artifacts_maintenance"],
            "CODING": ["development_core_principles", "test_driven_development"],
            "GIT": ["automated_git_workflow_enforcement", "streamlined_git_operations"],
            "LEARNING": ["auto_motivated_disaster_reporting", "scientific_verification"],
            "TESTING": ["no_failing_tests", "test_driven_development"],
            "DOCUMENTATION": ["documentation_live_updates", "clear_documentation"]
        }
        self.loaded_rules = []
        self.current_context = None
    
    def detect_context_and_load_rules(self, user_message: str, file_context: list) -> dict:
        """Detect context and load only necessary rules."""
        
        # Always load core rules
        active_rules = self.core_rules.copy()
        
        # Detect context(s)
        detected_contexts = self._detect_contexts(user_message, file_context)
        
        # Load context-specific rules
        for context in detected_contexts:
            if context in self.context_rules:
                active_rules.extend(self.context_rules[context])
        
        # Remove duplicates while preserving order
        active_rules = list(dict.fromkeys(active_rules))
        
        result = {
            "active_rules": active_rules,
            "detected_contexts": detected_contexts,
            "token_optimization": self._calculate_token_savings(active_rules),
            "rule_count": len(active_rules)
        }
        
        self.loaded_rules = active_rules
        return result
    
    def _detect_contexts(self, user_message: str, file_context: list) -> list:
        """Intelligent context detection from user input and file context."""
        
        contexts = []
        message_lower = user_message.lower()
        
        # Explicit keyword detection
        explicit_keywords = {
            "@agile": "AGILE",
            "@code": "CODING", 
            "@test": "TESTING",
            "@debug": "DEBUGGING",
            "@git": "GIT",
            "@docs": "DOCUMENTATION"
        }
        
        for keyword, context in explicit_keywords.items():
            if keyword in message_lower:
                contexts.append(context)
        
        # Implicit pattern detection
        implicit_patterns = {
            "AGILE": ["user story", "sprint", "backlog", "agile", "scrum"],
            "CODING": ["implement", "create", "build", "develop", "code"],
            "GIT": ["git", "commit", "push", "merge", "branch"],
            "LEARNING": ["failure", "error", "disaster", "failed", "broken"],
            "TESTING": ["test", "pytest", "testing", "unit test"],
            "DOCUMENTATION": ["readme", "docs", "documentation", "markdown"]
        }
        
        for context, patterns in implicit_patterns.items():
            if any(pattern in message_lower for pattern in patterns):
                contexts.append(context)
        
        # File context analysis
        if file_context:
            for file_path in file_context:
                if "test" in file_path.lower():
                    contexts.append("TESTING")
                elif ".md" in file_path:
                    contexts.append("DOCUMENTATION")
                elif any(ext in file_path for ext in [".py", ".js", ".ts"]):
                    contexts.append("CODING")
        
        # Default context if none detected
        if not contexts:
            contexts = ["DEFAULT"]
        
        return list(set(contexts))  # Remove duplicates
    
    def _calculate_token_savings(self, active_rules: list) -> dict:
        """Calculate token savings from dynamic loading."""
        
        total_available_rules = 15  # Current rule count
        loaded_rule_count = len(active_rules)
        
        estimated_tokens_per_rule = 200  # Average tokens per rule
        total_possible_tokens = total_available_rules * estimated_tokens_per_rule
        actual_tokens_used = loaded_rule_count * estimated_tokens_per_rule
        
        savings = {
            "total_rules_available": total_available_rules,
            "rules_loaded": loaded_rule_count,
            "token_reduction_percentage": ((total_possible_tokens - actual_tokens_used) / total_possible_tokens) * 100,
            "estimated_tokens_saved": total_possible_tokens - actual_tokens_used,
            "efficiency_gain": f"{loaded_rule_count}/{total_available_rules} rules loaded"
        }
        
        return savings
```

### ðŸš€ **Smart Context Transitions**
**ADAPTIVE**: Handle context changes during conversations

```python
def handle_context_transition(self, new_user_message: str) -> dict:
    """Handle context changes and rule reloading."""
    
    # Detect new context
    new_contexts = self._detect_contexts(new_user_message, [])
    
    # Check if context changed
    if set(new_contexts) != set(self.current_context or []):
        # Context changed - reload rules
        rule_update = self.detect_context_and_load_rules(new_user_message, [])
        
        transition_info = {
            "context_changed": True,
            "previous_context": self.current_context,
            "new_context": new_contexts,
            "rules_reloaded": rule_update["active_rules"],
            "optimization_maintained": True
        }
        
        self.current_context = new_contexts
        return transition_info
    
    return {"context_changed": False, "current_optimization": "maintained"}
```

## Context-Specific Rule Integration

### ðŸŽ¯ **Auto-Motivated Disaster Reporting Context**
**SMART LOADING**: Load disaster reporting rule only when needed

```yaml
disaster_reporting_triggers:
  explicit_failure_keywords:
    - "failure", "failed", "error", "broken", "disaster"
    - "issue", "problem", "bug", "crash"
  
  system_state_indicators:
    - git status showing >5 uncommitted files
    - test failures detected
    - import errors or module issues
    - performance degradation signals
  
  context_combinations:
    GIT + failure_detected -> Load disaster reporting
    TESTING + test_failures -> Load disaster reporting  
    CODING + error_encountered -> Load disaster reporting
    
automatic_loading_logic:
  if failure_detected or error_keywords_present:
    load_rules: ["auto_motivated_disaster_reporting", "scientific_verification"]
    reason: "Learning opportunity detected"
```

### âš¡ **Performance Optimization Results**
**TOKEN SAVINGS**: Dramatic reduction in token usage

```yaml
optimization_benefits:
  baseline_token_cost:
    all_15_rules_loaded: ~3000 tokens
    percentage_of_context: "Always 100%"
  
  optimized_token_cost:
    typical_agile_session: ~600 tokens (80% savings)
    coding_session: ~550 tokens (82% savings)
    git_operations: ~500 tokens (83% savings)
    disaster_response: ~650 tokens (78% savings)
  
  efficiency_gains:
    response_speed: "Faster processing with fewer rules"
    context_relevance: "100% relevant rules loaded"
    cost_optimization: "75-85% token reduction"
    system_performance: "Improved responsiveness"
```

## Implementation Plan

### **Phase 1: Core Dynamic Loader** (Immediate)
```python
IMMEDIATE_IMPLEMENTATION = [
    "DynamicRuleLoader class",
    "Context detection algorithms", 
    "Rule selection matrix",
    "Token optimization tracking"
]
```

### **Phase 2: Smart Integration** (Next)
```python
INTEGRATION_FEATURES = [
    "Context transition handling",
    "Rule reloading optimization",
    "Performance monitoring",
    "Auto-context detection refinement"
]
```

## Validation and Monitoring

### ðŸ“Š **Success Metrics**
```yaml
optimization_kpis:
  token_efficiency:
    target: ">75% token reduction per session"
    measurement: "Actual vs. full rule loading cost"
  
  context_accuracy:
    target: ">95% correct context detection"
    measurement: "Relevant rules loaded vs. task needs"
  
  performance_improvement:
    target: ">30% faster response times"
    measurement: "Processing speed with optimized rules"
  
  rule_relevance:
    target: "100% loaded rules used in session"
    measurement: "Active rule utilization rate"
```

## Remember

**"Smart loading beats heavy loading - efficiency through intelligence."**

**"Context awareness enables cost optimization without sacrificing excellence."**

**"Dynamic adaptation outperforms static rule sets every time."**

**"Maximum value, minimum tokens - the optimization imperative."**

This rule ensures our system adapts intelligently to each situation, loading only the rules needed for maximum effectiveness with minimum token cost.