---
description: "Auto-generated description for performance_monitoring_optimization_rule.mdc"
category: "quality-standards"
priority: "low"
alwaysApply: true
globs: ["**/*"]
tags: ['quality_standards']
tier: "2"
---

# Performance Monitoring and Optimization Rule

---
description: "Proactive performance monitoring and optimization with continuous measurement and improvement"
category: "performance"
priority: "critical"
alwaysApply: true
globs: ["**/*.py", "**/*.js", "**/*.ts", "**/*.java", "**/*.go"]
tags: ["performance", "monitoring", "optimization", "profiling", "metrics"]
---

# Performance Monitoring and Optimization Rule

**CRITICAL**: Implement proactive performance monitoring and optimization throughout the development lifecycle to ensure optimal system performance and user experience.

## Core Requirements

### 1. Performance Baseline and Monitoring
**MANDATORY**: Establish performance baselines and continuously monitor performance metrics.

**Performance Metrics**:
- **Response Time**: API response times and latency
- **Throughput**: Requests per second and processing capacity
- **Resource Usage**: CPU, memory, disk, and network utilization
- **Error Rates**: Performance-related errors and failures
- **User Experience**: Page load times and interaction responsiveness

**Implementation**:
```python
# ✅ CORRECT: Performance Monitoring
class PerformanceMonitor:
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.baseline_manager = BaselineManager()
        self.alert_system = AlertSystem()
    
    def establish_baseline(self, component: str) -> PerformanceBaseline:
        """Establish performance baseline for component"""
        # Collect baseline metrics
        baseline_metrics = self.metrics_collector.collect_baseline_metrics(component)
        
        # Calculate baseline statistics
        baseline = PerformanceBaseline(
            component=component,
            avg_response_time=baseline_metrics.avg_response_time,
            p95_response_time=baseline_metrics.p95_response_time,
            throughput=baseline_metrics.throughput,
            error_rate=baseline_metrics.error_rate,
            resource_usage=baseline_metrics.resource_usage
        )
        
        # Store baseline
        self.baseline_manager.store_baseline(baseline)
        
        return baseline
    
    def monitor_performance(self, component: str) -> PerformanceStatus:
        """Monitor current performance against baseline"""
        # Collect current metrics
        current_metrics = self.metrics_collector.collect_current_metrics(component)
        
        # Get baseline
        baseline = self.baseline_manager.get_baseline(component)
        
        # Compare and analyze
        performance_status = self.analyze_performance(current_metrics, baseline)
        
        # Alert if thresholds exceeded
        if performance_status.has_degradation():
            self.alert_system.send_alert(performance_status)
        
        return performance_status
```

### 2. Performance Profiling and Analysis
**MANDATORY**: Use profiling tools to identify performance bottlenecks and optimization opportunities.

**Profiling Requirements**:
- **CPU Profiling**: Identify CPU-intensive operations
- **Memory Profiling**: Detect memory leaks and inefficient usage
- **I/O Profiling**: Analyze disk and network operations
- **Database Profiling**: Monitor query performance and optimization
- **Network Profiling**: Analyze network latency and bandwidth usage

**Implementation**:
```python
# ✅ CORRECT: Performance Profiling
class PerformanceProfiler:
    def __init__(self):
        self.cpu_profiler = CPUProfiler()
        self.memory_profiler = MemoryProfiler()
        self.io_profiler = IOProfiler()
        self.db_profiler = DatabaseProfiler()
        self.network_profiler = NetworkProfiler()
    
    def profile_component(self, component: str, duration: int = 300) -> ProfileReport:
        """Comprehensive performance profiling"""
        profile_report = ProfileReport(component=component)
        
        # CPU profiling
        cpu_profile = self.cpu_profiler.profile(component, duration)
        profile_report.add_cpu_profile(cpu_profile)
        
        # Memory profiling
        memory_profile = self.memory_profiler.profile(component, duration)
        profile_report.add_memory_profile(memory_profile)
        
        # I/O profiling
        io_profile = self.io_profiler.profile(component, duration)
        profile_report.add_io_profile(io_profile)
        
        # Database profiling
        db_profile = self.db_profiler.profile(component, duration)
        profile_report.add_db_profile(db_profile)
        
        # Network profiling
        network_profile = self.network_profiler.profile(component, duration)
        profile_report.add_network_profile(network_profile)
        
        return profile_report
    
    def identify_bottlenecks(self, profile_report: ProfileReport) -> List[Bottleneck]:
        """Identify performance bottlenecks from profiling data"""
        bottlenecks = []
        
        # Analyze CPU bottlenecks
        cpu_bottlenecks = self.cpu_profiler.identify_bottlenecks(profile_report.cpu_profile)
        bottlenecks.extend(cpu_bottlenecks)
        
        # Analyze memory bottlenecks
        memory_bottlenecks = self.memory_profiler.identify_bottlenecks(profile_report.memory_profile)
        bottlenecks.extend(memory_bottlenecks)
        
        # Analyze I/O bottlenecks
        io_bottlenecks = self.io_profiler.identify_bottlenecks(profile_report.io_profile)
        bottlenecks.extend(io_bottlenecks)
        
        # Analyze database bottlenecks
        db_bottlenecks = self.db_profiler.identify_bottlenecks(profile_report.db_profile)
        bottlenecks.extend(db_bottlenecks)
        
        return bottlenecks

class CPUProfiler:
    def profile(self, component: str, duration: int) -> CPUProfile:
        """Profile CPU usage and identify hotspots"""
        import cProfile
        import pstats
        
        # Create profiler
        profiler = cProfile.Profile()
        profiler.enable()
        
        # Run component for specified duration
        self.run_component(component, duration)
        
        profiler.disable()
        
        # Analyze results
        stats = pstats.Stats(profiler)
        stats.sort_stats('cumulative')
        
        return CPUProfile(
            total_time=stats.total_tt,
            function_calls=stats.total_calls,
            hotspots=stats.get_stats_profile()
        )
```

### 3. Performance Testing and Validation
**MANDATORY**: Implement comprehensive performance testing to validate optimizations and prevent regressions.

**Testing Requirements**:
- **Load Testing**: Test system behavior under expected load
- **Stress Testing**: Test system limits and failure points
- **Endurance Testing**: Test system stability over time
- **Spike Testing**: Test system response to sudden load changes
- **Scalability Testing**: Test system performance as load increases

**Implementation**:
```python
# ✅ CORRECT: Performance Testing
class PerformanceTester:
    def __init__(self):
        self.load_tester = LoadTester()
        self.stress_tester = StressTester()
        self.endurance_tester = EnduranceTester()
        self.spike_tester = SpikeTester()
        self.scalability_tester = ScalabilityTester()
    
    def run_performance_tests(self, component: str) -> PerformanceTestResults:
        """Run comprehensive performance test suite"""
        test_results = PerformanceTestResults(component=component)
        
        # Load testing
        load_results = self.load_tester.test(component)
        test_results.add_load_test_results(load_results)
        
        # Stress testing
        stress_results = self.stress_tester.test(component)
        test_results.add_stress_test_results(stress_results)
        
        # Endurance testing
        endurance_results = self.endurance_tester.test(component)
        test_results.add_endurance_test_results(endurance_results)
        
        # Spike testing
        spike_results = self.spike_tester.test(component)
        test_results.add_spike_test_results(spike_results)
        
        # Scalability testing
        scalability_results = self.scalability_tester.test(component)
        test_results.add_scalability_test_results(scalability_results)
        
        return test_results
    
    def validate_optimization(self, before_metrics: PerformanceMetrics, 
                            after_metrics: PerformanceMetrics) -> OptimizationValidation:
        """Validate that optimization improved performance"""
        validation = OptimizationValidation()
        
        # Compare response times
        response_time_improvement = self.calculate_improvement(
            before_metrics.avg_response_time,
            after_metrics.avg_response_time
        )
        validation.add_metric("response_time", response_time_improvement)
        
        # Compare throughput
        throughput_improvement = self.calculate_improvement(
            after_metrics.throughput,
            before_metrics.throughput
        )
        validation.add_metric("throughput", throughput_improvement)
        
        # Compare resource usage
        resource_improvement = self.calculate_improvement(
            before_metrics.resource_usage,
            after_metrics.resource_usage
        )
        validation.add_metric("resource_usage", resource_improvement)
        
        return validation

class LoadTester:
    def test(self, component: str) -> LoadTestResults:
        """Test component under expected load"""
        import asyncio
        import aiohttp
        import time
        
        # Define test parameters
        concurrent_users = 100
        test_duration = 300  # 5 minutes
        ramp_up_time = 60   # 1 minute
        
        # Run load test
        start_time = time.time()
        results = []
        
        async def make_request():
            async with aiohttp.ClientSession() as session:
                start = time.time()
                async with session.get(f"http://localhost:8000/{component}") as response:
                    end = time.time()
                    results.append({
                        "response_time": end - start,
                        "status_code": response.status,
                        "timestamp": start
                    })
        
        # Execute concurrent requests
        tasks = [make_request() for _ in range(concurrent_users)]
        await asyncio.gather(*tasks)
        
        return LoadTestResults(
            total_requests=len(results),
            avg_response_time=sum(r["response_time"] for r in results) / len(results),
            p95_response_time=self.calculate_percentile([r["response_time"] for r in results], 95),
            error_rate=len([r for r in results if r["status_code"] >= 400]) / len(results)
        )
```

### 4. Performance Optimization Strategies
**MANDATORY**: Implement systematic performance optimization strategies based on profiling results.

**Optimization Strategies**:
- **Algorithm Optimization**: Improve algorithm efficiency and complexity
- **Caching**: Implement appropriate caching strategies
- **Database Optimization**: Optimize queries and database design
- **Resource Management**: Optimize memory and CPU usage
- **Network Optimization**: Reduce network overhead and latency

**Implementation**:
```python
# ✅ CORRECT: Performance Optimization
class PerformanceOptimizer:
    def __init__(self):
        self.algorithm_optimizer = AlgorithmOptimizer()
        self.caching_optimizer = CachingOptimizer()
        self.database_optimizer = DatabaseOptimizer()
        self.resource_optimizer = ResourceOptimizer()
        self.network_optimizer = NetworkOptimizer()
    
    def optimize_component(self, component: str, bottlenecks: List[Bottleneck]) -> OptimizationPlan:
        """Create optimization plan based on identified bottlenecks"""
        optimization_plan = OptimizationPlan(component=component)
        
        for bottleneck in bottlenecks:
            if bottleneck.type == "cpu":
                optimizations = self.algorithm_optimizer.suggest_optimizations(bottleneck)
                optimization_plan.add_optimizations(optimizations)
            
            elif bottleneck.type == "memory":
                optimizations = self.resource_optimizer.suggest_memory_optimizations(bottleneck)
                optimization_plan.add_optimizations(optimizations)
            
            elif bottleneck.type == "database":
                optimizations = self.database_optimizer.suggest_optimizations(bottleneck)
                optimization_plan.add_optimizations(optimizations)
            
            elif bottleneck.type == "network":
                optimizations = self.network_optimizer.suggest_optimizations(bottleneck)
                optimization_plan.add_optimizations(optimizations)
        
        return optimization_plan
    
    def apply_optimizations(self, component: str, optimizations: List[Optimization]) -> OptimizationResults:
        """Apply performance optimizations and measure results"""
        results = OptimizationResults(component=component)
        
        # Measure baseline performance
        baseline_metrics = self.measure_performance(component)
        
        # Apply each optimization
        for optimization in optimizations:
            try:
                # Apply optimization
                self.apply_optimization(optimization)
                
                # Measure performance after optimization
                after_metrics = self.measure_performance(component)
                
                # Calculate improvement
                improvement = self.calculate_improvement(baseline_metrics, after_metrics)
                
                # Record result
                results.add_optimization_result(optimization, improvement)
                
                # Update baseline for next optimization
                baseline_metrics = after_metrics
                
            except Exception as e:
                results.add_optimization_error(optimization, str(e))
        
        return results

class CachingOptimizer:
    def suggest_optimizations(self, bottleneck: Bottleneck) -> List[Optimization]:
        """Suggest caching optimizations"""
        optimizations = []
        
        # Function result caching
        if bottleneck.location.endswith(".py"):
            optimizations.append(Optimization(
                type="function_caching",
                description="Add @lru_cache decorator to expensive functions",
                implementation="from functools import lru_cache\n@lru_cache(maxsize=128)\ndef expensive_function():"
            ))
        
        # Database query caching
        if "database" in bottleneck.description.lower():
            optimizations.append(Optimization(
                type="query_caching",
                description="Implement Redis caching for database queries",
                implementation="cache.set(key, result, timeout=3600)"
            ))
        
        # API response caching
        if "api" in bottleneck.description.lower():
            optimizations.append(Optimization(
                type="api_caching",
                description="Add HTTP caching headers",
                implementation="response.headers['Cache-Control'] = 'max-age=3600'"
            ))
        
        return optimizations
```

### 5. Performance Monitoring Dashboard
**MANDATORY**: Implement real-time performance monitoring dashboard for continuous visibility.

**Dashboard Requirements**:
- **Real-time Metrics**: Live performance metrics display
- **Historical Trends**: Performance trends over time
- **Alert Management**: Performance alert configuration and management
- **Optimization Tracking**: Track optimization efforts and results
- **Resource Monitoring**: System resource utilization monitoring

**Implementation**:
```python
# ✅ CORRECT: Performance Dashboard
class PerformanceDashboard:
    def __init__(self):
        self.metrics_display = MetricsDisplay()
        self.trend_analyzer = TrendAnalyzer()
        self.alert_manager = AlertManager()
        self.optimization_tracker = OptimizationTracker()
        self.resource_monitor = ResourceMonitor()
    
    def display_real_time_metrics(self) -> DashboardView:
        """Display real-time performance metrics"""
        # Collect current metrics
        current_metrics = self.collect_current_metrics()
        
        # Create dashboard view
        dashboard_view = DashboardView()
        
        # Add performance metrics
        dashboard_view.add_performance_metrics(current_metrics.performance)
        
        # Add resource metrics
        dashboard_view.add_resource_metrics(current_metrics.resources)
        
        # Add error metrics
        dashboard_view.add_error_metrics(current_metrics.errors)
        
        # Add optimization status
        dashboard_view.add_optimization_status(self.optimization_tracker.get_status())
        
        return dashboard_view
    
    def analyze_performance_trends(self, time_period: str) -> TrendAnalysis:
        """Analyze performance trends over time"""
        # Get historical data
        historical_data = self.get_historical_metrics(time_period)
        
        # Analyze trends
        trend_analysis = TrendAnalysis()
        
        # Response time trends
        response_time_trend = self.trend_analyzer.analyze_trend(
            historical_data.response_times
        )
        trend_analysis.add_trend("response_time", response_time_trend)
        
        # Throughput trends
        throughput_trend = self.trend_analyzer.analyze_trend(
            historical_data.throughput
        )
        trend_analysis.add_trend("throughput", throughput_trend)
        
        # Error rate trends
        error_rate_trend = self.trend_analyzer.analyze_trend(
            historical_data.error_rates
        )
        trend_analysis.add_trend("error_rate", error_rate_trend)
        
        return trend_analysis
```

## Integration with Development Workflow

### Pre-Deployment Performance Validation
```python
# ✅ CORRECT: Pre-Deployment Performance Check
class PreDeploymentPerformanceCheck:
    def validate_performance(self, component: str) -> DeploymentValidation:
        """Validate performance before deployment"""
        # Run performance tests
        test_results = self.run_performance_tests(component)
        
        # Compare with baseline
        baseline = self.get_performance_baseline(component)
        validation = self.compare_with_baseline(test_results, baseline)
        
        # Check for regressions
        if validation.has_regressions():
            raise PerformanceRegressionError(f"Performance regression detected in {component}")
        
        return validation
```

### Continuous Performance Monitoring
```python
# ✅ CORRECT: Continuous Monitoring
class ContinuousPerformanceMonitor:
    def monitor_production(self) -> None:
        """Continuously monitor production performance"""
        while True:
            # Collect metrics
            metrics = self.collect_production_metrics()
            
            # Analyze performance
            analysis = self.analyze_performance(metrics)
            
            # Check for issues
            if analysis.has_issues():
                self.handle_performance_issues(analysis)
            
            # Update dashboard
            self.update_dashboard(metrics, analysis)
            
            # Wait for next cycle
            time.sleep(60)  # Check every minute
```

## Benefits

### Performance Assurance
- **Proactive Monitoring**: Detect performance issues before they impact users
- **Optimization Validation**: Ensure optimizations actually improve performance
- **Regression Prevention**: Prevent performance regressions in deployments

### Development Efficiency
- **Early Detection**: Identify performance bottlenecks early in development
- **Data-Driven Optimization**: Make optimization decisions based on real data
- **Automated Testing**: Automate performance testing and validation

### User Experience
- **Consistent Performance**: Maintain consistent performance across all components
- **Scalability**: Ensure system can handle expected and unexpected load
- **Reliability**: Prevent performance-related failures and outages

### Resource Optimization
- **Cost Efficiency**: Optimize resource usage to reduce costs
- **Capacity Planning**: Better understand system capacity and requirements
- **Resource Management**: Efficient use of CPU, memory, and network resources

## Enforcement

This rule is **CRITICAL** and must be followed for all:
- New feature development and implementation
- Code changes and optimizations
- System deployments and releases
- Performance-critical components
- Production system monitoring

**Violations of this rule require immediate performance analysis and optimization.**
description: "Auto-generated description"
globs: ["**/*"]
alwaysApply: true
---
